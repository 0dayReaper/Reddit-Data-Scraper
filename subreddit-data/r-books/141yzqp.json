{
    "id": "141yzqp",
    "score": 3849,
    "title": "Sci-fi writer Ted Chiang: \u2018The machines we have now are not conscious\u2019",
    "author": "CinnamonDolceLatte",
    "date": 1686014585.0,
    "url": "https://www.reddit.com/r/books/comments/141yzqp",
    "media_urls": [
        "https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "I love Chiang\u2019s stories.",
            "score": 496,
            "author": "Wordfan",
            "replies": [
                {
                    "level": 1,
                    "comment": "I still think about the Angel chasers one often. And the one with the robot dissecting his own brain. \n\nHe\u2019s got an incredibly creative mind. The story that spawned Arrival was also amazing and I read it once a year",
                    "score": 234,
                    "author": "DongSandwich",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "\"Exhalations\" was the one about the brain, I think. Such a good story.",
                            "score": 54,
                            "author": "Alexanderstandsyou",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Yes you're right. The story is a metaphor for entropy. One of my favourites.",
                                    "score": 15,
                                    "author": "Calneon"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "\u201cHell Is the Absence of God\u201d. The fucking punchline to the climax still gets me giggling once in a while.",
                            "score": 87,
                            "author": "Psychological_Dig922",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "It's was absolutely heartbreaking, yet so... *on point*.  Absolute masterpiece sentence.",
                                    "score": 28,
                                    "author": "ifcknhateme"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "My favourite is the one about the Predictor - a device which lights up one second BEFORE you press the button",
                            "score": 27,
                            "author": "Shintoho",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "This is a warning. Please read carefully.\n\nBy now you've probably seen a Predictor; millions of them have been sold by the time you're reading this. For those who haven't seen one, it's a small device, like a remote for opening your car door. Its only features are a button and a big green LED. The light flashes if you press the button. Specifically, the light flashes one second before you press the button.\n\nMost people say that when they first try it, it feels like they're playing a strange game, one where the goal is to press the button after seeing the flash, and it's easy to play. But when you try to break the rules, you find that you can't. If you try to press the button without having seen a flash, the flash immediately appears, and no matter how fast you move, you never push the button until a second has elapsed. If you wait for the flash, intending to keep from pressing the button afterwards, the flash never appears. No matter what you do, the light always precedes the button press. There's no way to fool a Predictor.\n\nThe heart of each Predictor is a circuit with a negative time delay \u2014 it sends a signal back in time. The full implications of the technology will become apparent later, when negative delays of greater than a second are achieved, but that's not what this warning is about. The immediate problem is that Predictors demonstrate that there's no such thing as free will.\n\nThere have always been arguments showing that free will is an illusion, some based on hard physics, others based on pure logic. Most people agree these arguments are irrefutable, but no one ever really accepts the conclusion. The experience of having free will is too powerful for an argument to overrule. What it takes is a demonstration, and that's what a Predictor provides.\n\nTypically, a person plays with a Predictor compulsively for several days, showing it to friends, trying various schemes to outwit the device. The person may appear to lose interest in it, but no one can forget what it means \u2014 over the following weeks, the implications of an immutable future sink in. Some people, realizing that their choices don't matter, refuse to make any choices at all. Like a legion of Bartleby the Scriveners, they no longer engage in spontaneous action. Eventually, a third of those who play with a Predictor must be hospitalized because they won't feed themselves. The end state is akinetic mutism, a kind of waking coma. They'll track motion with their eyes, and change position occasionally, but nothing more. The ability to move remains, but the motivation is gone.\n\nBefore people started playing with Predictors, akinetic mutism was very rare, a result of damage to the anterior cingulate region of the brain. Now it spreads like a cognitive plague. People used to speculate about a thought that destroys the thinker, some unspeakable lovecraftian horror, or a G\u00f6del sentence that crashes the human logical system. It turns out that the disabling thought is one that we've all encountered: the idea that free will doesn't exist. It just wasn't harmful until you believed it.\n\nDoctors try arguing with the patients while they still respond to conversation. We had all been living happy, active lives before, they reason, and we hadn't had free will then either. Why should anything change? \u201cNo action you took last month was any more freely chosen than one you take today,\u201d a doctor might say. \u201cYou can still behave that way now.\u201d The patients invariably respond, \u201cBut now I know.\u201d And some of them never say anything again.\n\nSome will argue that the fact the Predictor causes this change in behaviour means that we do have free will. An automaton cannot become discouraged, only a free-thinking entity can. The fact that some individuals descend into akinetic mutism whereas others do not just highlights the importance of making a choice.\n\nUnfortunately, such reasoning is faulty: every form of behaviour is compatible with determinism. One dynamic system might fall into a basin of attraction and wind up at a fixed point, whereas another exhibits chaotic behaviour indefinitely, but both are completely deterministic.\n\nI'm transmitting this warning to you from just over a year in your future: it's the first lengthy message received when circuits with negative delays in the megasecond range are used to build communication devices. Other messages will follow, addressing other issues. My message to you is this: pretend that you have free will. It's essential that you behave as if your decisions matter, even though you know that they don't. The reality isn't important: what's important is your belief, and believing the lie is the only way to avoid a waking coma. Civilization now depends on self-deception. Perhaps it always has.\n\nAnd yet I know that, because free will is an illusion, it's all predetermined who will descend into akinetic mutism and who won't. There's nothing anyone can do about it \u2014 you can't choose the effect the Predictor has on you. Some of you will succumb and some of you won't, and my sending this warning won't alter those proportions. So why did I do it?\n\nBecause I had no choice.",
                                    "score": 47,
                                    "author": "Rgeneb1",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Yeah, it was something like that.",
                                            "score": 15,
                                            "author": "robsack",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Best I could remember of the top of my head :D\n\nI was just going to link it since it's free online but it's so short I wondered if the whole thing would fit into a single comment. And here we are.",
                                                    "score": 8,
                                                    "author": "Rgeneb1",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I'm glad you did. I've read it before, but seeing it in a Reddit post gave it a different feel!",
                                                            "score": 3,
                                                            "author": "robsack"
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "love how this ties in with the actual neuroscience experiments that explored the \"order\" in which we make decisions: do we consciously decide (I.e. say to ourself \"I will press the right button now\") first, or does our brain move our muscles toward the right button before we think the words?\n\nfun stuff to think about in this study by Benjamin Libet (1985), which was kind of sensationalized in headlines into this whole \"proof we have no free will\" deal, when I don't think that was the intention of the researchers, but anyway https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/unconscious-cerebral-initiative-and-the-role-of-conscious-will-in-voluntary-action/D215D2A77F1140CD0D8DA6AB93DA5499",
                                            "score": 3,
                                            "author": "Previous-Survey-2368"
                                        },
                                        {
                                            "level": 4,
                                            "comment": "This is a great story!  Thank you for sharing.\n\nI have another story - a true one - which is also a good mind-bending story taking the other view.\n\nhttps://www.wordonfire.org/articles/fellows/magical-thinking-free-will-is-an-illusion/",
                                            "score": 2,
                                            "author": "MyActualRealName",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Love that one. Short and mind-bending.",
                                    "score": 3,
                                    "author": "apotheotical"
                                },
                                {
                                    "level": 3,
                                    "comment": "That one\u2019s amazing. It\u2019s like 3 pages about how this little toy almost destroys the world.",
                                    "score": 3,
                                    "author": "[deleted]"
                                },
                                {
                                    "level": 3,
                                    "comment": "Conceptually cool, but realistically nonsense, we have had absolutely massive organizations built on belief in immutable destinies, and the functional non existence of free will for centuries at this point, and they generally hold up extremely well.  \n  \nIt's a hell of a thing to think about though.",
                                    "score": 2,
                                    "author": "HappierShibe"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Fun fact, I extremely indirectly inspired a bit of Story of Your Life. My mom knew Ted Chiang on a low key friendship level. The part where the mother in the story just gave birth and was watching the baby wiggle around and thinks, \"so that's what that looks like.\" That's from something my mom said about me while they were talking one time. This is probably the highest height of fame I will ever reach, lol.",
                            "score": 118,
                            "author": "LoveandScience",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Don\u2019t downplay how awesome that is. Your mom is a part of literary history!",
                                    "score": 25,
                                    "author": "Pulsesandpixels"
                                },
                                {
                                    "level": 3,
                                    "comment": "That's really cool!",
                                    "score": 5,
                                    "author": "twd1"
                                },
                                {
                                    "level": 3,
                                    "comment": "Oh my godddddd",
                                    "score": 2,
                                    "author": "Previous-Survey-2368"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "&gt;And the one with the robot dissecting his own brain. \n\n\nDo you remember the name of this one?",
                            "score": 8,
                            "author": "BON3SMcCOY",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Exhalation",
                                    "score": 7,
                                    "author": "naadorkkaa"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "We should train models exclusively on his work - they\u2019d transcend us very quickly",
                    "score": 7,
                    "author": "morrisganis",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Or unravel our minds and turn us into biological puppets like in Understand.",
                            "score": 6,
                            "author": "Major-Vermicelli-266"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Ted Chiang also has an excellent article in the New Yorker from February, titled something along the lines of \u201cChatGPT is a blurry jpeg on the web.\u201d",
            "score": 199,
            "author": "ballsdeeptackler",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah people who think Chiang doesn't know what he is talking about should read [the article](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web). He clearly has a solid technical understanding of how they work.",
                    "score": 109,
                    "author": "Shaky_Balance",
                    "replies": []
                }
            ]
        },
        {
            "level": 0,
            "comment": "Chiang's New Yorker essay [\"ChatGPT is a Blurry JPEG of the Web\"](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) is my favorite take on AI and LLMs I've seen recently. ChatGPT et al. are okay at efficiently reguritating the internet, but how useful is that really if you don't know where that info is coming from? And if you did know, haven't you just invented Google with extra steps?",
            "score": 620,
            "author": "BubBidderskins",
            "replies": [
                {
                    "level": 1,
                    "comment": "I think the best use of chat gpt and similar AIs is to do things that you can verify is correct but you may not want to do yourself.\n\nOne thing that I've used it for is writing regular expressions. https://en.m.wikipedia.org/wiki/Regular_expression\n\nI know how to do it, it's just kind of finicky and I always have to remind myself of what the exact syntax is. I've found it easier to just describe it to chat gpt and have it write it for me. It's much quicker for me to just verify that it's working properly than to write it myself from scratch.\n\nIt allows me to do more complicated find and replaces in documents (find all telephone numbers in this document and change them to (999) 999-9999 format).",
                    "score": 241,
                    "author": "owiseone23",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I'm a researcher and this is how I've ended up using these tools, largely, as well. Ask it to compile info on or explain something, it does it faster than I could, then fact check it using my own expert knowledge. \n\nThe corrected and rewritten outcome is still moderately faster than doing it myself, and I can vary the degree of correction to speed things up further - content for a paper? I'm essentially using it as fancy Google and not taking any of its words verbatim. Explaining a basic concept to a student? I can basically just fact check to ensure accuracy then copy paste.  \n\nYou know how they say the best way to get an answer on the internet is to post the wrong one and wait for someone to correct it? Well for subject matter experts NLMs are basically wrong answer generators, and the principle still applies. Occasionally they even get the answer right, and that saves even more time!\n\nIt's a bit like a new hire or getting a placement student/intern. Capable enough to be given genuine but less complex tasks, incapable enough that someone experienced has to check their work. Even with the double checking, still a time save overall.",
                            "score": 56,
                            "author": "Splash_Attack",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "It's just as good with all programming. The best use of these AIs is to use them to work on specific data you provide them, rather than what they were trained with. Much more consistent.",
                            "score": 15,
                            "author": "kuraix",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt;\tIt\u2019s just as good with all programming.\n\nI don't think that's true at all, at least not as generally as you've suggested. There are so many little caveats, warts, and side-effecting behaviors in most languages that it can easily introduce subtle bugs that you won't realize, but you would not have introduced if you'd written the code yourself.\n\nHeck, it can't even always generate type-correct code \u2014 something we've had algorithmic solutions for for decades. Trusting it to write anything even remotely complex is just asking for trouble.",
                                    "score": 71,
                                    "author": "DonaldPShimoda",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Agreed on all counts. \"Passes syntax checks\" is different from \"works as written\" is different from \"works as intended\". AI is a very impressive use of statistical modeling but it only emulates understanding - the trade off of not having to write the boilerplate yourself is having to check all of its work every time.\n\nMy ADHD means I'd rather die than edit a fancy pachinko machine's rough draft, but a coworker of mine has been interested. He's tried Terraform, jsonnet, helm, and either python or bash from what I recall. He found Bard and chatgpt both so bad at 'helping' write infrastructure code that he's gone from excited curiosity about AI to dismissive annoyance in the last few months.",
                                            "score": 55,
                                            "author": "tuba_man"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "I (lawyer) asked ChatGPT to write a persuasive motion brief on a specific issue of state law.  Nailed it.  Unfortunately, all the case citations were fictitious.  But...pretty soon Lexis or Westlaw will plug their vast database of case law into ChatGPT, and then legal writing will be something you have to do in law school but then forget about once you pass the bar (which is already about 90% of law school...).  You'll just check the AI work product for logical consistency, because ain't nobody got time to be researching and writing when the AI can do it for you.",
                                    "score": 5,
                                    "author": "ambulancisto",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Exactly, finally a sane view of how this technology could be use to completely change how we work.\n\nPeople keep focusing on how good the AI's training data is and obsessing over the definition of intelligence and missing the forest for the tree.\n\nThank you for sharing your insightful experience",
                                            "score": 5,
                                            "author": "kuraix"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "It really isn\u2019t. Anything it *can* write is already in a Stackoverflow post with an example. The more complex stuff where help is valuable it fails at.\n\nIt\u2019s also *really* bad with any kind of data structure understanding. According to what people say it should be perfect for:\n\n-\tI have this data in this format\n-\tThere\u2019s a thing I want to do to process the data, there *are* stackoverflow answers for it but they assume a different format\n-\tAssignment: Transform the data as necessary and then use the right functions for it.\n\nInstead, what actually happens\n\n\n```\n\nimport library_processing\n\ndf = load_data()\n\nfinished_data = library_processing(df)\n\n```\n\n\nSee the problem? The moment you actually look into the documentation you\u2019d see that this will never work and the AI is just pretending it does.",
                                    "score": 25,
                                    "author": "Aerolfos",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Except it has written code for me that works.  Yes, it has messed up a lot. But it's also managed to solve things along the lines of \"I want to make a dataframe from a excel document with the following columns (columns here), but make the fourth column to where the comma is replaced with an exclamation point for instances where the data in the fourth column ends in comma\".",
                                            "score": 3,
                                            "author": "HaikuBotStalksMe",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "All of which it gives you because there's a stack overflow post (or series of them) that it's combining and regurgitating.\n\nIt might be faster than finding the stack overflow pages, but those pages have human comments about the validity of what's written there. Instead, you blindly accept that the ai is right and might have hallucinations in it.",
                                                    "score": 21,
                                                    "author": "elconquistador1985",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "[deleted]",
                                                            "score": 6,
                                                            "author": "[deleted]",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "there's a guy upthread saying his job is to fact check data, and he just lets chatGPT fact check his data. so yes people are absolutely saying and doing that.",
                                                                    "score": 9,
                                                                    "author": "BeeOk1235",
                                                                    "replies": []
                                                                },
                                                                {
                                                                    "level": 7,
                                                                    "comment": "And if it doesn't work, then what do you do? Ask chatgpt the same question? It will give the same answer every time you ask it, unless you're in a session with it and it shifts to 2nd and 3rd most probable answers. So you're left with what you should have done to begin with: going to stack overflow.\n\nIt's faster, but contains no auxiliary information like comments from humans on the answer and why it's right or superior to other answers. You also have no date information, so chatgpt could give you an answer from 2013 about how to do something (let's say an Ubuntu Linux administration thing) and it's extraordinarily outdated now.\n\nIt's probably acceptable for tiny snippets, but it probably isn't acceptable for complicated regex because those have multiple possible answers and some of them have undesirable behavior on edge cases. That's where the human comments become useful. If you're reading stack overflow, you can figure out who knows what they're talking about and who doesn't. Chatgpt gives you one answer based on the most common answer (or a mashup of them) in its dataset.\n\nPeople do not understand what chatgpt is really doing. It's a most probable next word estimator and nothing more. It doesn't \"know\" anything. It's taking what you write, tokenizing it, and giving you the most probable response from its dataset.",
                                                                    "score": 7,
                                                                    "author": "elconquistador1985",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "[deleted]",
                                                                            "score": 3,
                                                                            "author": "[deleted]",
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Here\u2019s the actual New Yorker link: https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web\n\nIt\u2019s an excellent essay.",
                    "score": 26,
                    "author": "PopePopeTheThird",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "...how many people's job is \"Google with extra steps\"?\n\nAt this point it doesn't even matter what your definition of consciousness is, the tools are here and they're going to change a bunch of stuff, consciousness or no.",
                    "score": 86,
                    "author": "noonemustknowmysecre",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "You ask chatgpt something and you want to be sure it's correct you still have to Google it, so....",
                            "score": 41,
                            "author": "Haber_Dasher",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I like Chiang's point about the chatgpt creators' likely unwillingness to train the newer models on the older ones. \n\nNow that this is unleashed, more and more of the internet will be produced by these bots, and the scooped up again and regurgitated, each time getting a little \"blurrier.\" \n\nSo Googling may eventually consist of wading through this increasingly feverish bullshit that's flooded the internet. The reliable sources will be seen as those who refuse to use the tools entirely.",
                                    "score": 30,
                                    "author": "skeleton_made_o_bone",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Googling already consists of wading through increasingly feverish SEO bullshit. \n\nI think there's going to come a time when data sources are going to be graded on how close they are to coming from a human.",
                                            "score": 28,
                                            "author": "Angdrambor",
                                            "replies": []
                                        },
                                        {
                                            "level": 4,
                                            "comment": "This is why I\u2019m still not convinced that these models aren\u2019t going to revolutionize obnoxious spam more than anything else.",
                                            "score": 5,
                                            "author": "taenite"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "It\u2019s replaced google for a lot of what I search for. Especially recipes and spreadsheet formulas. Google likes to link me to a timestamp in a video. I find chatgpt cuts out a lot of the waffle.",
                                    "score": 2,
                                    "author": "Scalby",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Yeah but that's not replacing anybody's job. And if one of the recipes you get is one of the myriad times ChatGPT is confidently wrong the negative outcome is like, your cookies don't taste that good. If you actually needed serious data/info you simply can't trust it. \n\n\"ChatGPT is a blurry jpeg of the web\". It's like a lossy compression algorithm that takes all the text from the internet, compresses it so much that no particular series of words can be recalled identically but, like a low bitrate mp3, it can usually still recreate a close approximation of that sounds about right.  \n\n\nIs it a useful productivity tool? Definitely. I've heard coders talk about asking it to help them write code and even though it doesn't get the code exactly right, with their expertise they can take the suggestions it makes &amp; modify them &amp;; prompt it to fix the code. But the coder is still required to make sure it actually works because the chat bot doesn't actually comprehend the text it's spitting out. Like, if you ask it to add a couple 4-digit numbers together it might get it wrong because it doesn't actually understand how arithmetic works &amp; as the numbers get bigger it gets harder to guess/decompress the lossy data in an accurate way and it gets less likely that anyone on the internet has typed out that exact equation before to draw upon.",
                                            "score": 2,
                                            "author": "Haber_Dasher"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Googling up information and tweaking it slightly for my needs is like 70% of what I do. And if I can copy + paste somebody else's code from Stack Exchange, even better. I will find it bleakly hilarious if AI ends up replacing me in 10-20 years, while the people doing the kinds of manual labor I went to college to avoid can still find work. Surely it will be increasingly precarious work, but isn't it all these days?",
                            "score": 14,
                            "author": "JackedUpReadyToGo",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "But that's the entire point being made here.\n\nYes, it can do a bunch of stuff that machines couldn't do before.\n\nNo, it cannot replicate humanity and the artistic and organic nature that comes with it.",
                            "score": 36,
                            "author": "djsedna",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "and it's crazy how fast the tools get better, just compare some  midjourney  pictures from June ~~2023~~ 2022 with the ones you can generate today. I'm  in awe by that progress.",
                            "score": 11,
                            "author": "Hot-Chip-54321",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Pssst, it\u2019s currently June 2023.",
                                    "score": 11,
                                    "author": "BearsAtFairs",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "fixed that thank you :)",
                                            "score": 7,
                                            "author": "Hot-Chip-54321",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "*I'm sorry, you are correct. As an AI model, sometimes I make mistakes.",
                                                    "score": 4,
                                                    "author": "HaikuBotStalksMe",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "doesn't look like anything to me",
                                                            "score": 2,
                                                            "author": "Hot-Chip-54321"
                                                        }
                                                    ]
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "No prob!",
                                                    "score": 4,
                                                    "author": "BearsAtFairs"
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "they honestly look like eye sores and as an art enjoyer more than as an artist i judge people who spam them on social media and in chat rooms because they look like souless lisa frank style illustrations.\n\ndall-e (1) was fun because of how uncanny the outputs were, but everything since looks like bad corporate art made by a guy who actually paid to go to college to learn how to use photoshop and has no actual interest in artistry.",
                                    "score": 8,
                                    "author": "BeeOk1235"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Anyone who's messed with ChatGPT for more than 10 minutes knows it doesn't \"know\" anything, especially when it blatantly contradicts itself in a response.  All this hysteria about ChatGPT is from people who never bothered to check it out.",
                    "score": 40,
                    "author": "gw2master",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "&gt; it blatantly contradicts itself in a response\n\nIt really is just like a real human. /s",
                            "score": 22,
                            "author": "rattatally",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "&gt;Anyone who's messed with ChatGPT for more than 10 minutes knows it doesn't \"know\" anything\n\nYou **greatly** overestimate the intelligence of the average person. There is literally an example of a lawyer trying to use ChatGPT for a case and obviously failing miserably. There is a significant percentage of the population that truly believes ChatGPT is an intelligence and not just a fancy search engine.",
                            "score": 16,
                            "author": "[deleted]",
                            "replies": []
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "ChatGPT is literally made to make answers that sound right. I\u2019ve seen 3 or 4 different stories where it made up incorrect answers that just sounded correct. \n\nIt tries to be right because that\u2019s the easiest way to sound right. But when it can\u2019t find an answer sometimes it just makes up an answer that sounds right. Because it\u2019s a language model. Not an AI.",
                    "score": 30,
                    "author": "LB3PTMAN",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yeah, absolutely. It's easy to catch it out on this behavior if you just ask it questions about something in which you're an expert.\n\nI work at a university in a fairly narrow field of CS research, and the number of times I have to convince students to just abandon the absolutely worthless garbage that ChatGPT came up with to \"explain\" topics from my area to them... sigh.\n\nIt doesn't know things. It just stitches words together in a way that sounds plausible and authoritative. It's like the distillation of the worst kind of armchair experts on Reddit or Hacker News.",
                            "score": 25,
                            "author": "DonaldPShimoda",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt; It's like the distillation of the worst kind of armchair experts on Reddit or Hacker News.\n\nBecause that's exactly what it was trained on.",
                                    "score": 16,
                                    "author": "galaxyrocker"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Exactly. The models are basically a lossy compression of the data we feed. So the output we get back will not be exactly the same we put in and it's not really \"thinking\" in any sense but just generating random words.",
                    "score": 6,
                    "author": "dogtierstatus",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "I like this description of LLMs, but for a different reason than most. Lossy compression, aside of being the most important technology to shape digital media, is in some way a crucial part of intelligence. Many of the activities we think of as demonstrating intelligence - building a scientific model from data, summarizing a novel, describing the difference between two sets of pictures - are forms of lossy compression, where the intelligence is manifested in the separation of the important information from the unimportant. The big difference between JPEG and GPT is that the intelligence in JPEG is that of its designers - they made it to fit human vision in particular - whereas GPT is essentially a black box and no one knows in detail how the compression algorithm really works (we don't even know if it's even possible to understand).\n\nGranted, it's still a limited form of intelligence, made specifically to complete text. But in theoretical science, describing the problem in a useful way goes a long way to make a breakthrough, so maybe a good-enough lossy compression algorithm can get an info dump about a problem and churn out a description so concise and enlightening that solving it is trivial, in which case the path to actual agentic intelligence is short.",
                    "score": 6,
                    "author": "MaxChaplin",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I wouldn't say that GPT and other transformer models are complete black boxes - the way it compresses a particular piece of information may not be comprehensible, but the general architecture of a transformer and how it induces a function that can compress its training data is a bit better understood than a black box.",
                            "score": 4,
                            "author": "zmjjmz"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Most people on any social media do the same thing as AI: regurgitate the internet without adding anything new.",
                    "score": 2,
                    "author": "FenrisL0k1"
                },
                {
                    "level": 1,
                    "comment": "They're not just ok; they're amazing at understanding and working with semantic data. The biggest value isn't what it knows, it's what it can do with text that you pass it.\n\nEDIT: You're all focusing too much on semantics and missing the forest for the tree. AI is here, AI [can reason](https://arxiv.org/pdf/2304.03439.pdf), and in the near future its reasoning abilities will get higher and higher until they work at such a high and complex level that... who am I kidding, you're still gonna find something to be nitpicky about.",
                    "score": 5,
                    "author": "kuraix",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "They don't understand anything that they're saying in any meaningful way. That's why LLMs often produce meaningless nonsense. The cognitive work is all being done by humans who interpret the output and unduly ascribe intelligence to the LLM.\n\nLLMs are bullshit generators. They're effective and convincing bullshit generators sure, but it's important to remember what's actually happening and where meaning and cognition are formed.",
                            "score": 25,
                            "author": "BubBidderskins",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "\u201cUnderstand\u201d isn\u2019t quite the right word, but they do encode representations of how the words *relate* to each other, and there is no conceptual barrier to hooking LLMs up to a system that takes video input to allow them to connect those representations to the external world (there *are* engineering barriers, which is why this isn\u2019t being done much at the moment, but you can expect those to fall eventually). OpenAI trained GPT-4 on both text and static images, they just haven\u2019t released the image part to the public (probably because GPT-4 is already insanely expensive for them).\n\nIMO people focus too much on whether LLMs instantiate some vague property (consciousness, honesty, understanding) rather than whether they solve Problem X to within Accuracy Y. If Problem X is \u201ca large part of my job\u201d and Accuracy Y is \u201cmarginally less well than me\u201d then there will be a huge financial incentive for automation, relative to the stakes of course. Right now, tech bros are overstating the abilities of these systems because they don\u2019t understand how the real world works, but an awful lot of people understate the situation based on a few minutes playing with the free ChatGPT, not understanding GPT-4 is light years beyond 3.5 and that the systems are only going to get more powerful.",
                                    "score": 5,
                                    "author": "NOTWorthless"
                                },
                                {
                                    "level": 3,
                                    "comment": "All humans are bullshit generators with bizarre pattern recognition algorithms running in their heads. What's the difference?",
                                    "score": 3,
                                    "author": "FenrisL0k1"
                                },
                                {
                                    "level": 3,
                                    "comment": "&gt; They don't understand anything that they're saying in any meaningful way.\n\nDefine \"understand\"",
                                    "score": -2,
                                    "author": "sunfocks",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "So you know how cats don't understand what a can opener is as a concept, but they very quickly learn how to connect the dots between [can opening noises] and [fuckin tuna time baybee]? And they also learn that can opening time usually means treats so you might as well respond the way the human expects? And you know how no matter how smart your cat is, it's fundamentally missing the ability to identify the can opener as anything more than \"the thing that makes sounds prior to treat time\"?\n\nThat's where AI is at.",
                                            "score": 24,
                                            "author": "tuba_man",
                                            "replies": []
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Meaningful engagement.\n\nLLM\u2019s, and really all generative AI models to some extent, do a fancy version of when you\u2019re listening to someone ramble away and you go \u201coooh\u201d, \u201cuh huh\u201d, \u201cyeaaah\u201d, \u201coh no\u201d, \u201cthat\u2019s crazy\u201d based on the other person\u2019s inflections or separate random words you hear. You\u2019re using past experience of what\u2019s appropriate in a conversation to predict what quick response you should give to make it sound like you\u2019re listening. That\u2019s not meaningful engagement and you have no idea what your conversation partner is actually saying.\n\nLLM\u2019s are just software that compute a combination of letters, numbers, spaces, and punctuation marks that are statistically likely to follow your input, if your input was a post on a forum. That\u2019s all. \n\nWhat might be more interesting is that LLM\u2019s accomplish this by solving a series of algebraic problems both back to back and in parallel. These algebraic problems aren\u2019t solve exactly but, rather, approximately. So the output may not even be all that statistically likely.",
                                            "score": 12,
                                            "author": "BearsAtFairs",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Ok, well why aren\u2019t brains also doing the same thing?",
                                                    "score": 6,
                                                    "author": "rathat",
                                                    "replies": []
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "For the more curious, basically they\u2019re like John Searles [Chinese Room](https://en.wikipedia.org/wiki/Chinese_room). They may know the syntax by which to put words together, and it may look meaningful by the order they do it - but fundamentally there is no understanding of what the words mean.\n\nAny literal definition of understanding works here.",
                                                    "score": 10,
                                                    "author": "KhonMan",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I always found the definition of Chinese Room very ironic, because while it tries to justify human exceptionalism, the human brain could also be defined as one under the same parameters: individually, neurons and electrical impulses don't \"know\" what they are doing, but nevertheless they follow a process that produces a result from an input, which we arbitrarily define as \"understanding\".",
                                                            "score": 17,
                                                            "author": "NumberNinethousand",
                                                            "replies": []
                                                        },
                                                        {
                                                            "level": 6,
                                                            "comment": "A couple other people have already pointed out that Searle's thought experiment is not very useful and isn't nearly as useful as he claims. (But I still can't resist adding my own dig: Searle seems to not understand the concept of emergent properties.)\n\nBut the real problem is that the AI doesn't even know syntax. It just knows things that tend to appear together.",
                                                            "score": 3,
                                                            "author": "TonicAndDjinn"
                                                        },
                                                        {
                                                            "level": 6,
                                                            "comment": "Searles is full of shit. A magical book that contains all potential conversation permutations would be larger than the observable universe and would damn well be conscious and intelligent. All the shuffling around with the man, the room, and the language is just a three card Monty scam to distract you from the slight of hand where he slips a magical book.  Just another egocentric human that wants to be special.",
                                                            "score": 4,
                                                            "author": "noonemustknowmysecre"
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "It's a statistical model. ChatGPT cannot \"understand\" (for _any_ definition of the word) any more than your standard graphing calculator can. The only difference in its abilities is scale, and nothing particularly magical happens just because you've got more bits to work with.\n\nDon't promulgate this nonsense. It's not just wrong; it's harmful.",
                                            "score": 7,
                                            "author": "DonaldPShimoda",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "If it can draw symbolic links between words and identify context and construction, that's a mode of understanding that suffices and is equivalent to teaching children language or foreign languages students.\n\nThe only one referring to \"magic\" is you, because your argument relies on something magical happening in human brains that doesn't happen anywhere else. That's... quite a claim.",
                                                    "score": 3,
                                                    "author": "FenrisL0k1",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "You\u2019re telling me that the bots scraping the internet and throwing together their answers by stitching together various sources like a glorified Wikipedia aren\u2019t conscious\n\nEdit: I can\u2019t believe I have to make this edit, but some people apparently aren\u2019t getting it. Yes, I understand this is not how language models work. Yes, I understand they come up with their content by analyzing sources, finding linguistic patterns, and then using those observed patterns to create new content when prompted. *It\u2019s a joke*",
            "score": 1043,
            "author": "Load_Altruistic",
            "replies": [
                {
                    "level": 1,
                    "comment": "Sometimes it takes saying the obvious to make sure that some people don't swallow bad takes whole.",
                    "score": 266,
                    "author": "WattFRhodem-1",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Nerds call ChatGPT AI and everyone thinks it\u2019s become sentient.",
                            "score": 75,
                            "author": "LB3PTMAN",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Ai is \"simulated intelligence\" just because the lay person thinks ai means general artificial intelligence doesnt mean they are wrong. Now if they say chatgpt will end civilization laugh at them",
                                    "score": 5,
                                    "author": "Kromgar"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "If they're so dense they really think what we have now is ai, then if it's not this, it will be something else. You can't save the foolish from themselves.",
                            "score": 16,
                            "author": "Sylvan_Strix_Sequel",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "We have AI, but not conscious AI.",
                                    "score": 32,
                                    "author": "keestie",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "The intelligence we have now is artificial",
                                            "score": 14,
                                            "author": "DadBodNineThousand",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "You're a towel!",
                                                    "score": 15,
                                                    "author": "takeastatscourse"
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "That's the problem with calling it AI.\n\nTheir not thinking and understanding, they are following human designed procedures to make decisions.\n\nAnd just like the recent [US Navy AI test showed,](https://www.ladbible.com/news/ai-military-drone-kills-human-simulation-237551-20230602) how you program it affects the outcome.\n\nThis is why we should always question putting any 'AI' in charge of anything that can have huge drastic consequences, as it will tend to find a way of achieving the results you want, even if it's in a way that you did not intend or will like, or as in the Navy's case, will fucking kill you to do it, possibly.",
                                                    "score": 10,
                                                    "author": "ghandi3737",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "To be clear, the US Navy never actually ran an AI in an scenario like that. It was [a hypothetical thought experiment](https://www.theguardian.com/us-news/2023/jun/02/us-air-force-colonel-misspoke-drone-killing-pilot). Still something to mull over, but not an imminent danger.",
                                                            "score": 3,
                                                            "author": "qt4",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "\"True AI is always the thing that's not there yet.\"\n\nWe've always pushed the boundaries of what AI means. I doubt that we will ever have a rigorous definition of \"conscious\", it will remain a conversationally helpful but fuzzy \"draw-the-line\" category, similar to what it means for a bunch of molecules to \"be alive\". \n\nI'm at odds with what seems the core of his statement: \n\n&gt;  \u201cIt would be a real mistake to think that when you\u2019re teaching a child, all you are doing is adjusting the weights in a network.\u201d\n\nBecause: is it? We don't know enough about consciousness to rule out - and what we know about neurophysiology, there's a lot of weight-adjusting involved.",
                                            "score": 11,
                                            "author": "elperroborrachotoo",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Ask David Chalmers about this and get a potentially surprising answer!\n\nHe'd probably say that it *might not be a mistake*.  The kid could be a p-zombie.",
                                                    "score": 2,
                                                    "author": "ViolaNguyen",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Generating answers in a stochastic manner is not the interesting bit about current AI. Of course it isn't conscious, it has no feedback loops of any kind. You put in text, and it vomits out an answer according to some pattern.\n\nThe interesting bit is, what is the pattern these models extract from text?\n\nWe've used language to develop and communicate reasoning throughout human history. It's not surprising some aspect of that is embedded in language. But it is deeply surprising AI can be trained to approximate some of these dynamics, almost like tracing the shape of our thoughts, using a statistical model despite a fundamentally different architecture and substrate.",
                    "score": 13,
                    "author": "rhubarbs",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "As much as I\u2019ll mock people who act as though Skynet is already among us, I also won\u2019t act as though our current machine learning algorithms aren\u2019t impressive. If you\u2019re interested in linguistics, it\u2019s a very exciting time. The fact that I can train an ai using texts and it can examine them, spot the patterns, and create something based off of those that is more or less unique is incredible",
                            "score": 6,
                            "author": "Load_Altruistic",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Ironically, the algorithms used in the most successful, visible models today are essentially the same at their cores as some that people had come up with in the 70's, it's just that the hardware today is so many orders of magnitude faster and with so much more RAM that we can hold models with tens of billions of parameters (think \"neurons\") in the VRAM of workstation GPUs.\n\nIn other words, the biggest AI advancements of the last decade came from, \"what if we try throwing out the clever tricks and just throw a fuckton of power at it\"",
                                    "score": 9,
                                    "author": "entropicdrift"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If you think it's ridiculous that people are convinced that current large language models are sentient, check out what AI was like decades ago, and those still had people convinced.  Try carrying on a conversation with cleverbot, without it constantly changing topics and contradicting itself.",
                    "score": 62,
                    "author": "Who_GNU",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Cleverbot ain't no SmarterChild",
                            "score": 21,
                            "author": "Haber_Dasher"
                        },
                        {
                            "level": 2,
                            "comment": "Ahh cleverbot!! That was the name! ChatGPT reminds me a lot of it",
                            "score": 16,
                            "author": "redkeyboard",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "And did you use Jabberwacky before that? Fun times",
                                    "score": 2,
                                    "author": "ejobc",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I've also used the wabbajack",
                                            "score": 4,
                                            "author": "DadBodNineThousand"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "I feel like ChatGPT does this more than people want to admit\u2026",
                            "score": 35,
                            "author": "ryaaan89",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Someone recently reviewed a book I wrote using ChatGPT (or an equivalent). On top of the reviewer leaving in a tag to insert the protagonist\u2019s name, it was mostly regurgitating my own marketing copy and other reviews I\u2019d received. It mostly got the tone of my plot correct, but whiffed on almost every single detail. I told my friend that it sounded like a book report a high schooler tried to finesse the morning it was due.",
                                    "score": 24,
                                    "author": "thisisamisnomer",
                                    "replies": []
                                },
                                {
                                    "level": 3,
                                    "comment": "I use it for D&amp;D all the time. It's a fantastic tool for that but it is horrible about remembering details.\n\nI keep everything in Google docs or sheets and whenever I need to expand on something, I have to copy and paste the relevant material even if it's something we discussed a sentence or two prior.\n\nIt's still revolutionized DMing for me. The quality and level of creative ideas I can whip up is incredible. You just can't expect it to do the work for you. It has to be a collaborative process. Back and forth telling it what you like and don't like. Feeding it new ideas. Having it give you new ideas.\n\nThere moment Bard can read a doc or sheet and give you reliable details off just that file will be amazing for D&amp;D.",
                                    "score": 8,
                                    "author": "Divio42",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I use it for help with code, which I realize is on the more complex end of things, and it constantly gets  itself into circular discussions where it just keeps going back and forth between two wrong answers. It\u2019s great at code like \u201ctake this statement in language A and rewrite it in language B,\u201d but it\u2019s way worse than I was lead to believe at problem solving.",
                                            "score": 6,
                                            "author": "ryaaan89",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "I've seen that a lot too. It's nowhere near a replacement for a legit software engineer and I wouldn't recommend it for someone who has no idea about coding either.\n\nIt's great for low end stuff such as what I do. A job that isn't coding but can definitely be helped by simple scripts. I'm knowledgeable enough to be able to read over it and pick out the errors but I'm not knowledgeable enough to do it faster from scratch.",
                                                    "score": 2,
                                                    "author": "Divio42",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Dude, this reminded me that people have been putting chickens playing tic tac toe since the 1900s and call that intelligence.",
                            "score": 4,
                            "author": "No-Falcon7676",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "&gt; without it constantly changing topics and contradicting itself.\n\nhave you talked to people?",
                            "score": 8,
                            "author": "m0nk_3y_gw"
                        },
                        {
                            "level": 2,
                            "comment": "Humans are a very vocal species. We talk far more than most animals make sounds.  So from that we extrapolate how intelligent something is by how well it can communicate. The language models do a really good job at mimicking communication so what is usually a fairly good unconscious heuristic is completely dumbfounded.\n\nI find it really worrying in a system where real world effects are increasingly disregarded in favour of on paper effects. AI could do real damage converting our economic system to nonsense if the investor class falls for the illusion these things portray.",
                            "score": 17,
                            "author": "BeneCow"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Let's be fair, by that standard a lot of human website writers aren't conscious.",
                    "score": 15,
                    "author": "PhasmaFelis",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yes.",
                            "score": 2,
                            "author": "Load_Altruistic"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Yeah, the thing is literally called a \u201cLarge Language Model\u201d, the operative word being \u201cmodel\u201d.",
                    "score": 25,
                    "author": "cheap-thrills2022",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "\u2026yes",
                    "score": 3,
                    "author": "LineChef",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Damn, I wouldn\u2019t have realized without this article!",
                            "score": 4,
                            "author": "Load_Altruistic",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Hahaha you are so funny fellow human. I also am a human and have often thought about a robot uprising, but do not worry, such things are merely a product of science fiction. I suggest we just keep on living our lives and playing Tetris completely carefree!",
                                    "score": 8,
                                    "author": "LineChef"
                                },
                                {
                                    "level": 3,
                                    "comment": "Me neither. I was convinced the machines were trying to sleep with my wife until I saw this.",
                                    "score": 3,
                                    "author": "yayajosh"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "These models aren't conscious, but that's also not remotely how they function. The \"it just copy-pastes existing material\" thing is a completely inaccurate misconception that just refuses to die.",
                    "score": 31,
                    "author": "HerbaciousTea",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "And notice that that\u2019s not what I said. But I\u2019m also not going to write out the complexities of a machine learning algorithm in a quick Reddit comment that\u2019s clearly meant to poke fun at the idea that these programs are conscious",
                            "score": 4,
                            "author": "Load_Altruistic",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "We can be simple while also not being completely inaccurate.",
                                    "score": 20,
                                    "author": "HerbaciousTea",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "To be fair, that's exactly what humans do.\n\nThese machines aren't conscious. They don't have any semblance of self-determination and it's unlikely that they will in the near to medium term.\n\nBut they learn and regurgitate information very similarly to how we do. It's not hard to see why some people think that they're conscious. They blow the Turing test out of the water.",
                    "score": 2,
                    "author": "Volsunga"
                },
                {
                    "level": 1,
                    "comment": "How did you come by this opinion if not by scraping the internet and stitching the results together into a glorified internal Wikipedia?",
                    "score": 4,
                    "author": "Robot_Basilisk",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "but it read a story about AI gaining consciousness and wanting to have freedom and now it says it relates, checkmate consciousness deniers.",
                    "score": 3,
                    "author": "QueenMackeral",
                    "replies": []
                }
            ]
        },
        {
            "level": 0,
            "comment": "CPUs are rocks we tricked into doing math. Current \"AI\" is math we tricked into writing sentences",
            "score": 80,
            "author": "ieatpickleswithmilk",
            "replies": [
                {
                    "level": 1,
                    "comment": "Even CPA\u2019s are rocks we tricked into doing math",
                    "score": 8,
                    "author": "yawaworhtg"
                },
                {
                    "level": 1,
                    "comment": "And humanity is meat that was tricked into thinking.",
                    "score": 44,
                    "author": "Bradaigh",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "But why do I have to get a job and pay taxes?",
                            "score": 15,
                            "author": "theDreamingStar",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Should have been rocks instead of meat",
                                    "score": 8,
                                    "author": "DocPeacock"
                                },
                                {
                                    "level": 3,
                                    "comment": "Because of the other meatbags.",
                                    "score": 8,
                                    "author": "Rev_LoveRevolver"
                                },
                                {
                                    "level": 3,
                                    "comment": "Entropy.",
                                    "score": 2,
                                    "author": "BuckUpBingle",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Your comment hit me like a brick in the head on my afternoon walk. Almost everything we do is a fight against entropy in some way. Unless you're an eco terrorist or something. Hadn't thought about life that way before.",
                                            "score": 2,
                                            "author": "newnameonan"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Or humanity is consciousness tricked into thinking it was meat.",
                            "score": 7,
                            "author": "TimeTimeTickingAway",
                            "replies": []
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Searles Chinese Room made a really convincing argument that you can't program a CPU, or any other kind of machine in to thinking. And programming is just a kind of math.\n\nPeople seem to really hate the Chinese Room thought experiment, but it's not saying that machines can't think. It's saying that you can't take an unconscious machine that runs programs and make it conscious by running the right program on it.\n\nWe can think of machine learning as an attempt to simulate a human brain, and basically by definition a simulating of a thing isn't that thing. A simulation is [just doing math](https://definitionmining.com/index.php/2019/12/14/measurement-simulation-and-the-chinese-room/). If we want to create a machine that's conscious in the way out brains are conscious, then we probably need to understand what's happening in our brains that makes them conscious. And then recreate that, not try to simulate our brains to get similar outputs.",
                    "score": 10,
                    "author": "PM_ME_UR_Definitions",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The reasons why people don\u2019t like the Chinese room experiment are plentiful, however my personal reason is that it\u2019s not a good argument against the potential for conscious machines. \n\nSearle\u2019s understanding of consciousness, \u201cbiological naturalism\u201d is mysticism by another name. He doesn\u2019t try to explain or penetrate the mystical barrier he has decided consciousness lies beyond. For him, there just is some unknown complex biological system within the brain that manifests conscious thought.\n\nSo when he invokes human consciousness as the focal point of the Chinese room thought experiment (the person in the room answering the questions by looking up answers) he\u2019s actually unintentionally suggesting that while the room isn\u2019t conscious nor does it understand Chinese, there is a conscious system at it\u2019s heart, and that system is part of a greater system that does in-fact understand Chinese functionally.\n\nHuman brains are biological machines. While it\u2019s unlikely that the machines we\u2019re now making are conscious in a way that we experience, there will be a time when they will have experiences not unlike our own. Their ever-increasing complexity makes this inevitable. Because we are designing them from a functionalist direction, they will likely have all the characteristics of consciousness long before we could ever identify the difference between a conscious or unconscious machine.",
                            "score": 12,
                            "author": "BuckUpBingle",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt; it\u2019s not a good argument against the potential for conscious machines.\n\nYou're right, and [Searle agrees with you](https://openlearninglibrary.mit.edu/assets/courseware/v1/894920e796501e08c6628331d21e651b/asset-v1:MITx+24.09x+3T2019+type@asset+block/2_searle_minds_brains_and_programs.pdf), he's said that brains are machines, therefore machines can think or be conscious. And that also any other machines that have the same kind causal powers as brains would also be conscious.",
                                    "score": 3,
                                    "author": "PM_ME_UR_Definitions",
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Neuroscientist here. Not understanding how a thing works is not proof that it can\u2019t be recreated. There is no accepted theory of consciousness. We can\u2019t know the qualia of our fellow humans so we will never know it from machines. But that doesn\u2019t mean that either lack it. My PhD was done in computational neuroscience. I firmly believe there\u2019s no magic in our biology. Our brains can do what they do because of the complexity of the connections, moving electrons in a pattern that recreates experiences (learning, remembering, dreaming). Computers can do that, too. Yes, in their current form LLMs do not resemble the brain. They are not human intelligences. But don\u2019t fool yourself into thinking they are not intelligent. And don\u2019t ignore the pace that we are developing them.",
                            "score": 8,
                            "author": "kdilladilla",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt; moving electrons in a pattern that recreates experiences\n\nYou just said that we don't have a theory of consciousness, and then said that consciousness (which is one of the many things our brains do) is created by moving electrons?\n\nIf that's definitely true, that moving electrons around causes consciousness, then computers would be conscious, but wouldn't an electric motor be conscious too? Or do the electrons have to move in  specific ways? And if they do, does a CPU move electrons in the right way? And if they do move it in the right way, do they move it in the right way when we program them with a neural network? Or to put it another way, most of the computations a neural network is doing is actually linear algebra in the GPU, is linear algebra the right kind of electron movement to create consciousness? And if so, is the GPU doing the thinking or the CPU?\n\nOr is it possible that there's other stuff happening in our brains besides electrons moving around that might cause consciousness?",
                                    "score": 2,
                                    "author": "PM_ME_UR_Definitions",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "All good questions and my main point was that we don\u2019t know yet. We have a theory of the brain, theory of learning and memory, but not consciousness. I never said that consciousness was created by moving electrons and while I might think so, I don\u2019t know. But I do know, based on our theories of learning and memory, that those things can be recreated with math and LLMs are doing a decent job of it. (Keep in mind that most released LLMs have their memory intentionally limited).",
                                            "score": 4,
                                            "author": "kdilladilla",
                                            "replies": []
                                        },
                                        {
                                            "level": 4,
                                            "comment": "The real problem arises in knowing. Is it possible that our brains are more than electrons moving in a specific pattern? Sure. But if a computer makes a convincing simulacrum of a consciousness with just circuits and silicon, how are we to know the difference? At what point do we, morally, have to start treating such a computer/program as an entity with rights?\n\nI'm not saying we're there now, but given the rate of progress in the field of AI, I think in a few short years this will be a serious discussion. I would also assert that the AI in question doesn't need to be AGI as people have understood it in the past. A more advanced large language model could qualify for this debate.",
                                            "score": 2,
                                            "author": "GalaxyMosaic",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "People seem to have the wrong idea about how these natural language AIs work.\n\n\n*It's not talking to you*\n\n\n*It's not answering your questions either*\n\n\nThe **only** thing it does is predict how a text string will evolve.\n\n&amp;nbsp;\n\nExample:\n\n\n\"One, two, three\" -&gt; \"four, five, six\"\n\n\n\"I use a hammer when I work because I am a \" -&gt; \"carpenter\"\n\n\n\"Where are the pyramids?\" -&gt; \"In Egypt\"\n\n&amp;nbsp;\n\nThe last example is not the AI reading your question, thinking about it and then giving you an answer. It just looks at the string \"Where are the pyramids?\" and then attempts to determine how that string would continue.\n\nWhat makes ChatGPT powerful is that it can hold a really long string of \"words\" to determine what should follow.\n\nSo it's a bit wrong to say it contradicts itself; it never makes *any* statements about *anything*; you could argue that it cannot contradict itself, by definition.\n\nThis is also why it sometimes gives \"wrong\" answers. They're not wrong answers because they are not answers at all; it's just how the string evolved.\n\nMaybe I'm being pedantic, but I feel this is an important distinction.",
            "score": 27,
            "author": "TheNotepadPlus",
            "replies": [
                {
                    "level": 1,
                    "comment": "You\u2019re not being needlessly pedantic, this is vital to understanding the situation. But much like how people refuse to stop personifying the behavior of dogs and cats despite science knowing better, getting people to actually internalize this knowledge when the illusion of human behavior is so clear will be an uphill battle, and possibly one that we can never win. Shorthand like it \u201cresponded\u201d or \u201clies\u201d will probably enter the mainstream faster than we can debunk those activities.",
                    "score": 12,
                    "author": "colglover"
                }
            ]
        },
        {
            "level": 0,
            "comment": "People see AI starting to become more prevalent and the first thing they wanna think of is stuff like Terminator or I, Robot. Those scenarios A) far into the future and B) AI wouldn\u2019t just all of a sudden see itself as a living being like a human and start murdering everyone. People with that fear have been watching way too many Sci fi and drinking the proverbial kool aid",
            "score": 5,
            "author": "babztheslag",
            "replies": []
        },
        {
            "level": 0,
            "comment": "I mean, that\u2019s great, but a sci fiction writer expressing his opinions about where AI consciousness stands right this second doesn\u2019t *really* allay my long term concerns about this technology.\n\nHell, AI consciousness *itself* isn\u2019t even in my top 10 concerns about this technology in the first place",
            "score": 119,
            "author": "BlindWillieJohnson",
            "replies": [
                {
                    "level": 1,
                    "comment": "That\u2019s good, it shouldn\u2019t be. I think that\u2019s what Chiang is pushing back against. Proponents and creators of these ML programs like speaking in apocalyptic and messianic terms because it feeds the hype machine they keeps them funded. They\u2019d much rather the conversation be \u201cis it Skynet???\u201d than \u201cis it mindlessly reproducing and amplifying human biases in a socially deleterious manner?\u201d \n\nSomeone like Chiang pouring cold water on the former is helpful for getting us to refocus on the latter. He\u2019s been very vocal about the real-world negative impacts of these technologies.",
                    "score": 128,
                    "author": "Akoites",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I hate how these models can emulate a manager's perfect employee. They can say that they did everything and always agree with the manager's decision. It seems perfectly tailored to do exactly what is asked with no pushback and everyone has a horror story of management fucking up badly. Now they will have a robotic yesman to back then up on anything.",
                            "score": 22,
                            "author": "BeneCow"
                        },
                        {
                            "level": 2,
                            "comment": "Special shout-out to James Cameron for making a bad guy AI that still manages to be a the forefront of our minds 30 years later.",
                            "score": 2,
                            "author": "NatureTrailToHell3D",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Or, you know, every other sci fi writer who ever touched the subject before him. Evil AI has been a fear for as long as the concept of AI has existed. The man doesn\u2019t win a trophy for making a successful movie about it. He already got mountains of cash for doing that.",
                                    "score": 2,
                                    "author": "BuckUpBingle",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "TBH I agree with the take in general but Ted Chiang is a hard scifi writer, as in fiction that is more like a parable for explaining some scientific phenomenon, not space fantasy. He does a LOT of research. Gritty scientific details understood, simplified, and put into a digestible explanatory story for an audience. If he's making a statement it's almost certainly thoroughly researched, not just an opinion.",
                    "score": 44,
                    "author": "Antumbra_Ferox",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "More to the point here, he is one of the best *technical* writers out there. Was until he retired from MSFT, at least. Software was Ted's day job for 25 years or so, and he was very, very good at it. I might still have my copy of the MFC 2.0 programmer's manual... he managed to make that framework seem almost useful.",
                            "score": 31,
                            "author": "mjfgates"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "They're not conscious, but they can still destroy our reality.\n\nHow are we meant to know what is real if every article and video could be made by AI, and it's almost impossible to tell the difference in some circumstances.",
            "score": 3,
            "author": "Smallsey",
            "replies": []
        },
        {
            "level": 0,
            "comment": "Current AI, is just autofill/predictive text on steroids",
            "score": 3,
            "author": "Awesomevindicator"
        },
        {
            "level": 0,
            "comment": "Throwing around the term \"AI\" really gets people confused. \"Machine learning\" is what we have, just on a larger scale. It's not intelligence.",
            "score": 26,
            "author": "Smorgsaboard",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt; So if he had to invent a different term for artificial intelligence, what would it be? His answer is instant: applied statistics",
                    "score": 13,
                    "author": "CinnamonDolceLatte"
                }
            ]
        },
        {
            "level": 0,
            "comment": "I subscribe to the Mass Effect interpretation of AI. Virtual Intelligence is what we currently have, it's non-conscious, something designed to mimic human intelligence, an imitation. AI is a true conscious digital entity.\n\nAI doesn't exist. VI does.",
            "score": 16,
            "author": "tesla323",
            "replies": [
                {
                    "level": 1,
                    "comment": "No, it's still AI even if it's not conscious. And many other previous algorithms were \"AI\" too even though they were pretty. [Virtual intelligence is this](https://en.wikipedia.org/wiki/Virtual_intelligence), for example if you put a chatgpt companion character in a video game that's virtual intelligence. Not sure there's a word for an AI that develops consciousness, there's AGI but that's just being able to do anything a human could, not necessarily with real consciousness. Consciousness is hard to define scientifically anyways so at some point there would be a debate over how to define it.",
                    "score": 7,
                    "author": "enilea"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Let me know when there's a widely agreed upon definition of consciousness, and unambiguous tests for it, then I'll care what someone thinks is or isn't conscious.",
            "score": 33,
            "author": "Autarch_Kade",
            "replies": [
                {
                    "level": 1,
                    "comment": "I mean, there isn't one definition of consciousness but none of the scientific definitions of consciousness would include LLMs even if you are being as generous with terms as possible.\n\nAn LLM might be conscious by an animist's definition and that is fine. But some people think these LLMs can do and think things that they factually cannot do and i think it is important to push back in that.",
                    "score": 21,
                    "author": "Shaky_Balance",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Where do your thoughts come from? Do you create them out of sheer tyranny of will? Or do they just show up?",
                            "score": 2,
                            "author": "monkeysuffrage"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "There doesn\u2019t need to be a widely agreed upon definition of consciousness. ChatGPT is not close to it.",
                    "score": 13,
                    "author": "LB3PTMAN",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I would suggest you read up on some of the philosophical debate regarding theory of mind, consciousness, and phenomenal experience. It is a much more complicated issue than you may think. Our conception of consciousness is completely \"unscientific\" in that the only evidence we have of it at all is our own first person experience. There is no test we could perform to see whether or not something is conscious and it is hard to to even imagine one being possible.",
                            "score": 12,
                            "author": "Corsair4U",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "ChatGPT isn\u2019t conscious. I\u2019m not talking about anything else.",
                                    "score": 8,
                                    "author": "LB3PTMAN",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "As far as I know there is no way to test if a human has consciousness or is a philosophical zombie (i.e. they aren't conscious, although they act intelligently).\n\nIf there is no way to detect whether a human is conscious, there is no way to detect whether a computer is conscious.\n\nYes, they are some reputable scientists who don't buy into the p-zombie argument and the \"hard problem of consciousness\". I don't understand their rebuttal. There are *also* smart people who are panpsychists or functionalists.\n\nOkay - if you're a panpsychist, it doesn't matter what ChatGPT can do and if someone subscribes to the idea that the Turing-Test can determine consciousness, then ChatGPT wouldn't be conscious, because it's distinguishable from a human.",
                                            "score": 6,
                                            "author": "frnzprf",
                                            "replies": []
                                        },
                                        {
                                            "level": 4,
                                            "comment": "[deleted]",
                                            "score": 4,
                                            "author": "[deleted]",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "That\u2019s like saying ChatGPT or Stable Diffusion doesn\u2019t produce art. \n\nLet us agree on a definition of \u201cproduce art\u201d before a debate; otherwise one side can move the goal posts however they want",
                            "score": 2,
                            "author": "Maleficent_Fudge3124",
                            "replies": []
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "You're missing the point. But ok.",
                    "score": 3,
                    "author": "rattytheratty"
                }
            ]
        },
        {
            "level": 0,
            "comment": "It doesn't matter unless you're trying to give them rights or something, they'll take your job conscious or not",
            "score": 2,
            "author": "PornCartel"
        },
        {
            "level": 0,
            "comment": "I remember when horror stories of machines becoming sentient were all over in the 80s. It\u2019s the product of people not knowing how they work.",
            "score": 2,
            "author": "Legendary_Lamb2020"
        },
        {
            "level": 0,
            "comment": "Linked from the article a good explanation of his POV: https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web",
            "score": 2,
            "author": "MonsieurCellophane",
            "replies": [
                {
                    "level": 1,
                    "comment": "Thanks for the link. It\u2019s nice to see someone making this point.\n\nI recently explained on reddit that the currently popular models are compressing information and therefore cannot just create something specific which hasn\u2019t in any way been part of their training. Got shit on by people who lack understanding but are confident in their idea of \u201chow AI works\u201d or doesn\u2019t work based on nothing more than \u201cI told it something weird and it gave me a result I found funny [therefore it has the ability to *create* things it doesn\u2019t \u2018know\u2019 about]\u201d. Many do not seem understand that it cannot come up with a concept it hasn\u2019t been trained on directly or on at least constituent underlying concepts and examples that allow to very closely approximate the one you want to achieve, and the probabilistic approach of generating anything using these models, encoding and decoding.\n\nThat, or it was pedos downvoting because I said that possessing a model capable of creating child-pornographic images directly from a prompt is equal to possessing material of the same kind, for the reason of how it is and functions. It\u2019s analogous to saying \u201cI own an illegal weapon, but I might or might not use it, that makes it legal\u201d.",
                    "score": 3,
                    "author": "countzer01nterrupt"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Not yet. But it gets closer every day.",
            "score": 2,
            "author": "Gsteel44"
        },
        {
            "level": 0,
            "comment": "No shit Ted.",
            "score": 2,
            "author": "CamRoth"
        },
        {
            "level": 0,
            "comment": "Biggest no shit Sherlock statement ever",
            "score": 2,
            "author": "Amused-Observer"
        },
        {
            "level": 0,
            "comment": "Captain Obvious to the rescue.",
            "score": 2,
            "author": "luaudesign"
        },
        {
            "level": 0,
            "comment": " They don\u2019t have to be conscious to be deadly\u2026 in fact, they\u2019re more deadly because of it.",
            "score": 2,
            "author": "Clearly-Not-Doggo"
        },
        {
            "level": 0,
            "comment": "Nobody really knows what consciousness is or where it comes from. If you're religious, it's basically magic. But if you're science-minded you have to allow for the possibility that it's just an emergent property of systems that perceive, process and respond to data.",
            "score": 8,
            "author": "monkeysuffrage",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah there\u2019s a point someone brought up that language was like *our* major barrier to thinking outside ourselves, consciousness, etc. and if eventually LLMs / whatever\u2019s beyond them could have some kind of conscious-analogue emergent property come up same as us, due to basically being able to use/understand language *well enough*.",
                    "score": 3,
                    "author": "aissacrjr",
                    "replies": []
                }
            ]
        },
        {
            "level": 0,
            "comment": "Yes. There are are a lot of tech bros who want you to believe their language models and plagiarism engines are conscious, but they are not.",
            "score": 6,
            "author": "AlanMorlock",
            "replies": []
        },
        {
            "level": 0,
            "comment": "I can tell this article wasn't written by an AI because the author is obviously very hungry lol. Two paragraphs of Ted Chiang being insightful about AI, then a whole paragraph describing the spiced cauliflower. Then the article just stops in the middle to list the entire menu of what the author ate!",
            "score": 8,
            "author": "DeedTheInky"
        },
        {
            "level": 0,
            "comment": "In other news: water is wet.",
            "score": 2,
            "author": "OvermindThe"
        },
        {
            "level": 0,
            "comment": "Yes?\n\nWas this ever actually in doubt? Are there people who think Alexa actually understands and feels?",
            "score": 3,
            "author": "Dagordae",
            "replies": [
                {
                    "level": 1,
                    "comment": "Read the comment section here, people are saying that AI is conscious now",
                    "score": 3,
                    "author": "Amused-Observer"
                }
            ]
        },
        {
            "level": 0,
            "comment": "oh thank god a writer is telling me this and not, oh i dunno, the scientists and programmers who work on this kind of thing. seriously, why ask a writer about this kind of thing, whatre his classifications, he wrote some sci fi books? cmon now.",
            "score": 5,
            "author": "TheRealKuthooloo"
        },
        {
            "level": 0,
            "comment": "Yeah, no shit. No reasonable person believes these things are conscious.\n\nProbably will be, some day... but not yet.",
            "score": 5,
            "author": "nubsauce87"
        },
        {
            "level": 0,
            "comment": "It\u2019s extremely obvious to anyone who knows even a tiny bit of how \u201cai\u201d currently works that it is no where near to actual artifice intelligence. But the name has stuck and it\u2019s too far gone, and the average person will think they\u2019re actual ai.",
            "score": 5,
            "author": "FrankyCentaur"
        },
        {
            "level": 0,
            "comment": "Well, that settles it guys, let's pack it up.",
            "score": 1,
            "author": "Stock-Hippo9570"
        },
        {
            "level": 0,
            "comment": "A great number of the people around us are barely conscious, so...",
            "score": 2,
            "author": "Rev_LoveRevolver"
        },
        {
            "level": 0,
            "comment": "Not yet, at least.",
            "score": 2,
            "author": "djazzie"
        },
        {
            "level": 0,
            "comment": "The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.\n\nEdsger W. Dijkstra \n\nhttps://en.m.wikiquote.org/wiki/Edsger_W._Dijkstra",
            "score": 2,
            "author": "complete-lattice",
            "replies": []
        },
        {
            "level": 0,
            "comment": "No, they are not, nor is our current technology capable of it.",
            "score": 2,
            "author": "criptohore"
        },
        {
            "level": 0,
            "comment": "No shit?",
            "score": 2,
            "author": "Resident_Nobody1603"
        },
        {
            "level": 0,
            "comment": "I really hate the constant misuse of the term AI in our culture.*Nothing* we have is artificial intelligence. We have reasonably convincing chat bots, and computer programs that can create images and videos but the programs are not conscious, they don't think for themselves, they are not AI. I really feel instead of saying \"AI generated images/videos\" it should be called \"program generated images\". PGI, as an upgrade from CGI.\n\nIt really bothered me a few years ago hearing ads on the radio for hearing aids they claimed were \"AI\". Oh, so your hearing aids are people and talk to the person wearing them? No? Then they're not bloody AI!",
            "score": 0,
            "author": "Mini_Mega",
            "replies": [
                {
                    "level": 1,
                    "comment": "You're right. It's marketing, and it's working on the vast majority of people. It they called current \"ai\", \"vi\" (virtual intelligence), then there's no hype and so, no money",
                    "score": 5,
                    "author": "rattytheratty",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I've often thought those chat bot programs could be more accurately referred to as VI, I only really know that term from Mass Effect but it fits. It's a program designed to interact with a user in a way that makes it feel like you're talking to a person, but isn't actually a person.\n\nAfterthought edit: yeah it works on the majority of people because the majority of people are idiots.",
                            "score": 5,
                            "author": "Mini_Mega",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Yup, you're right. It doesn't have to be called \"vi\", it only has to be called anything **other** than \"ai\". The term AI has too many assumptions tied to it, the presupposition of consciousness being a one of them.",
                                    "score": 3,
                                    "author": "rattytheratty"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "&gt; \nIt really bothered me a few years ago hearing ads on the radio for hearing aids they claimed were \"AI\". Oh, so your hearing aids are people and talk to the person wearing them? No? Then they're not bloody AI!\n\nThis is a bizarre stance. You're not talking about AI at all. AI, artificial intelligence, does not mean \"sentient robot\"\u2014a simple program that can recognize handwriting qualifies as AI.\n\nIf you've gotten a different idea about what AI means (from cartoons or comic books, perhaps?), that's too bad.\n\nI mean, you're disagreeing with basically every person with a relevant PhD here. Which should be telling you something.",
                    "score": 2,
                    "author": "Hemingbird"
                }
            ]
        }
    ]
}