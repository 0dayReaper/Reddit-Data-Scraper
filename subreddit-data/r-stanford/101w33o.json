{
    "id": "101w33o",
    "score": 0,
    "title": "How popular is ChatGPT at Stanford given it's proximity to Silicon Valley?",
    "author": "rocket2913",
    "date": 1672714450.0,
    "url": "https://www.reddit.com/r/stanford/comments/101w33o",
    "media_urls": [],
    "other_urls": [],
    "postText": "Just curious - how many of you use ChatGPT frequently for either of the following use cases:\n\n1. To  better understand concepts in your courses? As in, you converse with  ChatGPT &amp; ask it questions about topics you've learned during a  lecture (to authentically understand the topics better)\n2. To cheat. As in, you don't care/ask chatgpt to explain how it came to conclusions, you just plug in problems &amp; copy.\n\nCurious to hear how popular ChatGPT has gotten with other students on campus across different majors!",
    "comments": [
        {
            "level": 0,
            "comment": "Can't speak for anyone else, but it can be useful when I need a simplified explanation to a complex topic. Won't incriminate myself by answering that 2nd question, but a \"friend\" used it with some success on their final.",
            "score": 11,
            "author": "EntireInflation8663",
            "replies": [
                {
                    "level": 1,
                    "comment": "Have you found that it's worked best for you w/ STEM subjects or more abstract stuff like essay writing?",
                    "score": 1,
                    "author": "rocket2913"
                }
            ]
        },
        {
            "level": 0,
            "comment": "For what it\u2019s worth for the course I TAed we played around with ChatGPT when making the exams to make sure it wasn\u2019t accurate haha (exams were open internet open note). Granted this was a pretty heavy CS course so most of the time even it got things partially right there would be major deficiencies in approach or logic (ergo large gaps from performance benchmarks).",
            "score": 8,
            "author": "allignstaken",
            "replies": [
                {
                    "level": 1,
                    "comment": "Were the questions asking students to write code w/ comments (explaining the logic) and that's the part ChatGPT was messing up? Or was it more CS theory / fundamentals where the answers were in English?",
                    "score": 1,
                    "author": "rocket2913",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Both actually, in implementation it often just didn\u2019t compile but even if tweaked to work would be expressly bad approach-wise. \n\nTheory problems had varied results, it could sometimes point out some high-level concepts. I guess it could be useful in that sense, to get rough pointers for some topics students are lost on.",
                            "score": 3,
                            "author": "allignstaken"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Considering the length of answers chatgpt gives (only short answers), superficiality of its output, concerns about accuracy and deterministic nature, there are very limited cases in which using the bot makes sense for a college student taking appropriately challenging classes. Could change as the bot improves though, especially for stem questions (which it tends to answer better from my own experience).",
            "score": 8,
            "author": "SpinyLemon",
            "replies": [
                {
                    "level": 1,
                    "comment": "Very interesting. So you've seen better performance with more \"deterministic\" subjects like sciences &amp; maths? I assume the poor performance you're referencing then is things like essays about more abstract concepts?",
                    "score": 1,
                    "author": "rocket2913",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Chatgpt explicitly has length limits (try asking it for a 6 page essay for example) that make it pretty useless for college papers. It can\u2019t make citations, which is essential for a college essay. It\u2019s also generally incapable of original ideas, which makes sense because where would it get the data for thoughts not seen before? The bot makes decisions based off likelihood estimations, not actual critical thought.\n\nThe bot does seem to do okay for stem questions in which answers are as you said, more deterministic. It\u2019s very normal in say, math or CS, to have similar code or a proof as someone else. Less common for the humanities",
                            "score": 3,
                            "author": "SpinyLemon"
                        },
                        {
                            "level": 2,
                            "comment": "It fails miserably at any actual math problem. Yes it can recite facts or carry out brain dead problems that require no thinking at all, but even very elementary math is way beyond its capabilities.\n\nExample consider the simple problem: \"If we have a quadratic equation where a = 9b, and b = 3c, and c = 4, for what x is the equation equal to zero?\" \n\nIt just mumbles a bunch of garbage that makes no sense, e.g. in my case it came up  with x = (-34 +/- sqrt(34\\^2 - 4934)) / (29\\*3), but a middle schooler would be able to solve this problem.",
                            "score": 2,
                            "author": "Glapterbep",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt;If we have a quadratic equation where a = 9b, and b = 3c, and c = 4, for what x is the equation equal to zero?\n\nWhat's the correct answer to the question haha? Like what X makes the equation equal zero?\n\nFrom my understanding, ChatGPT isn't like a calculator in the sense that it does \"deterministic\" calculations. It's merely an invisible graph of encoded grammar finding correlations between language. So when it does 1 + 1 = 2, it's not actually adding 1 and 1 like a calculator is. It's just finding correlations between 1, +, and 1 equaling 2 in it's training data. This \"probabilistic\" nature is likely why it's not as accurate.",
                                    "score": 1,
                                    "author": "rocket2913",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "[https://www.wolframalpha.com/input?i=9\\*3\\*4\\*x%5E2+%2B+3\\*4\\*x%2B4+%3D+0](https://www.wolframalpha.com/input?i=9*3*4*x%5E2+%2B+3*4*x%2B4+%3D+0)\n\nYou're right it's not doing any actual calculating, which is why it is bad even at any new problem, deterministic/science/mathy or not.",
                                            "score": 3,
                                            "author": "Glapterbep"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Yes, anyone who tries to use chatGPT to do a math exam problem is taking a huge risk to submit gibberish that is obvious \"cheating via chatGPT\" (making errors so strange that no human would).  The output tends to have the \"right form\" in terms of linguistic constructions but the actual output can be full of absurd nonsense in the eyes of anyone who understands the content.",
                                    "score": 1,
                                    "author": "back-envelope12",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Yep. This is especially true when dealing with problems that don't have a ton of associated training data. The less \"correlations\" in encoded language the model can find, the weaker the connections will be and the more likely it is to make stupid errors.",
                                            "score": 1,
                                            "author": "rocket2913"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "[deleted]",
            "score": 0,
            "author": "[deleted]",
            "replies": [
                {
                    "level": 1,
                    "comment": "[https://workofthefuture.mit.edu/wp-content/uploads/2021/01/2020-Final-Report4.pdf](https://workofthefuture.mit.edu/wp-content/uploads/2021/01/2020-Final-Report4.pdf)\n\n[https://www.forbes.com/sites/adigaskell/2022/01/18/ai-creates-job-disruption-but-not-job-destruction/?sh=1fa43fb73b3e](https://www.forbes.com/sites/adigaskell/2022/01/18/ai-creates-job-disruption-but-not-job-destruction/?sh=1fa43fb73b3e)\n\n[https://hbr.org/2021/11/automation-doesnt-just-create-or-destroy-jobs-it-transforms-them](https://hbr.org/2021/11/automation-doesnt-just-create-or-destroy-jobs-it-transforms-them)",
                    "score": 1,
                    "author": "back-envelope12",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "[deleted]",
                            "score": 1,
                            "author": "[deleted]",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I suppose your \"I think no\" was meant to be \"I think so\".\n\nYou should be more skeptical about the hype surrounding AI.   The more one knows about what is going on under the hood in AI systems, the clearer it is that the dystopian future you're worried about is not remotely on the horizon.  (There was once a forecast about when various types of jobs would be replaced by robots &amp; AI, and the last such job was predicted to be \"software engineer\"; guess what type of people were making the forecast.)\n\nWhy hasn't Starbucks been taken over by robots behind the counter?  Is there anything the baristas do (not involving a mop) which machines couldn't have done plenty of years ago?",
                                    "score": 2,
                                    "author": "back-envelope12"
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    ]
}