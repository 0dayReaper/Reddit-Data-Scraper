{
    "id": "13rcl84",
    "score": 4,
    "title": "Former Google CEO Eric Schmidt Says AI Could Cause People To Be \"Harmed Or Killed\"",
    "author": "erinswider",
    "date": 1685005686.0,
    "url": "https://www.reddit.com/r/google/comments/13rcl84",
    "media_urls": [
        "https://globenewsbulletin.com/technology/former-google-ceo-eric-schmidt-says-ai-could-cause-people-to-be-harmed-or-killed/"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "add it to the long list of  risks... planes, cars, nukes, high fructose corn syrup",
            "score": 6,
            "author": "jessedelanorte",
            "replies": [
                {
                    "level": 1,
                    "comment": "From the article: \"My concern with AI is actually existential, and existential risk is defined as many, many, many, many people harmed or killed.\" \n\nOf the ones you mentioned, pretty much only nukes makes the cut. And only governments have nukes, while everyone will have AI. It's development is exploding into uncharted waters with no breaks and one would be a fool not to take the risk seriously.",
                    "score": 0,
                    "author": "mortenlu",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yup. 100% this.",
                            "score": 2,
                            "author": "smarthome_fan"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I mean when we get something like T1000 from Skynet then yes, we are truly fucked.",
                    "score": 0,
                    "author": "esp211"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Google invented the Transformers with attention over six years ago.   But they knew how dangerous this technology was and so only offered a paper but nothing else the public could use.  \n\nBut once OpenAI threw that to the wind and just charged forward.   Once that happened it kind of tied Google's hands to do the same.\n\nThe transformers with attention is not changed and what makes ChatGPT possible.    OpenAI engineers have changed they changed directions to use the day after the paper was released.\n\nhttps://arxiv.org/abs/1706.03762\n\nLove the title.\n\nGoogle tends to just let people use the IP they invent.  They patent but then do not protect.  Here they have a patent but have chosen to not enforce.  But curious if they change that at some point.\n\nhttps://patents.google.com/patent/US10452978B2/en\n\nGoogle could get us back to something more safe by just enforcing the patent.  But I highly doubt they would ever do that.  But it is another option.",
            "score": 1,
            "author": "bartturner"
        },
        {
            "level": 0,
            "comment": "Most likely. I find that OpenAI's and Microsoft's approach to AI could deem to be pretty dangerous. But the cat's been let out of the bag now, there is no way back anymore.",
            "score": 1,
            "author": "Honza368",
            "replies": [
                {
                    "level": 1,
                    "comment": "I guess Microsoft doesn't care about the danger or consequences, they just want the edge in search by whatever means necessary.",
                    "score": 2,
                    "author": "gangix"
                }
            ]
        },
        {
            "level": 0,
            "comment": "My Google account is disabled and will be deleted in 20 days and I need to put a government id or credit card info trash google",
            "score": -1,
            "author": "HourSweaty4593"
        },
        {
            "level": 0,
            "comment": "Yes, but think of the shareholder value that will be created.",
            "score": 0,
            "author": "AlternativePool5618"
        }
    ]
}