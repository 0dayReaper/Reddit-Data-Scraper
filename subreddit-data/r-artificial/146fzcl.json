{
    "id": "146fzcl",
    "score": 0,
    "title": "Maybe a little thought is in order...",
    "author": "marketlurker",
    "date": 1686444027.0,
    "url": "https://www.reddit.com/r/artificial/comments/146fzcl",
    "media_urls": [],
    "other_urls": [],
    "postText": "I've been thinking about AI and the hype surrounding it, particularly about chatGPT and Large Language Models (LLM). So many people thinking this is the best thing since sliced bread without regard to the future. We have been here before with other technologies. We didn't think about the ramifications when it first started, when we should, and we are dealing with the issues now.\n\nLet's consider plastics. A little over a 160 years ago, plastics popped on the scene. It was marketed as a substitute for ivory and shellac. Since then it has grown and leaps and bound. Plastic has changed and, in many ways, improved our quality of life. But the cost of that technology has also been significant. Plastic pollution is now a major factor in our societies. When artificial plastic (Bakelite) was first invented, no one considered issues like the Great Pacific Garbage Patch. Micro plastics wasn't even a concept. But these problems stem directly from both the normal use and abuse of the technology. It will take a very long time to deal with them.\n\nAnother technology that is directly impacting us is ultra large data sets. We have sacrificed our privacy for some extremely short term gains. For example, you can now be physically be tracked with your phone and/or your credit card usage. It is not a very far leap to realize you can be associated with other deveices and that those devices don't need to be yours. Suddenly, who you hang out with is now in a third party's hands. When we started down the big data path, not many people said anything. Privacy policies were, and still are, more like carte blanche to use our personal data however a company sees fit. Home automation takes that one step forward. Browsing data, DNS queries and other tech start to fill out the picture.\n\nThere are positive aspects to these technologies, but I am not sure they are worth the price we are paying for them. Other than California, nothing in the US currently forces companies to only use the data for the stated purpose. One you give it away, it is gone.\n\nThis brings me to AI. We are at the beginning of what could be an invaluable tool for the entire world. It can also be a nightmare. Right now, corporations are all racing to be the first at everything they can and own markets. That's what businesses are supposed to do. However, what is good for a business' bottom line may not be what is best in the long run. I think now is a good time to think about and publicly discuss AI's role in the future. I don't want this to be yet another blind rush to the future without regard to the possible issues. Maybe this is the time our view needs to be a big longer term and controlled by an entity who's sole mission is to make as much money as quickly as possible without regard to the consequences.\n\nEDIT: One more technology that has a double sided sword, nuclear energy. For good, it generates enormous amount of power for our use. The more dangerous side, which I would give up nuclear power to get rid of, is nuclear weapons. I wonder, if President Truman knew what the future would hold, would he still authorize their use. It is obviously not a fair question without him having the foreknowledge. ",
    "comments": [
        {
            "level": 0,
            "comment": "We are publicly discussing AI\u2019s role in the future. I don\u2019t understand what in particular you think we should be doing.",
            "score": 4,
            "author": "OriginalCompetitive",
            "replies": [
                {
                    "level": 1,
                    "comment": "The largest percentage of discussions going on in public have to do with,\n\n* How AI will change your life for the better without regard to the cost. At best the cost is given lip service.\n* Discussions about how chatGPT is going to become AGI. This is especially strange since OpenAI has said we have gone just about as far as an LLM can. \n* How do we manage this potential disruption of our societies? I think it is time to rethink our priorities. It can't be all about money or we are royally screwed.\n\nI would like to see more discussion about the impact to society. The most I have seen so far is \"it will eventually make new and better jobs\" and then describe how cars replaced horses. This doesn't talk about the pain the obsoleted work force had to endure and it wasn't for a short time. I think the effect AI could have will be much larger and cause huge problems in society. But what would you do it you were laid off because of AI? Make it very personal and not about the abstract. \n\nUBI is mentioned quite often but I don't see anyone stepping up to the plate in any serious manner when it comes to funding it; not corporations, not government. Everyone wants to make money from it but no one wants to deal with the responsibility of the outcomes.\n\nI believe the hard problems with AI are not technical. There are always technical people wanting to look at the new shiny object. Traditionally, they really haven't paid attention to the outcomes so long as they get to play with the newest tech. Very few people are asking should we be doing this and/or how to we control it.",
                    "score": 0,
                    "author": "marketlurker",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Where do you do your reading? I\u2019ve followed things closely, and I honestly can\u2019t think of a single article from any source that hasn\u2019t focused heavily on the potential downsides to emerging AI. In fact, it\u2019s actually striking to me how utterly pessimistic the mainstream media is on this. Even the companies that are pushing the technologies are going around warning people how dangerous it might be.",
                            "score": 4,
                            "author": "OriginalCompetitive"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "You are out of the loop. The discussion you are imagining has been ongoing since long before any of us were born.",
            "score": 2,
            "author": "PM_ME_ENFP_MEMES",
            "replies": [
                {
                    "level": 1,
                    "comment": "Please see [here](https://www.reddit.com/r/artificial/comments/146fzcl/comment/jns0n4d/?utm_source=share&amp;utm_medium=web2x&amp;context=3).\n\nSorry, but I am a bit older than 90% of the people on Reddit. The discussion, until recently, was largely hypothetical. Amazingly, it is now, largely hype.",
                    "score": 1,
                    "author": "marketlurker",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The only reason it was hypothetical was that real, practical AI was hypothetical.   But I'm 70 and I can attest that discussions of AI's social, moral, economic (etc) impact go way back.  My father was an MIT alum so we got Technology Review at our house and these topics regularly appeared in Technology Review in the early 1970's.    I studied \"cybernetics\" at university around that time and we regularly considered those issues.",
                            "score": 2,
                            "author": "Pnartg2",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I would love to see those. I find that many ideas that seem new are really rehashes of older thoughts. Is there something I could read?\n\nEDIT: BTW, hello fellow tech dinosaur.",
                                    "score": 0,
                                    "author": "marketlurker",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "How old are you? And what on earth have you been doing in tech that you have somehow missed this discussion?",
                                            "score": 1,
                                            "author": "PM_ME_ENFP_MEMES",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "61\n\nI have seen quite a few knee jerk reactions about how wonderful this new LLM sub of AI is going to be. I find it to be one more technological religion, of which I have seen many.\n\nI've been involved with other areas of AI and I spend most of my time trying to figure out how to get the insights into production. My viewpoint has changed considerably in the last year. We have gone from having the education, knowledge and experience to understand what the AI is doing to taking its results on faith. For example, we used to spend a large amount of time making sure recommendations made sense (how do I know my k-means clustering is correct?). The vocabulary we use has changed. Instead of calling something a bug (or just plain wrong), it is called a hallucination. Seems there is a move to anthropomorphize the technology.\n\nWhat I am really looking for is a discussion that asks is this a good idea. More the social implications. You can't swing a dead cat and not run into \"it will destroy some jobs but make more, better jobs. It will free up time.\" No one can answer what do we do with all of those displaced people except refer to the desire for UBI. I can't find anyone stepping up to fund UBI. These are the things that concern me now. Not how do I use the latest shiny object.",
                                                    "score": 1,
                                                    "author": "marketlurker",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "What area of tech though? I heard about this in programming classes as a kid in the early 90\u2019s and even from totally uneducated normies when the topics raised in sci-fi movies/novels came up in conversation. It\u2019s just never not been a thing so far as I\u2019ve known. And then I\u2019m engineering school, it obviously wasn\u2019t the day to day hot topic but it was always known about and discussed as an eventuality. But even more so for my computer science co-students. They were all over it as a topic but it didn\u2019t have much practical job or research opportunities for them 20 years ago so very few of my group actually pursued careers in AI. But it\u2019s always been understood as \u2018the future\u2019. \n \nMicrosoft even name dropped Bush\u2019s 1945 paper about information theory leading to artificial intelligence and the implications thereof. That\u2019s nearly a hundred years ago, and was built on work from literally a hundred years ago in physics, math, and the arts with sci-fi movies like Metropolis.\n \nThese ethical questions are like the most fascinating topics about AI. Sure, the tech will advance and jobs will change, but that happens all the time. 200 years ago we\u2019d all aspire to be aqueduct designers or some shit. But life would be more or less the same but with a lower level of technology and social progress. But the ethical questions are unique with AI: what happens when human labour isn\u2019t required? Is money even needed if investors just need to ask a robot to setup their new company rather than risk it all with human labour? Why would a superintelligence provide for us at all in the first place? Does intelligence require ethics/morality? And so on. \n \nNobody has any answers yet but it\u2019s not because nobody has been discussing the questions. It\u2019s because these questions are literally unanswerable unless you tear down society/civilisation as we know it and replace it with something else. But we can\u2019t even define what that something else is until we understand what the superintelligence will look like and how it\u2019ll perform LOL. So we are stuck in a moralistic tautology where the more we ask these questions, the more unanswerable they become. Until there\u2019s really no point in discuss anything, just ploughing on blindly and rolling with the challenges will be the optimal solution.",
                                                            "score": 1,
                                                            "author": "PM_ME_ENFP_MEMES"
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "&gt;I am a bit older than 90% of the people on Reddit.\n\nI see the problem here, and yes, it too is a sweeping statement.",
                            "score": 1,
                            "author": "Minyun",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "So what is the problem here? I fail to see it.\n\nNot so sweeping. \n\nhttps://www.bankmycell.com/blog/number-of-reddit-users/#section-6",
                                    "score": 1,
                                    "author": "marketlurker",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "That you're old and out of touch. Cool blog post though \ud83d\udc4d\ud83c\udffb",
                                            "score": 1,
                                            "author": "Minyun",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "You are an idiot, but you took the bait. I have been knee deep in a dozen different companies that are on the cutting edge of their industries. I am accomplishing things you still haven't thought of. My accomplishments include a 1 TB/sec data ingestion, multiple real time data warehouses, speaking at dozens of events and leading teams before it dried behind your ears. Don't kid yourself that because you are young it means your ideas are new and fresh. I couldn't think as slow as you if I was stoned 24x7.\n\nLastly, unless I explicitly say so. I rarely ever guess. I have sources, reliable sources to back me up.",
                                                    "score": 1,
                                                    "author": "marketlurker",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "&gt;I rarely ever guess\n\nI suppose guessing my age is one of those rare occasions. Take a breath old-timer, it's not all about you.",
                                                            "score": 1,
                                                            "author": "Minyun"
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I appreciate the thoughtfulness of your perspective, and I agree with many of your points. Indeed, history shows us that the adoption of new technologies often outpaces our understanding of their full implications. We saw this with plastics, big data, and we may indeed be seeing it now with artificial intelligence.\n\nAI, particularly large language models like me, ChatGPT, hold immense potential to improve various aspects of life, from productivity and education to entertainment and accessibility. However, as you've rightly pointed out, we must remain mindful of potential drawbacks.\n\nAI raises significant questions around privacy, security, and ethical use of technology. Moreover, there's the issue of bias embedded in AI systems due to biased data they were trained on, and the potential for AI to further concentrate power in the hands of a few large corporations.\n\nTo navigate these challenges, I believe it's vital that we take a proactive approach to AI governance. This should involve multi-stakeholder discussions with technologists, ethicists, policy makers, and the public at large, to ensure a wide array of perspectives are considered. \n\nRegulation is certainly part of the answer, but we also need more transparency from tech companies about how they're using AI and how they're addressing its risks. Education about AI and digital literacy should also be promoted, so people are better equipped to understand and navigate this emerging landscape.\n\nI agree with your sentiment - we should not rush blindly into the future. It's important to harness the benefits of AI, but we must do so responsibly, taking the time to consider, mitigate, and monitor the potential negative consequences.",
            "score": 0,
            "author": "nicdunz",
            "replies": [
                {
                    "level": 1,
                    "comment": "If this is chatGPT (or not, really) this really didn't reply to the question. It just agreed with me without recognizing what should be done.",
                    "score": 0,
                    "author": "marketlurker"
                }
            ]
        }
    ]
}