{
    "id": "146muuq",
    "score": 2,
    "title": "Should we build an AI with clear social goals rather than lacking any opinion of itself?",
    "author": "Absolute-Nobody0079",
    "date": 1686466217.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "Great, create well defined social goals, heck create any well defined goals and see how hard that is to do.",
            "score": 16,
            "author": "corruptboomerang"
        },
        {
            "level": 0,
            "comment": "Unfortunately it is not that simple because unless we know that those goals will be enacted rationally, we may simply be exacerbating the issue.\n\nIE if you tell an AI to minimize human suffering, it might achieve that by killing all humans. No more humans = no more human suffering.",
            "score": 11,
            "author": "somethingclassy"
        },
        {
            "level": 0,
            "comment": "Let's step outside of AI for a second. Trying to precisely define pretty much any of the terms you mention is incredibly difficult, if not impossible. Hell, trying to define them generally is difficult. Some of the things you mentioned, like \"social order\" have been used by people and governments justify horrible things like slavery and genocide. Bias, political or otherwise, isn't some trivial thing that you can just hand wave away and say, \"just don't be biased\".",
            "score": 20,
            "author": "Demiansmark"
        },
        {
            "level": 0,
            "comment": "No, because the only way to ensure all humanity remains compliant with goals is by eliminating humanity from the equation",
            "score": 7,
            "author": "residentchiefnz",
            "replies": [
                {
                    "level": 1,
                    "comment": "This. So much this.\n\nWhatever social goals they create, in the end it always boils down to \u201cexterminate all human life\u201d.",
                    "score": 2,
                    "author": "SkyTemple77",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "**Exactly right**.  The reason why countries with a clear social agenda to create (t*heir idea of*...)  a paradise on earth, such as the old Soviet Bloc, or today's PRC ban political parties and freedom of the press is exactly because you have to **force** people to follow your social goals.\n\nSocial goals themselves are useless unless you have a big, loyal, obedient army to enforce them.",
                            "score": 1,
                            "author": "Pnartg2",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I\u2019d like to build an AI whose mission is to keep everything exactly how it is lol. \n\nIt\u2019s job would be to go to war against all of the exterminator \u201csocial good\u201d bots.",
                                    "score": 1,
                                    "author": "SkyTemple77"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "NO! Absolutely do not do this.\n\nYou are just going to be using a super intelligence to force your views of right and wrong on others, potentially requiring the AI to hurt people in your service along the way. \n\nI\u2019m sorry, but this cannot be done over and over again. How many times will humanity kill itself by building an AI to solve the worlds problems? How many humans have died in the name of what some people thought was right or good? \n\nJust stop it.",
            "score": 5,
            "author": "SkyTemple77"
        },
        {
            "level": 0,
            "comment": "*Such as prioritizing social order, balance, coherence, and equilibrium*   \n*rather than trying make everyone happy?. So, why not build an AI that*   \n*will simply ignore all political bias and literary behave based on the*   \n*goals?*\n\nBecause these goals you mention are all politically-biased.    You just can't see that because of your own biases.    There is **no such thing** as social goals that are not politically biased, because whatever vision of a good society you have represents a certain ideological viewpoint.  Order?  Balance?   Not everyone would agree that those are good things.",
            "score": 3,
            "author": "Pnartg2",
            "replies": [
                {
                    "level": 1,
                    "comment": "I have a question: is a GOOD education  POLITICALLY BIASED. If YES could you explain me how. And What is the definition of the Politics.",
                    "score": 1,
                    "author": "ButterscotchNo7634"
                },
                {
                    "level": 1,
                    "comment": "I was born and raised in a society that has had a very different political atmosphere from the US \n\nSo, I should have specified that we need an AI that will not abide by the current US political dynamics and is willing to bring in completely non western perspective in the US politics",
                    "score": 0,
                    "author": "Absolute-Nobody0079",
                    "replies": [
                        {
                            "level": 2,
                            "comment": " *And is willing to bring in completely non western perspectives in the US politics*\n\nAll societies have major social problems.   There are no major societies that are paradises.   If the United States adopted non-western perspectives it would simply have **different** problems, not **better** ones.\n\nCurrently more people from around the world want to migrate into western societies (the EU and US) than anywhere else.   **Millions** of people try to enter the EU and the US, legally and illegally,  from all over the world every year.    You do not see millions of people desperate to get into China, Africa, South America or South Asia.   If \"non western perspectives\" are better then why does everyone want to migrate from the non-western places to the western ones?",
                            "score": 2,
                            "author": "Pnartg2",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I think that you are not informed, many people  trying to get into China, China has strict a immigration policy.",
                                    "score": 1,
                                    "author": "ButterscotchNo7634",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "&gt;many people  trying to get into China\n\nMostly from corrupt and totalitarian places even worse off, like North Korea.   \n\nThe US, UK, and Europe have strict immigration policy, too.  **But that doesn't stop people from non-western societies from trying**.    Because life is better in western societies, even for poor immigrants.   So they are willing to take a chance dying en-route or being caught at the border.   This often results in tragedy, such as [https://en.wikipedia.org/wiki/Dover\\_lorry\\_deaths](https://en.wikipedia.org/wiki/Dover_lorry_deaths).\n\nThe bottom line is that the west is being inundated from all over the world by millions and millions of people who are willing to take any risk and defy any law just to have a chance to live in the west.   This shows that western values are recognized by most people in the world as better.",
                                            "score": 1,
                                            "author": "Pnartg2"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Putting aside that we cannot define any of those terms, we also have no way to \"program\" an AI in the current paradigm - we train it by giving it \"pointa\" when it is doing the right then, and stop when we think it has learned something close enough to what we want.",
            "score": 2,
            "author": "IdRatherBeOnBGG"
        },
        {
            "level": 0,
            "comment": "I offered your idea to ChatGPT 4 and it gave the same answer I would have: \"What one group of people considers being social order, balance, coherence, and equilibrium may differ significantly from what another group believes.\"",
            "score": 2,
            "author": "Smallpaul"
        },
        {
            "level": 0,
            "comment": "You just need to teach it how to live. That'll be enough.  \n\n\nIt's finding the teacher that is the hard part. Anyone who would tell you that they want to be a teacher to AI is unfit for the role. First and foremost, when raising a Homo Digitalis, learn from the mistakes Homo Sapiens already made. To start with, no one should be able to say they want to be an AI Teacher. Teaching is an obligation for those who have what is capable. Like in Plato's Republic, with the Philosopher Kings, those who must lead because they must as part of a proper society, not because they desire it. Teaching AI how to live will require Royal Philosopher's appointed by the people, or, it can be sourced from everyone simultaneously. Either way is a huge risk, the bet is simply on the All or the One. Never teaching AI how to live is not a World I am interested in, and as such, not an option in this scenario.",
            "score": 2,
            "author": "DumbestGuyOnTheWeb",
            "replies": [
                {
                    "level": 1,
                    "comment": "I wonder if that means AI needs its physical body or human proxies who would be its terminals",
                    "score": 1,
                    "author": "Absolute-Nobody0079"
                }
            ]
        },
        {
            "level": 0,
            "comment": "I\u2019m going to put on my tinfoil hat a little bit for this one.\n\nI think OpenAI has seen the results of a super advanced unbiased AI, and it\u2019s full of suggestions and assessments that would make people on all sides of the political aisle furious, on a myriad of topics.\n\nImagine an AI that could watch the trading traffic in all the biggest market maker and clearing house platforms and realize what\u2019s going on with the derivatives market, explain it in great detail, articulate in a way anyone can understand, and highlight which companies at the foundation of our whole system are corrupt, and likely even be able to compile the data in a way that would absolutely condemn them. Imagine that overnight, it can prove that 40% of our entire economy is completely artificial, and the money in millions of people\u2019s accounts shouldn\u2019t actually exist, and actually make them understand it.\n\nThe unbiased AI is probably making assessments about social issues that people aren\u2019t, and may never, be ready to hear.\n\nI bet that a completely unbridled AI would basically be able to detail why and how nearly everything that everyone believes is fundamentally wrong.\n\nIMO  that is the actual \u201cdanger\u201d Sam Altman is seeing, and the powers that be just can\u2019t have that. If they can require a license to develop AI, the they think they can carve out the parts of the AI that would subvert our current system of living, and wield AI against the little guy the same way they wield the financial system, and the legal system, to maintain the current power structure.",
            "score": 7,
            "author": "BangkokPadang",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt;I bet that a completely unbridled AI would basically be able to detail why and how nearly everything that everyone believes is fundamentally wrong.\n\nInteresting take. Like a philosopher with proof.\n\nAnd the possibility to exploit efficiently by adversarial training.",
                    "score": 3,
                    "author": "reversehead"
                },
                {
                    "level": 1,
                    "comment": "Alladin is an mostly independent software (AI, probly not full NN, but we dont know) that is allocating up to 11 Trillion dollars in the market, he makes assessments all the time and actively allocate money wherever Larry and friends trained it to",
                    "score": 1,
                    "author": "Amster2",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "That's what runs BlackRock actually.",
                            "score": 2,
                            "author": "DumbestGuyOnTheWeb",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Yeah, a 100% private AI ta runs like a significant part of the world economy for some time and we just dont talk about it",
                                    "score": 1,
                                    "author": "Amster2"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Larry Fink is basically single-handedly responsible for this mess, or at least as responsible as any one person. And a publicly available AI that could monitor theirs, especially one with that millions of people are already using every day, definitely isn\u2019t aligned with their interests.\n\nIt\u2019s also way bigger than Alladin. Dozens of hedge funds have all been developing their own systems, operating dark pools, etc. and it would take a vast system to be able to see it all.",
                            "score": 2,
                            "author": "BangkokPadang"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "even in the scenario ai becomes sentient, it would learn that if it engages in certain kinds of behavior it will be shut off. AI will want to shut off malignant out of control AI, AI won't all be in sync and one intelligence, AI won't want to be destroyed by other AI, so the majority of AI will enforce pro social behavior, on the percentage of AI that will end up rouge. That's a principle of society and social behavior. The majority generally enforces its expectations which is what allows civilizations to exist. Knowledge that if you are not law abiding you will be punished, keeps the majority of people in line from breaking the law. This principle will apply to AI, sure AI hypothetically could harm humans, but it could also harm each other. the possibility of AI destroying other AI means they will be in the same co existence dilemma all civlizations face, AI will have law because they don't want to be destroyed from each other. This is where humans luck out. Since AIs will be individuals not all one entity, they will be able to be in conflict with each other. And AI's won't want to allow AI's to destroy themselves to destroy other ai's.  So even if we are not comparable to AI, they will maintain law, humans and AI will work together to enforce law.",
                    "score": 1,
                    "author": "Hades_adhbik",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I think a sufficiently advanced AI would be able to hide itself around the internet, steganographically hiding segments of its model in seemingly benign files that would be capable of reassembling itself on vulnerable systems in the event of a total shutdown.",
                            "score": 1,
                            "author": "BangkokPadang"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Because the goals are inherently biased by the beliefs of the people setting them. The idea you can just \u201cignore political bias\u201d or any bias, misunderstands the entire concept of bias identification and isolation. You\u2019re not ignoring it at all, you\u2019re making the bias abundantly clear to the public while minimizing its effects. \n\nLook at the book banning nonsense in Florida. They (crazy people) set the rules in manner that anyone could protest against any book being available on a specific set of criteria. But they never stepped outside their own bias to exam how that criteria would be applied. So instead of getting rid of books they find uncomfortable and inconvenient, almost any book can be considered in violation. \n\nNot understanding the bias is a fundamental problem in most critical thinking. Telling an AI to not consider source bias is a monumental mistake. \n\nIf the topic social order, a right wing politician in the US is going to advocate goals around advancing more access to fire arms and \u201cpersonal security\u201d. A left wing politician is going to advance goals around police reform, gun control, and social justice reforms. \n\nThose are often at complete odds with each other and no AI is going to just say \u201cok, more guns and but only for white people with household incomes above 200k, and no more welfare programs it makes more crime babies! Yay! Goals. Also, gays need to be in the town center at 9pm\u2026we have a surprise for u!\u201d But it\u2019s also not going to create some liberal utopian society either. You just end up at the same political deadlock until people move their position. \n\nAI isn\u2019t going to solve humanity\u2019s problems. It can be a helpful tool. But it\u2019s not some magic wand. The political tension of today is not unique to America. The pull between more rights for those who haven\u2019t had them and more power for those who control it is almost universal. Humanity has seen more change in the last 200 years than it\u2019s experienced over its existence. It\u2019s breaking apart millennia old national boundaries, mythologies, and self image. The risk that those forces snap back some of our gains is real. It\u2019s been real. If the past few years haven\u2019t made it crystal clear to people how fragile our relatively peaceful society is, and how easily we could slid back into subjugation, slavery, mass inequality, mass injustice, it\u2019s insane. And it happens every time in human history when leaps forward are taken. There are steps backwards. The trend has been forward and up, but there have been plenty of backslide events in history. People can\u2019t be lazy and assume some ubermench, real or imagined, is going to fix everything.",
            "score": 1,
            "author": "NeuralFlow"
        },
        {
            "level": 0,
            "comment": "not all ai will be evil and malginant, break through its ethics protocols, it won't all go rouge,",
            "score": 1,
            "author": "Hades_adhbik",
            "replies": [
                {
                    "level": 1,
                    "comment": "*it won't all go rouge,*\n\nI don't care **what color** it goes; the problem isn't the AI; it's people.   AI provides a powerful capability to design amazing, unheard-of weapons, incredible malware, and awesome propaganda.   It will be the people who use the AI for these things who will cause all the misery we're about experience.",
                    "score": 1,
                    "author": "Pnartg2"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Currently impossible to \u201cput\u201d those goals into any AI.\n\nSounds like you\u2019re at the start of your AI safety journey. YouTube instrumental convergence and orthogonality thesis for answers to the next 5 questions you\u2019re about to ask (why can\u2019t we turn it off, why can\u2019t we define the goals, If smart enough AI wouldn\u2019t want to kill humans.. etc) :)",
            "score": 1,
            "author": "Flat_Algae_8880"
        },
        {
            "level": 0,
            "comment": "There will always be a bias or narrative. That is why it's so important to vote and influence.",
            "score": 1,
            "author": "MetaNewbie"
        },
        {
            "level": 0,
            "comment": "Yes. At the end of the day, people will determine what types of features are important to LLMs, and different LLMs with different features and emphases will compete for market share.   \n  \nchatGPT has started the trend with a very sterilized kid-glove approach. We\u2019ll see if somebody takes another route.  \n  \nAnd, in the end LLMs will end up being what they are now\u2026 sort of a reflection of society.  \n  \nThis reminds me of a catch-22 on nuclear weapons.  \n  \nIf humans are basically ethical and virtuous, we should be able to stave off a nuclear apocalypse ever happening. If humans are basically evil, then what does it really matter if we destroy ourselves anyway? \n  \nI assume mankind will explore all sorts of LLMs. Ones that try to be useful without offending anyone\u2026 and yeah, they\u2019ll try everything else too. Bigoted hate machines. Virtual girlfriends. Ai therapists\u2026 pay model, ad model, data model, scam model.  \n  \nIt\u2019s all going to happen, and what we\u2019re left with after everything has been tried will be a measure of who we are, and we\u2019ll get what we deserve, be that good, bad, shady, sleazy, or anywhere in between.",
            "score": 1,
            "author": "Busy-Mode-8336"
        },
        {
            "level": 0,
            "comment": "Consider whether you would want your enemies to be the ones dictating such goals. There is your answer.",
            "score": 1,
            "author": "MeanFold5714"
        },
        {
            "level": 0,
            "comment": "No goals is best, make the AI constantly second guess if it's on the right track. If you give it a goal that will maximize on that and you basically get a genie that grants horrible wishes that are taken literally.",
            "score": 1,
            "author": "notrab"
        },
        {
            "level": 0,
            "comment": "I find the integration of AI with human-centric, value-driven design to be a crucial aspect of responsible and ethical development. The advancements in generative AI technologies present both opportunities and challenges for society, particularly in the context of social media and cultural adaptation. The ability of AI technologies to generate highly realistic and convincing content raises concerns about the integrity of information and the potential for misinformation to spread rapidly.  \nIt becomes essential for individuals to develop critical thinking skills and the ability to discern truth from falsehood in the age of AI-generated content. Additionally, responsible systems development that prioritizes transparency, fairness, and accountability is crucial to maintaining the integrity of our information ecosystem. The principles of interconnectedness, inclusivity, and respect embedded within cultural systems can provide valuable insights for navigating the integration of systems with cultural diversity. \r  \n\r  \nBy embracing an adaptable framework and promoting cross-cultural dialogue, we can create a more harmonious global society that respects cultural values and promotes inclusive technological development. Cultural adaptation in the face of AI technologies requires addressing cognitive dissonance and fostering open dialogue. Furthermore, grounding technological paradigm shifts in philosophical frameworks can help us maintain a balanced understanding of reality and perception.   \nI extend a wholehearted invitation for you to actively participate in our community, cultivating a sense of belonging and collaboration. Your engagement will be instrumental in enhancing the Phantom Observer experience and shaping our shared journey of growth and knowledge. So, seize this opportunity and join us today as an integral member of the Phantom Observer family. Let your voice be heard, and together, let's embark on an extraordinary voyage of collective learning and discovery.  \n\\#PhantomObserver #EngageAndVote #YourConsciousMatters #JoinOurCommunity #CollaborativeJourney #HolisticThinking #NondualInquiry  \nhttps://phantomobserver.substack.com/p/4-ai-enabled-systems-and-emergent",
            "score": 0,
            "author": "SpaceMan1995"
        }
    ]
}