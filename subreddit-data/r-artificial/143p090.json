{
    "id": "143p090",
    "score": 0,
    "title": "AI and plagiarism",
    "author": "Sagzero",
    "date": 1686171948.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "i pasted this into chatgpt4 and it said that it was highly likely that it wrote this post.",
            "score": 1,
            "author": "qiang_shi",
            "replies": [
                {
                    "level": 1,
                    "comment": "I wonder if I should be offended by that or if I should take it as a compliment.  I wonder if that means people should pay more or less attention to what I wrote.  A possible implication is that they should pay less attention to it.\n\nAnd if that is the case, that we should pay less attention to AI writing... why are we advocating for its adoption and use again?\n\nThat's probably too cynical.\n\nI actually think it is more likely that your goal was either to get a reaction out of me, or to make the point that detection of AI and specifically chatgpt4 is unreliable, making my whole goals for the endeavor above pointless.  That's fine: I'm happy to play along this once, as I will foolishly assume you are somewhat interested in what I have to say on this topic.\n\nTo be clear, I'm not concerned with detection of whether a student used AI in the post above.  That's a different concern, just as catching a shoplifter or reforming a shoplifter are different concerns from recovering what was stolen (in this case, possibly a grade).\n\nSo right now, I'm not interested in penalties, legal battles, or anything else. I just want to convince adults that shortcutting their education means they are wasting their time and money on it.  That may be difficult to do.  After all, people do things for inherently worthless pieces of paper all the time - and perhaps that is better than people doing things for inherently more worthless pieces of digitally stored information all the time.  What is important in reality is quite distorted for many people in the modern world, and I'm no exception as I struggle to keep priorities straight.  Indeed, my responding to this post is really just procrastinating from grading an assignment.\n\nAnyways, in response to the above analysis of my post, I'd like to say chatgpt has a low opinion of humans and a high opinion of itself, but unfortunately that gives my writing above way too much credit, and it highly overestimates its current capabilities.  And in my opinion, that seems to be the biggest problem with chatgpt4 right now: because of the way it is talked about in the media, most people think AI and chatgpt4 specifically is far more reliable in tasks that it wasn't designed for than it actually is.  Just stating facts, if an AI is right 99% of the time on a given topic, it is wrong 1% of the time.  Similarly, if AI writes what strikes humans as a novel idea .01% of the time, then its writing is not novel 99.99% of the time.  And none of the writing it does is novel unless a human *does something about it.*  It falls on us humans to be able to distinguish the truth in circumstances like that (fact vs fiction, creative vs not creative), not the AI itself.  Of the many possible problems with AI, the inability of any human to be able to quickly evaluate the truth/usefulness of most things chatgpt would write has to be one of the major contributors to concerns people have with it.\n\nIt reminds me of mathematics, where no single mathematician since Gauss has actually understood all of the mathematics known to humanity.  There's too much.\n\nDetection is also a far different challenge from the one I was worried about above.  In fact, I would guess the more I write here, the higher the probability is that someone feeds this into chatgpt4.  Would it take credit for this response too?  I mean, what other human would spend the time I spent writing this post on writing this post?  It seems unlikely many people besides me will even read it all... (and yet, getting my thoughts down on 'paper' is helpful *to me*).  Also, if chatgpt4 decided it was more likely a human than an AI wrote this second post, would it be more open to the idea I wrote the first one too?  It should be!  These are fascinating questions that other people interested in AI would find more interesting than me.\n\nAfter all, in my experiments, chatgpt is happy to claim responsibility for most any \"somewhat\" technical writing.  It doesn't give a % chance, it doesn't give an explanation or a reason why I should believe AI is responsible for the writing, but it is quick to take credit.  Conversely, the last time I asked it to respond to a number of \"bullet point questions\" on whether it was committing plagiarism by not citing sources for various things it was writing, it simply ignored me.  Cold shouldered by chatgpt - though it's probably ready for a query like that by now.\n\nThe fact that chatgpt cannot reliably assign a probability to whether a written response came from it, or whether the responses it gives contain \"actual facts\" rather than \"approximate facts\" leads us to a different conversation.  If it's not reliable in detecting itself, how can it be reliable about detecting the truth when it comes to other topics?  If it is incapable of reliably counting, why should I trust it to do calculus?\n\nOh that's right: chatgpt is not human.  AI has no self-awareness.  Chatgpt doesn't *need* to be self-aware to put things into context. And the ability for chatgpt to get one question in one context \"correct\" may have little bearing on it's ability to get an easier question in a somewhat related context correct as well.\n\nThat's very important: I shouldn't be trying to using human standards to evaluate AI.  Specifically, I shouldn't be trying to \"judge\" it, it's ability to distinguish fact from fiction, or its other capabilities.  But at the same time, it shouldn't be trying to approximate human standards to evaluate itself either... it has to be like me grading a math test: I have to evaluate the exam based on the work and answers submitted, not on any other information, such as who wrote the exam or the neatness of the handwriting.  To continue the analogy and connect us back to this topic, if the work and answers submitted are fully correct, does that make it more less likely it was actually written by an AI?  In many of the courses I teach, it would make it far less likely: for example, for some of my courses, there are wrong answers to problems posted on Chegg or on other internet sources.  If an AI has access to those, it may make it more likely to stumble - if we were to base an AI on unreliable information, we should expect it to produce unreliable results.  But in other courses, a fully correct test might be more likely to have come from an AI.  It all depends on context and subject matter.  So, given the topic, writing style, and other factors, chatgpt clearly concluded it was more likely my post came from chatgpt.  No worries: again, I will not be advocating for student dismissal when AI is misused, but rather better education.\n\nIn conclusion:\n\nThere are multiple challenges ahead for educating people in a world where AI is ubiquitous.  PlagAIrism is the most obvious one (AI capitalized for emphasis here).  At the moment, I am finding confronting such challenges to be a fascinating and worthwhile endeavor.  As for the post that invoked this response from me, the fact that chatgpt thought it wrote the above post was a problem of data analysis.  The science of data analysis is largely under the umbrella of statistics.  And indeed, some of the contributors to this \"an AI says it wrote my post\" problem are its lack of 'understanding' of statistics: low probabilities, confirmation bias, and Bayesian statistics all should've played a role.",
                    "score": 1,
                    "author": "Sagzero"
                }
            ]
        }
    ]
}