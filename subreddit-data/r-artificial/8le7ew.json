{
    "id": "8le7ew",
    "score": 390,
    "title": "The struggle is real",
    "author": "Yuli-Ban",
    "date": 1527027800.0,
    "url": "https://i.imgur.com/5C7upTs.jpg",
    "media_url": "https://i.imgur.com/5C7upTs.jpg",
    "comments": [
        {
            "level": 0,
            "comment": "\"What are neural networks?\"\n\nYuli-Ban: Neural networks are sequences of large matrix multiples with nonlinear functions used for machine learning.\n\nComments sections everywhere: Skynet. The more neurally they are, the more Skynet they become.",
            "score": 39,
            "author": "Yuli-Ban",
            "replies": [
                {
                    "level": 1,
                    "comment": "Some thoughts, take or leave\u2014&gt;People have on their minds a model that sticks. Then you have famous ppl dissing. You have a tech press which is more hype than actual journalism, hyping some new work as if singularity/ second coming. You have some AI researchers saying they are \u2018people first,\u2019 but treat human knowledge like it is a fortress to be seized: with the right algorithm and a billion attacks, we can \u2018solve\u2019 language. \u2018And stop human idiocy...\u2019 is often the unsaid. I am not sure how much some AI researchers love ppl, the messy, stupid, irrational, illogical, obsessed messes, etc etc. Not sure a hacker culture can ever be expected to protect any group of ppl. I have not yet heard any leading AI org say, \u201cWe will build an AI shield to protect you from X,Y,Z.\u201d If the most familiar tech today spies, mines and usurps personal data, how can everyday ppl imagine a tech that doesn\u2019t use them?",
                    "score": 7,
                    "author": "desiringm",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "the public at large thinking AI is more dangerous then it (currently) actually is is better than the opposite\u2014the public at large thinking AI is less dangerous then it actually is ",
                            "score": 14,
                            "author": "WADE_BOGGS_CHAMP"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "When this comes up I always think about how much of history's violence is simply personal vandetta. Computers don't have the burden of emotion. That said there's still a threat of being marginalized but people act like AI would even see us as a threat despite being so powerful itself.",
            "score": 3,
            "author": "[deleted]"
        },
        {
            "level": 0,
            "comment": "No, it's just math and statistics. Get real",
            "score": 10,
            "author": "[deleted]",
            "replies": [
                {
                    "level": 1,
                    "comment": "\"Nuh uh, have you ever watched that documentary, *Terminator*? SMH the robots are gonna take over and you're just welcoming them. Elon Musk, Stephen Hawking, and Bill Gates all said it's happening, are you smarter than all of them?\"\n\nThat was an actual comment. ",
                    "score": 15,
                    "author": "Yuli-Ban",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "r/woosh",
                            "score": 6,
                            "author": "[deleted]"
                        },
                        {
                            "level": 2,
                            "comment": "It\u2019s probably satire ",
                            "score": 1,
                            "author": "[deleted]",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "The \"documentary\" part probably set off people's satire-o-meter, but trust me, these were no jokes. This was in the comments of the most recent Atlas video, and I could have chosen a dozen thousand other similar comments.",
                                    "score": 2,
                                    "author": "Yuli-Ban"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I mean to be fair we are seriously lacking an ethical dialogue on the subject",
            "score": 5,
            "author": "zzuum",
            "replies": [
                {
                    "level": 1,
                    "comment": "Part of the reason, I feel, is because of our absurdly black-and-white definitions. Either this is an AI or it isn't. Either it is narrow AI or it is general AI. \n\nI personally feel there's a spectrum, \"strong AI\" can also describe narrow AIs that are superhuman in a single area, that there is an entire field of AI that is more generalized than narrow AI but less generalized than general AI. \n\nBecause otherwise we get ridiculous misconceptions. We keep thinking that it takes strong/general AI to do things when it actually only takes strong narrow AI, which very well may be able to do just about anything we think AI can do as long as we develop for it. But because we don't have a word for \"human-level narrow AI\", we create these predictions of human-level AI beating us at chess, but when DeepBlue came and went and kicked up Skynet memes back in the day, now we point at it and say \"See? Nothing came of it. There's no danger at all.\" No human will ever dominate chess against a chess-playing AI, but we still call these programs \"weak AI\".\n\nJust like how we think all AI is either narrow or general, which can skew perceptions of how close or how far general AI currently is. Because AlphaZero is not a narrow AI, but no one respectable would call it a general AI either.\n\nTLDR the very terminology itself is killing the chance for debate because it leaves so much to be desired and many unanswered questions that we don't even think about asking in the first place. [I tried creating some reformed definitions here, but no one's read it.](https://radiomonkeys.org/2018/04/23/artificial-intelligence-a-summary-of-strength-and-architecture/)",
                    "score": 7,
                    "author": "Yuli-Ban",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I read your post and generally agreed with the classifications you presented. My biggest disagreement was whether or not insects are examples of general intelligence. I'd expect them to fit better as expert intelligences, but I've never seen an analysis of their capabilities to support or refute my intuition. I'd be interested to know if you have anything on this.",
                            "score": 1,
                            "author": "BTernaryTau",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Studying insect behavior proves that several are able to learn across a generalized field, most notably the social insects such as ants and bees. \n\nFor example, [bees can learn to solve tasks from other bees](https://www.pbs.org/newshour/science/intelligence-test-shows-bees-can-learn-to-solve-tasks-from-other-bees) and improve upon these tasks, which shows how they use their social intelligence to build practical knowledge. It may be alien to humans, but it is still intelligence. \n\nNot to mention that all animal brains serve two functions: external *and* internal survival. The brain not only allows you to think and reason but also allows your heart to beat at a certain rate thanks to certain stimuli, among many other things. The same is true for insects: if they did not have complex general intelligence split up into various narrow and expert areas (e.g. heart beating and unconscious control of organs), their bodies would not function long enough to allow them to learn from their environments. So in a sense, even having a body at all means you have to have more than expert intelligence.",
                                    "score": 2,
                                    "author": "Yuli-Ban"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "You know, I appreciate this thread. I just got done ranting about how AI isn't going to magically kill all humans on Earth, how it'll be dumb and helpless and various other things in a failed attempt to curb expectations.\n\nThat, the Fermi paradox, and some other things I've read reek of too much Sci Fi. I get this is reddit and speculation is healthy and this is a laid back forum, but damn.\n\nSomething something skynet, singularity, great filter, end of our species. ",
            "score": 4,
            "author": "Earthboom"
        }
    ]
}