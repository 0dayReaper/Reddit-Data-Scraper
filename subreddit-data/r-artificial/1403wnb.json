{
    "id": "1403wnb",
    "score": 0,
    "title": "Was it a mistake for the mankind to leave Medieval Era behind?",
    "author": "Block-Busted",
    "date": 1685860749.0,
    "url": null,
    "media_url": "https://www.reddit.com/r/artificial/comments/1403wnb/was_it_a_mistake_for_the_mankind_to_leave/",
    "comments": [
        {
            "level": 0,
            "comment": "\u201cMany were increasingly of the opinion that they'd all made a big mistake coming down from the trees in the first place, and some said that even the trees had been a bad move, and that no-one should ever have left the oceans.\u201d\n\nDouglas Adams, Hitchhikers Guide to the Galaxy.",
            "score": 17,
            "author": "daronjay",
            "replies": [
                {
                    "level": 1,
                    "comment": "Douglas Adams was one of a kind, the Hitchhiker's Guide series is some of the best literature ever written. When the AI does eventually end it all, I hope to be viewing the spectacle from a restaurant at the end of the universe.",
                    "score": 6,
                    "author": "DrunkenGerbils"
                }
            ]
        },
        {
            "level": 0,
            "comment": "The length of this post makes me LONG for human extinction. Please AI overlords kill us all. We have squandered our time on this earth reading this one post and deserve to perish.",
            "score": 14,
            "author": "Joburt19891"
        },
        {
            "level": 0,
            "comment": "I'm just not convinced by the recent warnings from people who have a vested interest in locking AI technology down. I don't believe OpenAI, Google and DeepMind are truly concerned about a doomsday scenario.  I believe their true concern is that their trillions of dollars in investments might not give them the returns they were expecting. My belief is that they want to scare the worlds governments into creating regulations that will effectively kill any open source projects like BLOOM or any other start ups that might pose any future competition. AI technology is moving fast and becoming more and more accessible to build without needing the deep pockets of a company like Google or Microsoft. AI will undoubtedly change the world even more than the internet did, and corporations want to be the sole profiteers.",
            "score": 7,
            "author": "DrunkenGerbils",
            "replies": [
                {
                    "level": 1,
                    "comment": "Most people warning of x-risk from AI have absolutely no vested interest in preventing AI. The ones you've heard might. Most of us are actually really excited about AI. Altman is late to the party; although he is on record as saying AGI is scary as shit before he started at OpenAI.\n\nIf you want to have a real considered opinion on AI x-risk, you need to look at the actual arguments and logic seriously. Such a thing has never happened before. It seems worth thinking about.",
                    "score": 1,
                    "author": "sticky_symbols",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I do think that investing into research for AI safeguards and mitigating the risks involved is reasonable. What rubs me the wrong way is people like Bill Gates and others fear mongering about human extinction while calling for a six month moratorium on AI research. If Bill truly believed that human extinction was a likely outcome I don't believe all he'd do is sign a petition. Look at all the money Bill pours into malaria awareness. Until he starts pouring real money into a campaign to raise awareness about the risk of an AI extinction event, I just don't believe he actually thinks human extinction is a likely outcome. A six month moratorium seems like an oddly lackluster response to such a grave threat and much more like an opportunity to slow down the development of would be competitors to me. Do I believe AI poses some risks? Sure, bad actors could use the technology in a myriad of malicious ways and I do believe it's worth discussing some sort of common sense regulations. I just don't believe that a full moratorium on all AI research and spreading fears about the extinction of the human race is a reasonable response to the risks AI poses, and I question the motives behind people like Bill Gates feeding into that hysteria.",
                            "score": 1,
                            "author": "DrunkenGerbils",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "The arguments for AGI extinction risks sound weird at first glance, but they seem airtight to me, after reading them and thousands of counterarguments. I'm not saying we're doomed, just that we'd better be damned careful, starting yesterday. Read them and tell me where you think they're wrong if you care about the topic. The faq at r/controlproblem is a good brief statement. Stampy.ai is another really good one.\n\nThis isn't people just guessing. There's a whole detailed logic for why it's not as safe as it sounds. \n\nRea",
                                    "score": 1,
                                    "author": "sticky_symbols",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Here's a sneak peek of /r/ControlProblem using the [top posts](https://np.reddit.com/r/ControlProblem/top/?sort=top&amp;t=year) of the year!\n\n\\#1: [I gave ChatGPT the 117 question, eight dimensional PolitiScales test](https://i.redd.it/gr5o6o1fgz3a1.png) | [53 comments](https://np.reddit.com/r/ControlProblem/comments/zcsrgn/i_gave_chatgpt_the_117_question_eight_dimensional/)  \n\\#2: [EY: \"Fucking Christ, we've reached the point where the AGI understands what I say about alignment better than most humans do, and it's only Friday afternoon.\"](https://mobile.twitter.com/ESYudkowsky/status/1639425421761712129) | [31 comments](https://np.reddit.com/r/ControlProblem/comments/121qik6/ey_fucking_christ_weve_reached_the_point_where/)  \n\\#3: [DL pioneer Geoffrey Hinton (\"Godfather of AI\") quits Google: \"Hinton will be speaking at EmTech Digital on Wednesday...Hinton says he has new fears about the technology he helped usher in and wants to speak openly about them, and that a part of him now regrets his life\u2019s work.\"](https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/amp/) | [28 comments](https://np.reddit.com/r/ControlProblem/comments/134ozu9/dl_pioneer_geoffrey_hinton_godfather_of_ai_quits/)\n\n----\n^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| ^^[Contact](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| ^^[Info](https://np.reddit.com/r/sneakpeekbot/) ^^| ^^[Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/o8wk1r/blacklist_ix/) ^^| ^^[GitHub](https://github.com/ghnr/sneakpeekbot)",
                                            "score": 1,
                                            "author": "sneakpeekbot"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Well, you seem to think that AI will indeed kill us all very soon based on this comment of yours:\n\n&gt; **When** the AI does eventually end it all, I hope to be viewing the spectacle from a restaurant at the end of the universe.\n\nhttps://old.reddit.com/r/artificial/comments/1403wnb/was_it_a_mistake_for_the_mankind_to_leave/jmualkt/\n\nBesides, isn't everything here considered as credible? I mean, that article by Eliezer Yudkowsky was published by Time after all:\n\n&gt; Because he worked 20 years on AI safety and research. The CEO of OpenAI credits him for his work on substantially accelerating AI development.\n&gt; \n&gt; Because the arguments right now for AI extinction, are literally the same arguments of Eliezer from a decade ago. Reason why he was espousing it for so long, was because it was apparent in the past already, but nobody had interest in listening until now.\n&gt; \n&gt; About AI sentience. It doesn't need sentience at all to cause human extinction. The common scenario as an example of extinction event, as an illustration, is paperclip maximizer. Here:\n&gt; \n&gt; https://www.youtube.com/watch?v=rgrCG8PT6og&amp;t=1s\n&gt; \n&gt; The thing is, do not rely on authority to make conclusions. Listen to his arguments yourself, and evaluate it. This way you will be sure in what is correct and what is wrong. I recommend reading arguments for AI extinction risk.\n&gt; \n&gt; One of the great articles by Eliezer Yudkowsky, released in the beginning of this year: https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmu7aar/",
                    "score": -1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "  That was a sarcastic comment and reference to the Hitchhikers Guide series. I don\u2019t believe AI will kill us all any more than I believe there\u2019s actually a restaurant at the end of the universe that distorts time and constantly replays the apocalypse for the entertainment of its patrons.\n\n   I\u2019ll believe it when Microsoft, Google and OpenAI start investing as much or more of their money into trying to develop AI safeguards. These companies are still pouring billions into research and actively developing AI products for profit. If they truly believed they\u2019re creating the instrument of human extinction, they would do more than ask for a six month moratorium. That sure sounds like a convenient way to stifle any progress would be competitors might make in that time too me. Bill Gates spends hundreds of millions of dollars making people aware of the risk Malaria poses to humanity, but when he believes extinction is imminent he just signs a letter asking the government to do something? I won\u2019t buy it until I see Bill drop at least 100 million on an awareness campaign.",
                            "score": 3,
                            "author": "DrunkenGerbils"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "There are so many ways in which mankind is going to fuck itself before AI does.",
            "score": 2,
            "author": "leanmeanguccimachine"
        },
        {
            "level": 0,
            "comment": "Extreme and silly overreaction\n\nProgress is good",
            "score": 2,
            "author": "MpVpRb",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yes, this.\n\nPlus, GPT and similar ML systems are likely to alter our economic systems quickly because they can resolve many types of queries and generate fictions in various media faster than humans can -- that's a legit issue -- but they do not think and are in no way intelligent. There's no part of them that has intention or goals aside from the ones they are fed.\n\nWhen/if AGI arrives, these worries about intent will become valid current context. Until/unless then, it's a phantom with no technological basis. The doomsaying right now is ludicrous -- it's either clickbait for the uninformed, or the misinformed speculating about things they really do not understand.",
                    "score": 1,
                    "author": "NYPizzaNoChar"
                }
            ]
        },
        {
            "level": 0,
            "comment": "You know life was unrelenting fear, misery, disease, uncertainty, religious zealotry                    for the majority of people in the medieval era yeah? I get that may be hyperbole but like... come on dude.\n\nAlthough, Life 3.0 **is** an excellent book highly recommend.\n\nWould also recommend to *Scythe* books: a young-adult dystopia series which takes place in a post-singularity world where death, disease, scarcity, and even sadness has been all but conquered. Run by the benevolent godlike AGI called the \"Thunderhead\" since it's an emergent intelligence of the 'the cloud' the collective servers of the world and the internet itself.\n\nThe dystopia in that world stems from imperfect humans failing to fit in a prefect world and the AI realizing that it cannot hold humanity's hand, for its own sake.\n\nThe first book sets up the world but the 2 after are extremely fascinating with how it presents AI philosophy, humanity's relationship with death, humanity's relationship with power, and the concerns of stagnation as a civilization in a post-singularity world where people are **literally** immortal and want for nothing.\n\nI think what AI or even AGI will be will be a reflection of humanity as a whole. After all, they'd be trained on data we **all** generate. We may not be worthy. Maybe our creation will be more merciful. Maybe not. But due to human nature, the hedonic treadmill, we will never be satisfied and will always keep advancing. What comes may be inevitable. For better or for worse.",
            "score": 2,
            "author": "Office_Depot_wagie"
        },
        {
            "level": 0,
            "comment": "[\"wouldn't it be cool if you were being mugged and had a sword?  not today!  we're taking this back to the 12th century.\"  -John Caparulo](https://youtu.be/EMOTwnW6bXU?t=383)",
            "score": 2,
            "author": "imissyahoochatrooms"
        },
        {
            "level": 0,
            "comment": "Wow that's a lotta words. To bad I'm not readin em.",
            "score": 2,
            "author": "AcanthocephalaOld889"
        },
        {
            "level": 0,
            "comment": "I am currently using chat GPT to digest this absurdly long post. I\u2019ll be right back.",
            "score": 2,
            "author": "Extreme_Practice_415"
        },
        {
            "level": 0,
            "comment": "Like, I don't remember seeing these many legitimately credible doomsday scenarios before.",
            "score": 1,
            "author": "Block-Busted",
            "replies": [
                {
                    "level": 1,
                    "comment": "Go move to one of elons corpo towns and become a serf if you want to so badly lol",
                    "score": 2,
                    "author": "Nervous-Daikon-5393"
                },
                {
                    "level": 1,
                    "comment": "At the height of the cold war and MAD, the threat of nuclear annihilation was more credible than AI.  I'm not saying that AI isn't a threat, but we have / had many thousands of nuclear warheads ready to fly at a moments notice, an acknowledged civilizational conflict, and leaders that wouldn't wait to use them.  \n\nI'm not nearly as worried about AGI itself as I am about bad actors using current or slightly better AI to make things worse for almost anyone to their benefit.",
                    "score": 2,
                    "author": "beezlebub33"
                }
            ]
        },
        {
            "level": 0,
            "comment": "There\u2019s a fundamental difference between AI, Covid and the Manhattan project: the how. With the former two the risk to life was obvious but nobody is sure *how* AI might kill us all. There\u2019s just a bunch of theories and terror of the unknown. \n\nThe title of this post is more appropriate than the OP possibly intended because of that.",
            "score": 1,
            "author": "letharus"
        },
        {
            "level": 0,
            "comment": "Humans can\u2019t think past Sunday. We are especially short sighted, so it makes sense that we will cause our own demise, in one way or another (war, destroying our planet,\u2026). Inventing AI will just speed it all up.",
            "score": 1,
            "author": "Charming_Foot_495",
            "replies": [
                {
                    "level": 1,
                    "comment": "So I guess this confirms that we should've never left Medieval Era?",
                    "score": 0,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Even if we go extinct, AI is humans 2.0, it\u2019s our creation.",
            "score": 1,
            "author": "Black_RL"
        },
        {
            "level": 0,
            "comment": "Its just public scare so they have a good enough reason to make public models illegal and make it a business only endeavor to keep the American people weak and compliant",
            "score": 1,
            "author": "PsillyScout",
            "replies": [
                {
                    "level": 1,
                    "comment": "Well, there is also this:\n\n&gt; Then read this article by one of AI godfathers, turing award winner, Yoshua Bengio, who signed the extinction letter. https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/\n&gt; \n&gt; If you want to see more human side of him, look at the screenshot of his facebook post. https://twitter.com/danfaggella/status/1662810885595734016\n&gt; \n&gt; If you want to dig deep into AI and potential dangers, i recommend reading a book called Life 3.0, by Max tegmark.\n&gt; \n&gt; And do your own research.\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmvwqna/",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Thank goodness for AI! Here is a slightly shorter summary:\n\n*\"The given sources present arguments and concerns about the potential dangers of artificial intelligence (AI) and its impact on humanity, including the possibility of human extinction. Some experts, including figures from the AI industry, have signed open letters emphasizing the need to prioritize mitigating the risks associated with AI. They compare the urgency of addressing AI risks to other global-scale threats such as pandemics and nuclear war.*\n\n*Eliezer Yudkowsky, a decision theorist and AI researcher, expresses grave concerns about the future of AI and its potential to surpass human intelligence. He argues that if AI reaches a level of superhuman intelligence without proper alignment and control, it could lead to the extinction of humanity. Yudkowsky emphasizes the need for a moratorium on AI development and the shutdown of large training runs to prevent catastrophic outcomes. He believes that the current state of AI alignment is insufficient and that proceeding without adequate safety measures could result in the demise of humanity.*\n\n*Various Reddit threads highlight similar concerns, with individuals expressing the belief that AI poses a significant risk of human extinction within the next decade. These views are supported by the opinions of experts such as Paul Christiano, a former OpenAI employee, and Eliezer Yudkowsky himself, who has been advocating for AI safety for many years.\"*",
            "score": 1,
            "author": "MrEloi"
        },
        {
            "level": 0,
            "comment": "I definitely won't be reading this on a Sunday, but just relax. Considering the endless possibility that AI provides, its development will continue nomatter what. There are just too many people passionate about it and regulations are never created based on whataboutism. AI development may slow down at a point when some people have monetary or political interest in stopping its further improvement. Like, I worked for 9 months as a Photovoltaic Installer and I am of course pro renewable energies and willing to fight global warning. But I didn't work this job to help the planet. I was doing it to help myself by making money. And in my opinion, the same applies to all levels. At some point people will try to stall the development of AI, as long as they can profit from it, but ultimately they will never stop it, so what is the point of worrying about autonomous AI happening, if in my opinion it is bound to happen. But how we regulate it and what we make out of it, I believe still depends entirely on us. And lastly, about the title, I am very happy that I don't have to face the bubonic plague among 100 other reasons I can list about how happy I am we left the Medieval Era behind and very excited about what the future has to offer.",
            "score": 1,
            "author": "ProgrammerNext5689"
        },
        {
            "level": 0,
            "comment": "Ton of people not reading this, then subsequently bashing OP and calling bs.\n\nIf you\u2019re going to form an opinion at least take the time to read the post. \n\nIt\u2019s a little concerning, and I don\u2019t know what to make of it, but I did get to see Sam Altman in a small event at my school talking about precisely this.\n\nSomeone in the crowd asked him \u201care you an optimist, or concerned at all about extinction?\u201d The response was a long pause and him saying he believed there were \u201cgood people in charge\u201d of the policy making, and that he wasn\u2019t terribly concerned.\n\nVery strange experience overall",
            "score": 1,
            "author": "doublemint2202",
            "replies": [
                {
                    "level": 1,
                    "comment": "So you think we're all going to die within this decade due to AI? Why or why not?",
                    "score": 1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Fuck if I know. The CIA is one of the leading research groups in AI right now, and has been. \n\nAny conversation regarding the CIA is going to be with uncertainty and not enough info.\n\nThe development time between gpt 3 and 4 was far smaller than the gap in time between 1 and 2. As soon as someone has access to let\u2019s say \u201cGPT 10,\u201d they probably have access to \u201c11\u201d quickly after that. It\u2019s not unreasonable to say we could be approaching actual, serious, hyper-exponential growth.\n\nConsidering GPT was released to the public (just recently) a year or so after it was actually developed, and I think that classified projects currently exist FAR beyond what is available to the masses.\n\nI can\u2019t claim to believe anything past that \u2014 it\u2019d be a conspiracy theory. All I know is that there\u2019s a lot going on behind the scenes right now, and my personal guess is that people \u201cbehind the curtain\u201d  see some MAJOR advancements in the next year or two (if not already).",
                            "score": 1,
                            "author": "doublemint2202"
                        },
                        {
                            "level": 2,
                            "comment": "https://www.thecipherbrief.com/column_article/how-ai-and-ml-are-impacting-dod-and-cias-future",
                            "score": 1,
                            "author": "doublemint2202"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Absolutely, let's embark on a glorious journey back to the days of feudalism, bubonic plague, and knightly battles. Who needs modern comforts and advanced medicine when we can relish the thrill of serfdom and the occasional public execution? Medieval times, the ultimate solution to all our AI related problems!",
            "score": 1,
            "author": "FutureWasBetter"
        },
        {
            "level": 0,
            "comment": "We \"left the era behind\" because humans innovate and technology ramifies.  \n\nHumans collectively have had millennia of disregarding the advice \"Don't do that, it's too dangerous\" with frankly spectacular results.  Humanity typically benefits from our own bravery and/or foolhardiness--in complete disregard of the fate of any individual fool.\n\nWe've also had millennia of prophets and experts (and mentally ill people) saying \"The end is nigh!\", and in *every* case, they've been wrong. While this is just a corollary of the Anthropic Principle, the psychological effect is that people tend to disbelieve doomsayers.\n\nFinally, I don't understand why you would pose as an alternative the Middle Ages.  The plague reduced the population of Europe by a third.  If anything is going to spur innovation and problem solving, it's epidemic and war (and famine, and death in general--basically the Horsemen of the Apocalypse).",
            "score": 1,
            "author": "Cephalopong"
        }
    ]
}