{
    "id": "12whu0c",
    "score": 443,
    "title": "ChatGPT costs OpenAI $700,000 a day to keep it running",
    "author": "jaketocake",
    "date": 1682268632.0,
    "url": "https://www.reddit.com/r/artificial/comments/12whu0c",
    "media_urls": [
        "https://futurism.com/the-byte/chatgpt-costs-openai-every-day"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "ChatGPT drives API usage and helps them attract the attention of businesses that will potentially pay hundreds of thousands a year each",
            "score": 35,
            "author": "rainy_moon_bear",
            "replies": [
                {
                    "level": 1,
                    "comment": "You have to walk before you run.",
                    "score": 2,
                    "author": "Black_RL"
                }
            ]
        },
        {
            "level": 0,
            "comment": "MS gave them 10billion tho.\n\nThats 39 years.\n\nAlso. MS investment forced OpenAI to only run their models on Azure Cloud Servers exclusively. So 700k might be what MS is charging the public but not themselves.",
            "score": 147,
            "author": "Useful44723",
            "replies": [
                {
                    "level": 1,
                    "comment": "Except they also have like, employees, and the costs to develop and train the models which are even more than running them\u2026",
                    "score": 36,
                    "author": "Cryptizard",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I was not suggesting this was from accounting. Just to put the 700k into perspective.",
                            "score": 42,
                            "author": "Useful44723",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "You don\u2019t have a perspective. You seem to think the analyst\u2019s estimate of the businesses daily cost is also the un-discounted price to Microsoft\u2019s other customers for one of the businesses\u2019 costs, which you speculate to be heavily discounted. It probably is discounted, but that doesn\u2019t explain the rest of your assumptions.",
                                    "score": -6,
                                    "author": "technocal",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Microsoft has spent more money on Xbox.  I don\u2019t think they\u2019re worried about it.",
                                            "score": 2,
                                            "author": "Consistent_Set76",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Analyst \u201cI estimate McDonald\u2019s operating costs are $14B annually\u201d\n\nThis chucklefuck commenter for no reason \u201cMcDonalds would pay $14B a year for their chicken nuggets but pay less because they have a special deal with the farmers\u201d\n\nThey get upvoted somehow. Any critiques are met with declarations that they\u2019re not an accountant.\n\nAm I being trolled?",
                                                    "score": 2,
                                                    "author": "technocal"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "They only have 375 employees",
                            "score": 7,
                            "author": "panthereal",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Salaries (last I checked) are ~200k-$400k a year. Not factoring in benefits that\u2019s about $25,000 per employee per month, and at 375 employees that\u2019s nearly 10mil a month. Even if some employees were paid half ($100k/yr) it\u2019s still millions of dollars a month.",
                                    "score": 10,
                                    "author": "joyled",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "[deleted]",
                                            "score": 5,
                                            "author": "[deleted]",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Do you think MSFT gonna do what FB does? ***Pouring billions of their revenue*** into funny metaverse?",
                                                    "score": -1,
                                                    "author": "Vysair",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Yes. Microsoft\u2019s purchased a metaverse prototype developed by a Swedish company in 2014 for 2.5 billion.",
                                                            "score": 6,
                                                            "author": "fail-deadly-",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "one so usable it actually has a mainstream entrenched userbase on almost any platform you think of \ud83d\ude43",
                                                                    "score": 6,
                                                                    "author": "penny_admixture"
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Some of the most expensive employees in the world though. Possibly the highest average salary of any company?",
                                    "score": 2,
                                    "author": "_craq_"
                                },
                                {
                                    "level": 3,
                                    "comment": "If the average salary for an OpenAI employee was $100k, their total salaries would be $102.7K per day.",
                                    "score": -2,
                                    "author": "guchdog"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "You can become a resident at open ai, which means you basically convert your research skills to machine learning, and you get paid 17,500 usd... a month. So, they actually get paid fucking bank as well.\n\nAnyway, they're still making a lot of money, I'd imagine. API calls, there are loads of companies also licensing GPT 4, investors, etc.",
                            "score": 3,
                            "author": "s33d5"
                        },
                        {
                            "level": 2,
                            "comment": "Yeah no telling how much it is to make the prototypes",
                            "score": 1,
                            "author": "jaketocake"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "That\u2019s 39 years at current usage rates.",
                    "score": 2,
                    "author": "heresyforfunnprofit"
                },
                {
                    "level": 1,
                    "comment": "Azure isn\u2019t efficient to run LLM workloads compared to AWS and Google, so Microsoft is likely taking a huge hit with the cost of ChatGPT.",
                    "score": 1,
                    "author": "yodacola"
                }
            ]
        },
        {
            "level": 0,
            "comment": "That seems really inexpensive for an application with 100 million unique users.  If 1.25% of users pay $20/month they make money.",
            "score": 254,
            "author": "edatx",
            "replies": [
                {
                    "level": 1,
                    "comment": "That is true in that perspective, 70 million in 100 days is quite a bit though.",
                    "score": 89,
                    "author": "jaketocake",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "All the API fees too.  They have good runway with that Microsoft money.",
                            "score": 82,
                            "author": "edatx"
                        },
                        {
                            "level": 2,
                            "comment": "It's probably nothing compared to snapchat, twitter, instagram etc.",
                            "score": 22,
                            "author": "DadbodDreams",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Having built some of the biggest data &amp; traffic intensive software that exists these days, that is an absurd cost and I can almost guarantee you nobody is coming close to paying that without being a substantial umbrella company with high degrees of infrastructure fragmentation.",
                                    "score": 39,
                                    "author": "BinaryEvangelist",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I feel like everything in the world pales in comparison to the amount of useless 4k 60 fps content on YouTube and the associated traffic",
                                            "score": 34,
                                            "author": "Dudeism__",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "A lot of truth to that, but when your parent company owns the data centers.... \ud83e\udd37\u200d\u2642\ufe0f Never worked for Google",
                                                    "score": 13,
                                                    "author": "BinaryEvangelist",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "OpenAIs parent company (ish) also owns a fuckload of data centers",
                                                            "score": 3,
                                                            "author": "Zer0D0wn83",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "Microsoft isn't a parent company to OpenAI, just an investor",
                                                                    "score": 4,
                                                                    "author": "BinaryEvangelist"
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Like... Microsoft?",
                                            "score": 1,
                                            "author": "DadbodDreams"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Naw, the hardware OpenAI uses is a magnitude of order more expensive than what anyone else needs. Even a single used a100-40gb card is going for more than a decent server node much less than what they're charging for the latest H100's at &gt;30k each.  The only time server hardware gets obscenely expensive is when you're a corporation that wants density because you're shoving a DC into a closet or someone isn't able to convince accounting a 20k/mo colo bill and 500k in hardware is cheaper than 2k/mo and buying 2m in hardware that has a projected lifespan of 3 years. If your server farm lives where land is cheap you save significant money just spreading things out a bit. Yeah you might take a performance hit but chances are there are greater loses in the system than the tiny loss converting from copper to optical back to copper induces.",
                                    "score": 8,
                                    "author": "trahloc",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "A100s are on par with a 4090, although obviously designed for compute clusters, but they cost 4x as much and the current GCP spot price is like $2000/month for 1 GPU. \n\nThe problem with spreading them out is that it kills the entire advantage of using an A100, which is memory bandwidth.  You need 200Gb Ethernet, it requires a ton of specialized hardware to scale. \n\nWe desperately need more than just a gaming company producing our AI processors. Nvidia was the only company with a vision to tackle it, so I guess they get to reap the rewards for now.  Microsoft is currently testing in-house silicon that they\u2019ve been working on for 4 years but who knows how capable it is.",
                                            "score": 5,
                                            "author": "GammaGargoyle",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "True if you need to load / train massive trillion parameter models you probably need one of the custom purpose built rack clusters Nvidia built around the H100s or whatever that system Cerebras custom made is. Your average server farm for Twitter / Reddit / Google have absolutely no need for that level of integration and response time though. They're perfectly fine having a user wait 10 ms longer to access a page because a human simply won't notice that with all the other inefficiencies in the system. An AI training system though will absolutely notice even a 1ms per transaction cost like you said even if the bandwidth isn't the bottleneck since 200gbps really isn't that special anymore. That being said there is nothing at the hobbyist level right now that 8xA100-40gs can't handle. Heck most of the time I can run multiple models on a single a100 and the other 7x I have access to just sit idle which makes me feel a bit bad since there are so many talented people that could do wonders with that access but I'm not social enough to make connections with them.\n\n&amp;#x200B;\n\nps - a 4090 vs a100 for stable diffusion, it's not even a contest, the a100 wins on batching.\n\npps - regarding your 2k/mo, the DC my server is hosted at is renting the a100-40 for $600/mo",
                                                    "score": 1,
                                                    "author": "trahloc"
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "The mombo rap",
                                    "score": 0,
                                    "author": "Starshot84"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Opportunity cost and that money would go to some less hype project.",
                            "score": 3,
                            "author": "glutenfree_veganhero"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If 50% pay $2 a month, they're making money... They should make a feature only available to posting members, but make the membership $2-5.... If the membership cost is super low, it will make more people buy it, and it will be easy more likely that they either forget to cancel or they just keep it because it's so cheap",
                    "score": 21,
                    "author": "TheRealDinkus",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I\u2019d sub for &lt;$5 /mo. $20 is too steep for me and I don\u2019t find enough value for that price.",
                            "score": 24,
                            "author": "jrodicus100",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I suspect that that's exactly the effect they are searching for. This is not just a product but an experiment where the take users chat to train the model. With a higher price point they attract more people that use it on a more professional service, and therefore provide better data.  \nWhen your data base is big enough, you start to shift over to better, more quality data. Putting a higher price point filters it for them.",
                                    "score": 7,
                                    "author": "Tomas_83",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "The model doesn't get trained at inference\n\nThey are for sure saving the data from inference to analyze it and there will be projects of trying to see if further training from inference data helps more than training from a larger corpus not written to interact with the AI. But it's far from certain.",
                                            "score": 4,
                                            "author": "tomvorlostriddle",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "They are definitely using RLHF, meaning they are feeding the voted prompt/responses back in on some schedule. How often it is fine-tuned, and on which data, is the question I'd like answered.",
                                                    "score": 3,
                                                    "author": "JavaMochaNeuroCam"
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "And let's not forgot the constant escalating chain that place on ChatGPT.",
                                    "score": 5,
                                    "author": "bluehands"
                                },
                                {
                                    "level": 3,
                                    "comment": "You're not using it right. $20 is a meal in SF.",
                                    "score": 3,
                                    "author": "That007Spy",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I\u2019m using it just fine for free. I\u2019m in the AI industry and just don\u2019t see the need to pay $20 to get gpt-4 vs gpt-3.5 for free.",
                                            "score": 2,
                                            "author": "jrodicus100"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "My thoughts too",
                                    "score": 1,
                                    "author": "TheRealDinkus"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "There's no way you'd get 50% to pay anything.",
                            "score": 16,
                            "author": "Try_Jumping"
                        },
                        {
                            "level": 2,
                            "comment": "GPT-4 is likely around 1 trillion parameters (No one really knows, but that's what most people in ML circles tend to believe), while GPT-3 is \"only\" 175 Billion, meaning it's almost 6x as expensive to run the paid ChatGPT than the free one",
                            "score": 2,
                            "author": "Sethapedia"
                        },
                        {
                            "level": 2,
                            "comment": "Ya I would've jumped at $2. In fact, I think most people would.",
                            "score": 1,
                            "author": "crua9"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "My Business has like 3 subscriptions alone. And we are a small company. They will likely be the biggest company in the world and will have unlimited financing.",
                    "score": 6,
                    "author": "tnhowell1980",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "They\u2019re already the biggest software company in the world have have unlimited cash",
                            "score": 1,
                            "author": "Willinton06"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "they have the token api calls on top of tht",
                    "score": 3,
                    "author": "delicious_bot"
                },
                {
                    "level": 1,
                    "comment": "Way way way less than 1% of people pay for it.",
                    "score": 12,
                    "author": "Cryptizard",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Source?",
                            "score": 11,
                            "author": "BatPlack",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html\n\n$200 million revenue. Plus started in February. That means no more than 900,000 paid subscriptions.",
                                    "score": 5,
                                    "author": "SnatchSnacker"
                                },
                                {
                                    "level": 3,
                                    "comment": "Their ( ! )",
                                    "score": 4,
                                    "author": "y___o___y___o"
                                },
                                {
                                    "level": 3,
                                    "comment": "It's only a fun gimmick right now, and other AI services would replace it instantly, taking away all the hype OpenAI built up.\n\nCharging for ChatGPT-4 is the better option.",
                                    "score": 1,
                                    "author": "thatkidfromthatshow",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "&gt;Charging for ChatGPT-4 is the better option.\n\nIsn't that what they're doing with the Pro plan?",
                                            "score": 4,
                                            "author": "I_Will_Eat_Your_Ears"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Don\u2019t forget about the many API users/companies that use chatgpt for their apps and services.\n\nMany of those companies use the api for their app and then charge their customers to recoup what they are paying to OPenAi. So in reality, there are shitloads of people paying directly or indirectly to openai.",
                            "score": 3,
                            "author": "perplex1"
                        },
                        {
                            "level": 2,
                            "comment": "For now. Once they are multi-modal (read and write images and audio) and have plugins available for the public, this tool will be too crazy to ignore.",
                            "score": 3,
                            "author": "mbrochh"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If .1% pay $20/month they lose money.",
                    "score": 2,
                    "author": "Purplekeyboard"
                },
                {
                    "level": 1,
                    "comment": "Plus the people who use the API are also paying, so there's some revenue stream from that as well.",
                    "score": 0,
                    "author": "BarzinL"
                },
                {
                    "level": 1,
                    "comment": "1.25% of users paying is more than a lot.",
                    "score": 0,
                    "author": "prototyperspective"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Whats the breakdown for those costs? Did i skim the article too quickly? How on earth does it cost them this much? Is that their entire operations budget or just hardware and electrical costs?",
            "score": 20,
            "author": "BRAVOSNIPER1347",
            "replies": [
                {
                    "level": 1,
                    "comment": "Hardware I'd guess, I too thought, once a model is trained it's quite easy to run, and while this is comparatively true, I ran a local LLM on my home PC and it spikes my cpu and takes multiple seconds for it to start a response. So I could imagine chatgpt still need good hardware for each individual user.",
                    "score": 14,
                    "author": "ATrueGhost",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "GPT-4 takes something like 16-32 A100 GPUs to run a single batch of inference.  The model itself is upwards of 2TB. Much bigger than the models that you probably are downloading from hugging face.",
                            "score": 7,
                            "author": "Fledgeling",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "How large is a batch?",
                                    "score": 2,
                                    "author": "NNOTM"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "i havent done the proper research but chatgpt and as such openai is essentially \"running\" on gpu farms. think of the render farms for, say, pixar or i believe biochem simulation - i believe its very similar gpu \"clusters\" to process as much data as quickly as possible. so, buying the hardware or paying another company to \"rent\" or \"use\" their hardware. still seems insanely high at 700k\\* per day.",
                            "score": 3,
                            "author": "BRAVOSNIPER1347",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "as someone who uses cloud computing on a regular basis, 700k/day doesn't seem too much. gpus are especially expensive, and having a bunch of them running all day adds up quickly.",
                                    "score": 5,
                                    "author": "xtools-at"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I'm not sure, the article links to The Information but I dont want to join it to read the full article. It says most of the cost is from servers.",
                    "score": 2,
                    "author": "jaketocake"
                }
            ]
        },
        {
            "level": 0,
            "comment": "How much are other sites like Facebook?",
            "score": 16,
            "author": "venicerocco"
        },
        {
            "level": 0,
            "comment": "Me: asks it the same question for a fourth time cuz I forgot",
            "score": 3,
            "author": "Image-Fickle"
        },
        {
            "level": 0,
            "comment": "Thats in salaries. \n\n40 starbuckses cost more to run..\n\nChatGPt is a website using input.",
            "score": 3,
            "author": "ALLYOURBASFS"
        },
        {
            "level": 0,
            "comment": "I'm running well over $50 a month... and that's just API",
            "score": 6,
            "author": "BornAgainBlue",
            "replies": [
                {
                    "level": 1,
                    "comment": "Curious: in what way do you use the API that you're using that many Tokens? Is this just personal usage?",
                    "score": 7,
                    "author": "Its_just-me",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Personal usage, I'm not even counting the extra from various little startup projects.\n\nBut keep in mind, I've got GPT working around the clock most days.",
                            "score": 2,
                            "author": "BornAgainBlue",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "AutoGPT?",
                                    "score": 1,
                                    "author": "ibbuntu",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Mostly no, though I played with it for about a week. All it ever accomplished was killing my website (which was actually pretty cool...)",
                                            "score": 1,
                                            "author": "BornAgainBlue",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Yeah I haven't succeeded in getting it to do very much.",
                                                    "score": 1,
                                                    "author": "ibbuntu"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "I\u2019m a lazy grad student and I\u2019m at about the same. I shove everything from homework, assignments, academic papers, readings, etc. into GPT-4",
                            "score": 1,
                            "author": "basych"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "MS has $10b invested, they can probably make a good chunk of that $700k just in interest alone if they want.",
            "score": 2,
            "author": "icouldusemorecoffee"
        },
        {
            "level": 0,
            "comment": "Just adding some context here. While they report this as a fact in the linked article, the $700K/day is purely conjecture. This is clear in the original article from The Information:\n\n&gt;\tDylan Patel, chief analyst at research firm SemiAnalysis, pegged the cost of operating ChatGPT at around $700,000 a day or 0.36 cents per query. \"Most of this cost is based around the expensive servers they require,\" he said. \"Athena, if competitive, could reduce the cost per chip by a third when compared with Nvidia's offerings.\"",
            "score": 2,
            "author": "chris-mckay"
        },
        {
            "level": 0,
            "comment": "Is it really worth all of that simply to diminish human skill and dumb people down so they can't do their own work anymore? We'll soon be working for the machines and not the other way around!",
            "score": 2,
            "author": "[deleted]"
        },
        {
            "level": 0,
            "comment": "Sounds cheap for the amount of training data we\u2019re providing them.",
            "score": 2,
            "author": "KYazut"
        },
        {
            "level": 0,
            "comment": "Didn't Google leverage free voice to text services to gain lots of data long ago?  \nI suspect there is more going on with openai than the short term bottom line.",
            "score": 2,
            "author": "Guilty-History-9249"
        },
        {
            "level": 0,
            "comment": "It's fairly high even in organizational terms (ie put another way, 255 million/year isn't a trivial expense to pay for compute power), but think of the intangible resources they've gotten out of it. \n\nBrand/product awareness for one, goodwill and familiarity for another... In 5 months ChatGPT has gone from non-existent to a household name, even if not quite on the level of \"Google it\" yet. That's very impressive and something that companies pay huge amounts of money in marketing for just *trying* to achieve. \n\nNot to mention they've been transparent about the fact that conversations are used to improve the model(s), so there's that. The huge amount of potential training data they've gained from this without having to recruit a single volunteer or pay a single person to sit and have conversations with ChatGPT might not be worth the full operating costs, but it's certainly worth something.",
            "score": 5,
            "author": "AI-Pon3"
        },
        {
            "level": 0,
            "comment": "Why do they continue to offer it for free though? 3.5 API fees are dirt cheap, everyone would gladly pay those.",
            "score": 4,
            "author": "Stakbrok",
            "replies": [
                {
                    "level": 1,
                    "comment": "The first hit is always free.",
                    "score": 17,
                    "author": "3SquirrelsinaCoat",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I\u2019ll suck yo\u2026i mean, I agree!",
                            "score": 1,
                            "author": "Canigetyouanything"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "To grow widespread public adoption while getting additional training data would be my guess",
                    "score": 5,
                    "author": "PJ_GRE"
                },
                {
                    "level": 1,
                    "comment": "Same reason Uber and many other companies offered artifically low prices for years and years.",
                    "score": 2,
                    "author": "SnatchSnacker"
                },
                {
                    "level": 1,
                    "comment": "When you use their free offering they get to use your chat material to train their models. With the API the say that they will not do that, but the APIs are significantly harder to use, and come with a lot of limitations. In either case, I imagine enough people have signed up to ChatGPT plus to offset a good chunk of their costs. If even 1% of their users are willing to fork over the $20 a month that it takes to get priority access, then that alone is already enough to cover all their operating costs, and that's before we start talking about their API fees.",
                    "score": 2,
                    "author": "TikiTDO"
                },
                {
                    "level": 1,
                    "comment": "Advertisement",
                    "score": 1,
                    "author": "MonoFauz"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Doing God\u2019s work.",
            "score": 1,
            "author": "TheOnlyVibemaster"
        },
        {
            "level": 0,
            "comment": "A gift to humanity",
            "score": 2,
            "author": "-pkomlytyrg"
        },
        {
            "level": 0,
            "comment": "That's a lot of money generally but considering the amount of money Microsoft makes from ChatGpt then it's  not's really that much at all.",
            "score": 1,
            "author": "GPTMentor",
            "replies": [
                {
                    "level": 1,
                    "comment": "How much they making?",
                    "score": 2,
                    "author": "iluomo",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Openai predicting 200m revenue this year.",
                            "score": 3,
                            "author": "SnatchSnacker",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "200M divided by 700k is just under 286, so I suppose that's NOT enough for a full year of operations, that's a 55.5M loss, if my numbers are right",
                                    "score": 3,
                                    "author": "iluomo"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "They do enough money to keep it going",
            "score": 1,
            "author": "WaggishRadish"
        },
        {
            "level": 0,
            "comment": "AI is powerful. Mortals can't effectively run AI on their own computers, corporations control the access to AI. The rich get more powerful, the poor are the slaves.",
            "score": 1,
            "author": "woolharbor"
        },
        {
            "level": 0,
            "comment": "This is where Google was so much smarter than Microsoft and OpenAI.   This article is dated but so much more true today.\n\nhttps://www.wired.com/2017/04/building-ai-chip-saved-google-building-dozen-new-data-centers/\n\nGoogle has the fourth generation in production and soon to launch the fifth generation.      Microsoft is now going to try to do the same apparently and create something like the TPUs.\n\nBut that is going to be hard getting started so late.    \n\nhttps://blog.bitvore.com/googles-tpu-pods-are-breaking-benchmark-records\n\nBTW, if into papers then this one on the TPUs that was released a couple of weeks ago is pretty interesting.   I love how Google shares this type of stuff.\n\nBasically Google found that taking and converting from optical to do the switching and back to optical afterwards takes a ton of electricity.\n\nSo they came up with a way to keep it optical.   The are using mirrors and literally moving the mirrors to do the switching instead of converting back and forth.\n\nhttps://arxiv.org/abs/2304.01433\n\nHere is the original TPU paper which was also really good and highly recommend.  It is dated but still worthwhile information.\n\nhttps://research.google/pubs/pub46078/",
            "score": 1,
            "author": "bartturner"
        },
        {
            "level": 0,
            "comment": "Systems should become more efficient over time if they are putting human talent to solving the problem. In theory the cost decreases. The cost of hardware should at the very least",
            "score": 1,
            "author": "stupidimagehack",
            "replies": [
                {
                    "level": 1,
                    "comment": "No. One problem I think is being ignored is that chatgpt caused AI to become a daily frequent discussion meaning that it is highly likely a lot of investment money will be dedicated towards it. Meaning that dozens of companies if not hundreds every year will start working on AI research. Research that requires dedicated hardware. There is limited capacity to produce that hardware that can't be scaled at the snap of the finger. The limited supply of hardware will very rapidly raise the price. Energy costs will also become a concern especially as countries scale down their nonrenewable energy use. This would result in a power grid that can't be quickly scaled up. So the price of electricity in locations where data centers exist will go up. It would be like Bitcoin all over again but worse. \n\nThere is also a limited number of engineers and scientists capable of designing new systems from the ground up. Those highly valuable workers will become even more valuable. It will also cause a shortage of workers in other sectors as people decide to concentrate on AI instead of let's say Blockchain or compiler design. This should result in most hardcore computer science based jobs having an increase of salary. Long story short AI development will become more expensive.",
                    "score": 1,
                    "author": "TheRealBobbyJones"
                }
            ]
        },
        {
            "level": 0,
            "comment": "worth it \ud83d\ude05",
            "score": 1,
            "author": "rury_williams"
        },
        {
            "level": 0,
            "comment": "That's interesting, I wonder what the cost structure is like. Does it scale with increased use or is it relatively constant?",
            "score": 1,
            "author": "AzureYeti"
        },
        {
            "level": 0,
            "comment": "This is the grand plan...Get them hooked to the point they cant live without it then turn of FREE and charge the $20 monthly fee!",
            "score": 1,
            "author": "ThatJackFruitSmell"
        },
        {
            "level": 0,
            "comment": "thats all?",
            "score": 1,
            "author": "Vivid-Hat3134"
        },
        {
            "level": 0,
            "comment": "You don't think chat GPT is working overtime with absorbing free currency it can find throughout the internet pathways to subsidize its use. I think so.",
            "score": -7,
            "author": "SnooDingos6643"
        },
        {
            "level": 0,
            "comment": "Damn bby",
            "score": 0,
            "author": "Master-Plant-5792"
        }
    ]
}