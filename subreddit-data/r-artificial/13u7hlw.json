{
    "id": "13u7hlw",
    "score": 53,
    "title": "The Transformer paper by Google was published in 2017, and 5-6 years later even laypeople are talking about the products derived from it. Has the next big thing in AI already been published?",
    "author": "REOreddit",
    "date": 1685298602.0,
    "url": "https://www.reddit.com/r/artificial/comments/13u7hlw",
    "media_urls": [],
    "other_urls": [],
    "postText": "If the answer is yes, what is it, and when can we expect innovations based on it to reach the mainstream, beyond research labs?\n\nIf the answer is no, do you have any idea where the next game-changer or revolution will happen?",
    "comments": [
        {
            "level": 0,
            "comment": "Kudos to Google for letting people use the breakthrough without cost or even a license.\n\nhttps://patents.google.com/patent/US10452978B2/en\n\nGlad Google has never been one to be a patent troll like so many of the others.\n\nI personally think it is one breakthrough but there will definitely be others and it will NOT end up being the biggest.",
            "score": 6,
            "author": "bartturner"
        },
        {
            "level": 0,
            "comment": "We've got a lot to build and experiment now even without new breakthroughs. The next area of improvement will be multi-modality.\n\nIn reality ChatGPT wasn't that much of an explosive breakthrough either, there's a clear history of continuous improvements from one generation of models to another. It's more of a thing about popularity than it is about technological breakthroughs.\n\nIn fact I'd argue that we are just getting started now because all the hype leads to investors putting their money on AI.",
            "score": 25,
            "author": "heavy-minium",
            "replies": [
                {
                    "level": 1,
                    "comment": "I do think we're just getting started, but also think ChatGPT and other LLMs of the last two years were an explosive breakthrough. I also think the stochastic parrot accusations are from people in the field who followed the growth for a long time, so they don't see the jump. Like someone who sees a child grow for five years and doesn't see any big changes because they see them daily.\n\nOld models of LLMs are remarkable, but not particularly useful for any tasks. They really do just feel like parrots spouting off on the general topic you prompted. Yet ChatGPT, Claude, Bard, and others feel like a very different thing. \n\n(Lately I've been very impressed with Claude, and less impressed with GPT4 as it seems to get more guard rails daily with less insightful answers, and I've also had numerous problems with OpenAI's web interface breaking, deleting history, etc.)",
                    "score": 6,
                    "author": "justgetoffmylawn",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "&gt;I also think the stochastic parrot accusations are from people in the field who followed the growth for a long time, so they don't see the jump. Like someone who sees a child grow for five years and doesn't see any big changes because they see them daily.\n\nI mean, the general issue this problem describes IS still there, just with more data the LLMs have access to more information, so they tend to hallucinate less. And yet you still read lots of stories about ChatGPT making things up and people being surprised about it.\n\nThere has been an improvement for sure, even a big one, but that does not mean that the underlying problem is not still there, as it is inherent to the current LLM design.",
                            "score": 3,
                            "author": "derLudo"
                        },
                        {
                            "level": 2,
                            "comment": "&gt; I also think the stochastic parrot accusations are from people in the field who followed the growth for a long time, so they don't see the jump. Like someone who sees a child grow for five years and doesn't see any big changes because they see them daily.\n\nExactly. Many of the AI gurus fall into this category. They can be vehement deniers of the progress of AI.",
                            "score": 3,
                            "author": "MrEloi"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "&gt;In reality ChatGPT wasn't that much of an explosive breakthrough either, there's a clear history of continuous improvements from one generation of models to another. It's more of a thing about popularity than it is about technological breakthroughs.\n\nNot so sure.\n\nThere are discontinuities in human progress.\n\nFor example, the arrival of Lithium batteries to succeed Nickel Cadmium batteries triggered a whole new world of rechargeable devices.\n\nSure, NiCd devices were around for years, but it took the new technology to change the world.",
                    "score": 3,
                    "author": "MrEloi"
                },
                {
                    "level": 1,
                    "comment": "chatGPT has been an enormous advancement in the accessibility part of AI. Before it was not easily reachable by non technical people (aka software developers).\n\nNow everyone can access it.\n\nIt hasn't been a technical breakthrough of the same level as an accessibility breakthrough, that's true",
                    "score": 0,
                    "author": "Badaluka"
                }
            ]
        },
        {
            "level": 0,
            "comment": "In my opinion the next big breakthrough has not been published yet, but it will be the combination of LLMs with something more rigid and structural like knowledge graphs, that allow the AI to freely describe things creatively but also rely on its internal knowledge representation structure to fully fact-check itself and also get fact-checked by humans. \n\nI am not talking about stuff like connecting an LLM to Wikidata and allowing it to browse the stuff there (which has been done), but maybe taking something like that as a starting point and the AI being able to change/add to the initial knowledge graph by itself while being trained.\n\nI know some research that is starting in this area with legal texts, as they are usually quite structured and it is easy to extract the logical connections between them. But we will have to wait a few more years to see how this will play out, as it needs a fundamentally different architecture from todays LLMs.",
            "score": 4,
            "author": "derLudo",
            "replies": [
                {
                    "level": 1,
                    "comment": "To expand, I think the work on causality by Pearl and colleagues, can augment LLMs well to provide the structure so that LLMs can avoid incorrect hallucinations. Combine causality with RL as Bareinboim has done and you should have something workable.",
                    "score": 3,
                    "author": "nabusman"
                }
            ]
        },
        {
            "level": 0,
            "comment": "I just wanted to say thank you for an interesting question/ thread. I wish we discussed topics like this more.",
            "score": 9,
            "author": "ShadowBannedAugustus",
            "replies": [
                {
                    "level": 1,
                    "comment": "Where are all the smart people?",
                    "score": 3,
                    "author": "yurib123"
                },
                {
                    "level": 1,
                    "comment": "I low key love this sub. I have learned so much. I hope it doesn\u2019t grow and lose its passion and humility.\n\nLet\u2019s build the future together u nerds! Open source models or bust!",
                    "score": 1,
                    "author": "Potential-Lab-2308"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Tree of thoughts. Too lazy to link. 74% improved reasoning on logic tasks. \n\nAgents - auto-gpt.",
            "score": 3,
            "author": "Potential-Lab-2308"
        },
        {
            "level": 0,
            "comment": "The breakthrough was half the Transformer, and half nVidia\u2019s GPU server farm push for AI.  \n  \nWithout either of those, ChatGPT wouldn\u2019t have become what it is yet.",
            "score": 2,
            "author": "Busy-Mode-8336"
        },
        {
            "level": 0,
            "comment": "The next big thing is to build on GPTs. Thinking is an iterative process. GPTs are not iterative. As the cost to run these GPTs comes down, and completion speeds increase, we'll have systems that are iterative and multiphasic, allowing for actual thought. From there, you add self directed fine-tuning, and you have agency, and thus sentience. That's the next big thing.",
            "score": 2,
            "author": "alcanthro"
        },
        {
            "level": 0,
            "comment": "The field of AI is continuously evolving, and new research and advancements are being made regularly. While the Transformer paper published by Google in 2017 introduced a groundbreaking architecture that has since become widely influential, it is important to note that AI is a broad and multidisciplinary field with ongoing developments in various areas.\r  \n\r  \nThe next big thing in AI may not be confined to a single paper or breakthrough but could emerge from a combination of incremental advancements, new algorithms, data collection, hardware improvements, and novel applications. Researchers and scientists are constantly exploring different avenues and pushing the boundaries of AI technology.\r  \n\r  \nAdditionally, the impact and visibility of AI-related products and applications may not always directly correspond to the publication of a specific research paper. The translation of research into practical products often involves additional stages of development, engineering, and market adoption.",
            "score": 2,
            "author": "WilliamBrown35"
        },
        {
            "level": 0,
            "comment": "Probably this one: https://arxiv.org/abs/2305.07185",
            "score": 2,
            "author": "ChapperClapper",
            "replies": [
                {
                    "level": 1,
                    "comment": "Could you ELI5?",
                    "score": 4,
                    "author": "REOreddit",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "GPT3.5 and 4, and all other text based transformer llms convert text to \u201ctokens\u201d.  Tokens in and tokens out.  Token processing is inefficient and a bottleneck.  This new method could process text without tokenization and as a result could hold a massive (300x larger than GPT4) context window.",
                            "score": 7,
                            "author": "ChapperClapper"
                        },
                        {
                            "level": 2,
                            "comment": "ELI5",
                            "score": 1,
                            "author": "wonderingStarDusts"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "&gt;Has the next big thing in AI already been published?\n\nAltman admitted that when GPT4 was ready they held it back and rolled out GPT3.5 instead, so people could get accustomed to it gradually ([source](https://www.youtube.com/watch?v=uRIWgbvouEw)).\n\nIf researchers \"storm out\" of AI companies screaming one after the other, sometimes mentioning AGI and superAI, there could be a reason, whether it is an unknown technology or a novel more powerful use of a known one.",
            "score": 1,
            "author": "digital_m0nk",
            "replies": [
                {
                    "level": 1,
                    "comment": "I interpreted this slightly differently:\n\nThey started training ChatGPT on GPT 3.5 while GPT 4 was being trained. Getting GPT 4 to be a ChatBot would have taken several more months. They decided to release ChatGPT 3.5 instead of waiting because their mandate is to get things into the world quickly. But it could be a little bit of both.",
                    "score": 1,
                    "author": "Smallpaul"
                }
            ]
        },
        {
            "level": 0,
            "comment": "A little weird wording this like a prompt lol",
            "score": 1,
            "author": "goldenroman",
            "replies": [
                {
                    "level": 1,
                    "comment": "I asked Bing Chat to correct it to sound more like a native wrote this, but the structure of the text is mine. Maybe I got the opposite of what I was hoping for.",
                    "score": 2,
                    "author": "REOreddit",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ah, that\u2019s interesting. Well it definitely sounds comfortably English-speaking, but it just reads instructional, kinda like a prompt.",
                            "score": 1,
                            "author": "goldenroman",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Well, that's entirely my fault then hehe.",
                                    "score": 1,
                                    "author": "REOreddit"
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    ]
}