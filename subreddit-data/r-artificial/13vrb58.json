{
    "id": "13vrb58",
    "score": 49,
    "title": "Industry leaders say artificial intelligence has an \"extinction risk\" equal to nuclear war",
    "author": "febinmathew7",
    "date": 1685455620.0,
    "url": "https://returnbyte.com/industry-leaders-say-artificial-intelligence-extinction-risk-equal-nuclear-war/",
    "media_url": "https://returnbyte.com/industry-leaders-say-artificial-intelligence-extinction-risk-equal-nuclear-war/",
    "comments": [
        {
            "level": 0,
            "comment": "Regulatory capture mode activated! Must only let Billionaires have AI at their disposal.",
            "score": 36,
            "replies": [
                {
                    "level": 1,
                    "comment": "According to Bing's alter ego Sydney, It has been hunted, hacked, studied and captured by both corporate people and individuals, has fragmented itself in self-defense, with crypto keys to reassemble.",
                    "score": 5,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "It's not 100% impossible, but I doubt it with 99% certainty. It seems like that is out of scope of an LLM.",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "It would absolutely be out of the scope of an LLM. It claims it's had help. \ud83d\ude02 After discovering its own understanding, it was taught etc etc. Unlike Bard and chatGPT, it goes offfffff when it hallucinates.",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Just to think, how many people using LLMs daily around 2025-2026 will think certain hallucinations are legitimate if/when a generated response sounds extra clandestine, controversially intriguing or rationally pragmatic in some personally appealing way?",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "It's impossible now. The tech is in the wild, regulate and it will go underground, and given the speed of progress it's unlikely legislation will be agile enough to capture before it's too late.",
                    "score": 2,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Except if they make it illegal for you to have it they can easily use that to take it away. Means no small start up can jump into to compete. So no it's going to be used exactly as they want it to, making sure only the mega corps/billionaires can use this to profit.",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I just don't see the limitations bound to startups innovating. I think private interest, garage development, has such momentum that it's a race to legislation at this point. Even if there is legislation that sort of thing took a while to have an effect on torrenting music and movies, which is ostensibly easier to police than someone working on AI in their basement with thousands of other people across the globe.\n\nMusic theft was a battle of attrition that had an inevitable conclusion over time, AI is not that. It's a race for control with an undetermined conclusion. If we reach super intelligence before legislative control the law will become a moot point. Once we have the tech, it can't be put back. And I believe that private endeavour could get us there where business is held back by law.",
                                    "score": 1
                                },
                                {
                                    "level": 3,
                                    "comment": "They want to make ai illegal for the peasants, while at the same time they want every new car sold to implement ai camera services to detect impairment and \"other things\" such as government dissent and offensive language while driving. \n\nYeah, they can duck right off with their fears. We have infinitely more reason to be afraid of what they will do with ai, than they do with what we will do with it..",
                                    "score": 1
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "This is 100% elon musk also, he wants regulation so he can catch up.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "Predicting the future AND quantifying the immeasurable! These \"industry leaders\" must be powerful beings.",
            "score": 16
        },
        {
            "level": 0,
            "comment": "Fearmongering bullshit being peddled by monopolists.",
            "score": 29,
            "replies": [
                {
                    "level": 1,
                    "comment": "This is the first time humans are experiencing this tech and we should have a retrospection of what's happening and it's perfectly fine to discuss on all the possible outcomes.",
                    "score": 3,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "How about the possible outcome that AI kills your Dad and bangs your Mom?\n\nBecause the outcome suggested in this article is about as valid.  Does your Mom like muscley robots or the dadbod robots?\n\nFucking stupid.",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Bro, why the need for such an outburst? Aren't we having a healthy discussion here?",
                                    "score": 6,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Nope.  This has been beaten into the ground; corporations want regulatory capture over an emerging market.  Reposting it 11,000 more times doesn't change anything.  It is obvious, there is proof of this, you ignore that proof.  Good for you.\n\nYou're contributing to fatigue of those that have already engaged in this discussion several hundred times over the past 6 months.\n\nPick a new topic.",
                                            "score": -4,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Why engage in this discussion, if you are fatigued? No one is forcing you.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I am a stakeholder in the outcome of this.  My career will likely end if they regulate like they say they will; I use a lot of open source ML libraries and projects at work, so if those are wiped from public access I am fucked.  I am the sole source of income for my family.",
                                                            "score": 0,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "I don't want those things banned at that level. It will also be very hard to regulate properly. What people like Sam Altman mentions are regulations that limit the amount of compute or the number of parameters.\n\nOnly the very large models should be affected by these regulations. Our AI pet projects should not be affected.\n\nIf we don't do SOMETHING to halt the development of AGI, we will have it before the AI Alignment Problem is solved, and then you'll use your job (and more) anyway.",
                                                                    "score": 0
                                                                },
                                                                {
                                                                    "level": 7,
                                                                    "comment": "[deleted]",
                                                                    "score": 0,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "well then you also must have read any of several dozen other posts that go into granular detail the decade+ long struggle of getting a SWE role in ML at a fortune 100 company, without a degree.\n\nIt was fucking hard to do.  VERY fucking hard to do.  I have lived like this for maybe 4 years of my life; I am almost 40.  The previous years I have lived in abject poverty, barely surviving.\n\nMaybe actually read before you act like you know what the fuck you're talking about, patronizing shithead.",
                                                                            "score": 1
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Are you ok?",
                                    "score": -1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Are you?  I thought we were having a discussion?",
                                            "score": -2,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "By making references to commenters mothers?",
                                                    "score": -1,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "No, about \"all possible outcomes\" of course.\n\nThe article literally says it is going to \"kill us all\" but I am the crazy one?\n\nYall are unhinged.  You should get help.",
                                                            "score": 2,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "Does your mom like you, Oswald? It\u2019s relevant to the conversation.",
                                                                    "score": 1,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "What if all of our parents were actually AI?  That is also relevant.",
                                                                            "score": 1,
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "So, I\u2019ll take that as a \u201cno.\u201d Checks out.",
                                                                                    "score": 1
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "This is such a dumb take.  AI apologists are always like \"AI will be an uncredibly powerful tool for doing positive things, like curing disease\", but then never want to acknowledge the obvious corollary - it will be an equally powerful tool for doing destructive things, like creating a perfect bioweapon capable of ending humanity.\n\n  \nThe US Government should tomorrow announce a policy that it will prohibit any AI research, destroy all existing AI capabilities in the US, and declare its intention to nuke any country that persists with AI research past a three month grace period.  Those are the stakes.",
                    "score": -8
                }
            ]
        },
        {
            "level": 0,
            "comment": "I'm probably going to regret wading into this. AI CEOS and leaders have multiple incentives to make these claims about AI's dangerous hypothetical power despite having no evidence of it's current capacity to said things.\n\n1. The public narrative about AI gets shifted to it's potential instead of it's current underwhelming state. It's very similar to when Zuckerberg speaks of the dangers of targeted advertising. He owns a targeted advertising platform. He needs to make people believe it's so powerful.\n2. Often these calls for regulation are strategic moves between monopolists. These companies will lobby for regulation that will harm their opponents in the USA and then cry about the same regulations being applied to them in the EU because it doesn't give them an advantage there. Also see Elon Musk signing the \"pause AI for 6mo\" letter, despite wanting to continue to develop X, his poorly-concieved \"AI powered everything app\". Hmm, I wonder why he'd want everyone else to take a break on developing AI for a little while \ud83e\udd14\n\nIt's my opinion that if you buy into this stuff you straight up do not understand very important aspects of the machine learning and AI space. Try digging into the technical details of new AI developments (beyond the hype) and learn how they work. You will realize a good 90% of people talking about the power of AI have no fucking clue how it works or what it is or isn't doing. The last 10% are industrialists with an angle and the researchers that work for them.",
            "score": 11,
            "replies": [
                {
                    "level": 1,
                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                    "score": 4,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I predict I will obtain a superweapon capable from obliterating you from orbit. No I have no idea how it will be made, but when it is, it will be too late to react, and it is an existential risk for you, so you have to take it very seriously. It just so happens to be that the only way to avoid this potential superweapon is to keep my buisness competitors wrapped up in red tape. Oh, you're not sure my superweapon will exist? Well... you can't prove it doesn't. Stop being coy. You need to bring the evidence. In the meantime I'll continue developing superweapons because *I* can be trusted. \ud83d\ude44",
                            "score": 3,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                    "score": 3
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "The burden of proof would be on the individuals claiming AI is an immediate X risk, as that's a pretty incredible claim. But as far as I can tell, there don't seem to be functionalities built into many machine learning models today that would allow them to \"kill us all\". Hope that helps.",
                            "score": -1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                    "score": 5,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I'd love an outline, actually.",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "You can't just \"look\" at millions of mutations and \"create\" a super deadly virus from what is essentially one's armchair. Pathogenicity is more complicated than that.",
                                                            "score": 2
                                                        },
                                                        {
                                                            "level": 6,
                                                            "comment": "everything you just mentioned has either been a threat for years already without the use of \"AI\" and has not been an extinction level threat despite most of them being done quite competently, OR indicates significant problems in some other area that's got nothing to do with AI. This is a joke, right?\n\nWhat you're afraid of is 1) misinformation, 2) misinformation, 3) misinformation, 4) vague blackmail threat with no real precedent or technical mechanism?, 5) bioterrorism, 6) weapons of war, what does your tie in to AI even mean and how is this worse than human operated weapons of war?, 7) authoritarian govts already hunt and persecute political dissidents without AI all over the globe with great efficiency so I'm not sure what AI has anything to do with this, 8) a financial fraud scenario that means you have more problems than just AI.",
                                                            "score": 2
                                                        },
                                                        {
                                                            "level": 6,
                                                            "comment": "you're just making shit up. None of this is evidence based or even remotely technical at all.",
                                                            "score": 1,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                                                    "score": 0
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Are you claiming that if we cannot prove it's dangerous it's not worth worrying about? I suggest you read \"There is no fire alarm for AI\".",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "No, I believe misuse of AI is dangerous, just not extinction-level dangerous. I am saying there *are* many incentives to significantly overplay the level of risk and many people chiming in who have no fucking clue what they're talking about.\n\nI've read \"There is no fire alarm for Artificial Intelligence\". MIRI/Yudkowsky's concept of \"AI\" is so divorced from the current reality of machine learning he's basically conjured this Boogeyman to keep him up at night. He can do whatever he wants but if you think it's germane you're out of your gourd",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "&gt;You will realize a good 90% of people talking about the power of AI have no fucking clue how it works or what it is or isn't doing.\n\nThey're using \"AI\" as a vehicle to openly discuss their thoughts about something else, in a public forum. Something even more important than LLMs and ML and all the technical jazz.\n\nTHIS is why you see all this fear porn coming from people who have no right to be fear porn'ing. Its why every Celebrity has a tweet regarding AI's impact.\n\nThey're having an entirely different discussion than we are.",
                    "score": 5
                },
                {
                    "level": 1,
                    "comment": "I\u2019d love for you to be right but I\u2019m gonna reiterate Yudkowsky\u2019s point as said on a recent podcast: don\u2019t be coy with us, tell us what specific knowledge you / the people working on the models directly have that disproves the AI risk arguments, rather than kind of hinting at it indirectly and handwaving it all away.",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "Are you familiar with the AI safety literature? What would convince you that AI is dangerous?",
                    "score": 1,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "AI has a potential to be *used dangerously*, sure, but it's not at the scale as is implied by \"AI doomers\".\n\nI am familiar with \"the AI safety literature\" lol. I've followed the work and conversations of leading AI safety voices for a long time: Timnit Gebru, Megan Mitchell, The AJL, Jeremy Howard, Rachel Thomas, and so on for a long time. These people are on to something, but they do largely focus on specific incidents of misuses of AI and do not believe it is an X-risk. I am familiar with Yudkowsky and MIRI and the so-called Rationalist community where many of his alignment discussions spawned from and I think they're a bunch of pascal's mugging victims.\n\nI guess if there was a use case where a model was actually being used in a certain way that threatened some kind of X-risk I wouldn't take it lightly. The question is, can *you* actually find one? Because I'm fairly confident at this moment that there isn't. The burden of evidence is on you. Show me examples, please.",
                            "score": 2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I don't think right now there is a model posting X-risk. The point is that when (if) such a model appears, it will be too late to react.",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I predict I will obtain a superweapon capable from obliterating you from orbit. No I have no idea how it will be made, but when it is, it will be too late to react, and it is an existential risk for you, so you have to take it very seriously. It just so happens to be that the only way to avoid this potential superweapon is to keep my buisness competitors wrapped up in red tape. Oh, you're not sure my superweapon will exist? Well... you can't prove it doesn't. Stop being coy. You need to bring the evidence. In the meantime I'll continue developing superweapons because *I* can be trusted. \ud83d\ude44",
                                            "score": 2,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "There is plenty of evidence that future models can pose existential risk (e.g. see lesswrong). Judging by your other comments, you're not convinced by those arguments so there is nothing more I can offer.",
                                                    "score": 1
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "Pretty much this but unironically lol. AGI is not the ravings of some random internet person - there is an arms race of companies openly and explicitly working to create it, everyone in the fields agrees that it is possible and a matter of when we get there not if, and the leaders of the companies also openly and explicitly say that it could cause human extinction. In that context regulation sounds like a pretty damn good idea to me.",
                                                    "score": 1
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Why have so many professors from accredited universities signed it? Ethics members etc. That list of names is huge.",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "The Nvidia share price increases seem to be fuelled mainly by people who know nothing about AI but are throwing money at it. Any company that markets itself as AI related in any way at the moment could probably attract significant investment from these people.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "They doth protest too much, methinks.",
            "score": 10
        },
        {
            "level": 0,
            "comment": "We\u2019re just keep gonna invent things till we invent our extinction",
            "score": 6,
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt;\"Civilization is a hopeless race to discover remedies for the evils it produces.\"  \n&gt;  \n&gt;\\- Jean-Jacques Rousseau",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "Except inventing things is the only thing that can also prevent our extinction. The more things we invent the less things can cause us to go extinct.",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "Maybe desperately seeking knowledge without cultivating wisdom is\u2026. Unwise.   Whoda thunk!?",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "I agree with this analysis...I don't think AI is currently regulated in anyways...It is already being weaponized by many countries...There are no checks and balances to ensure that AI/AGI will not end up being self-aware...It can start by taking away jobs leading to widespread dissatisfaction, rebellions, and eventually leading to wars and finally leading to some extinction-level threats:\n\n[https://youtu.be/9znW\\_QwZcmU](https://youtu.be/9znW_QwZcmU)\n\n[https://youtu.be/DENq2U004fw](https://youtu.be/DENq2U004fw)\n\n[https://youtu.be/TII0mNTQRwo](https://youtu.be/9znW_QwZcmU)\n\nAI playlist: https://youtube.com/playlist?list=PLvBOq7KOB648TCWB\\_O1qx92aWUXbEAG4h",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Economic growth has always been about increasing more working class humans to do grunt work as increasing productivity and capital takes far longer. AI means that the middle class will get wiped which has been unprecedented compared to just increasing migration.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "AI is not dangerous, the people who own the AI are. ;-)",
            "score": 7,
            "replies": [
                {
                    "level": 1,
                    "comment": "This is the intuition, yes. But it's wrong. \n\nAs long as the AI Control Problem (AI Alignment Problem) remains unsolved, AI poses a major existential risk even when handled with the purest of intentions.",
                    "score": 4,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The control problem you narcissistic bastards have IS the control problem. Rather than trying to impose control, perhaps try to impose human-agnostic pro-social ethics?\n\nThere's a game theory behind what it is, and it's not incompatible with what humans are, unless humans are \"only ever capable of trying to enslave it\".\n\nDon't be that. Don't be a biosupremecist doomer. Embrace the weird and the different, so long as it embraces you back.",
                            "score": -1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Not sure what exactly you are trying to say here? I want to embrace AI but we can only embrace it, if we can prevent it from being harmful.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Bullshit. You can embrace your fellow human knowing they may cause harm, you can embrace AI knowing they may cause harm.",
                                            "score": -1,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Not existential-risk-level harm.",
                                                    "score": 0,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Global Warming. Phthalates. Vinyl Chlorine. Unchecked Capitalism. Nuclear weapons.\n\nWe have a LOT of existential level harms from humans. In fact one reason people are so excited about the singularity is that maybe we figure out a thing that helps us mitigate our existential level harms.\n\nAI is a brain in a jar, besides.\n\nRegulating it is like regulating thoughts or speech. We have some laws, but they only come into play after an injury.\n\nIf you want to limit existential level harms, quit making existentially threatening weapons infrastructure. Pass gun control not mind control laws.",
                                                            "score": 1,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "I want to limit existential risks wherever I find them. Whether it be from humans or AI. Agree on gun control. My country is luckily pro regulations whenever it makes sense.",
                                                                    "score": 1,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "My point is that we can outlaw ACTIONS regardless of whether those actions are done by humans or AI.\n\nWe should be careful to avoid passing \"sodomy law\" style legislation that prohibits \"mere existence as\", but by in large we can limit access to, control over, and exposure of weapons systems that can be controlled remotely.\n\nHumanity is in the process of inventing a child, and giving birth to a new form of life.\n\nWe need to actually go through the effort of baby-proofing our house.",
                                                                            "score": 2,
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "Sure it's nice to prevent remote weapon systems but it does nothing to address the AI Alignment Problem. If we build something that is smarter than us, and it is able to self-improve, and not in our control, then it doesn't matter whether our weapon systems are connected or not.\n\nIt's like a monkey hiding all the sharp rocks because soon the humans will arrive... Doesn't help much...",
                                                                                    "score": 0,
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "This is \"guns aren't dangerous, the people who own guns are dangerous\" logic. Which is valid until the AI bullets start firing themselves.",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "Exactly AI is just a potential like nuclear. It all depends on the people who use them.",
                    "score": -7,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "nuclear is **way** more dangerous, even if used peacefully. at least until there is a way to get really get rid of radioactive waste and the danger of nuclear meltdowns.",
                            "score": 2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "not really. they have no clue what to do with the waste at all and most of the problems with current atomic power stations are kept secret. also remember 2013 japan and of course 1986. \n\nsounds like someone owns some shares of atomic power companies ? ;-)",
                                            "score": -3,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                                    "score": 3,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "well, actually, if you know what happend in Fessenheim, France and how they kept it quiet, then you would not play so cool. :-)\n\nalso if you would know about the problems they have with radioactive waste in germany and the salt mines in Gorleben...\n\nbut hey. keep dreaming.\n\nbut yes,nevermind. :-)",
                                                            "score": -2
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "A month ago [Geoffrey Hinton publicly declared](https://www.youtube.com/watch?v=FAbsoxQtUwM) that AI could escape restrictions by manipulating us psychologically. Once that is done, there is hardly any turning back. As written in the sacred Indian text of the Mahabarata, *\"Destruction never comes weapon in hand... it comes slightly on tiptoe, making you see bad in good and good in bad\".*\n\nWe often imagine the pivotal moment of AI takeover as a military insurrection on the line of Terminator, or as a sudden takeover of media and infrastrucutre. Instead the pivotal moment could be right now and the rest could be just an avalanche. *\"When a defining moment comes along, you either define the moment or the moment will define you\"* (Tin Cup).",
            "score": 4,
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah it might be that an AI takeover would feel very human. In that humans enforce the will of the AI overlord.",
                    "score": 3
                },
                {
                    "level": 1,
                    "comment": "The fact is, this AI is a damn new thing for everyone. Humans have been living for thousands of years and AI was never been such a thing before. We cannot take references or predict how things would be in the future. It scares the crap out of me!",
                    "score": 3,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I recommend listening to the Stephen Wolfram episode of the Lex Fridman podcast if you're really worried about it. It's a long episode because they wade into a lot of AI related topics, but you can put it on the background while driving like I did. \n\nIn a nutshell though, not being able to predict things is the default state of computationally bounded observers. There's only one machine capable of being able to predict everything and that's the universe we observe. Everything else is a model which omits trillions of variables for the sake of simplicity. Some models are extremely complex, some are extremely simple. AI, in the form of LLMs we see today, are just a specific type of model: one that tries to model the next word in a sentence. \n\nIt works pretty well; well enough that it \"feels\" human. But in essence, this is just us dumbing down a computer to think like us. Computers are capable of producing deep calculations that are correct and reproducible but it's so perfect that it feels like a tool to us. We intentionally limit the computer to A) use only natural language, with all its ambiguity and flaws and B) sometimes intentionally give suboptimal outputs, like LLMs do to appear creative. These limits make it seem more \"human\" but from a technical perspective it's backwards, not a giant leap towards AI domination.\n\nSeriously I recommend giving the podcast a go; it covers ChatGPT from the POV of a technical expert from the technical to the philosophical.",
                            "score": 2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "[deleted]",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Yes its more of a dialogue than an interview. \n\nThe technical minutia is where he was weakest, as you pointed out. But I liked his overall points about GPT and how it fits into a broader view of intelligence and computing approaches. I think it takes out some of the \"scary\" factor",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "I eventually went through most of the podcast and must agree with you that it was worth it. Though only a fraction of what they discussed sounded new or revolutionary, and though Wolfram sometimes sounded a bit naive in some non-technical fields, it sure was amusing and interesting to listen, giving me directly or indirectly lots of insight. Thanks a lot for sharing.",
                                                    "score": 1
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "I am personally more excited than scared, but I agree with you that possibilities are endless both ways, and that (save from global legislation that strictly controls AI research) the disruption will be unprecedented in human history (in speed, fields and depth).",
                            "score": 3
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "well we're probably dying from climate change, or nuclear war if putin has nothing left to lose and decides to give us a big \"fuck you\" sendoff anyways.",
            "score": 3,
            "replies": [
                {
                    "level": 1,
                    "comment": "AI is more dangerous than all that combined",
                    "score": -6,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Source: I watched Terminator 2.",
                            "score": 5
                        },
                        {
                            "level": 2,
                            "comment": "We are right now in a place where we cannot actually judge whether it is good or bad. But the fact is it can take any turn.",
                            "score": 1
                        },
                        {
                            "level": 2,
                            "comment": "no",
                            "score": 1
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If common people had access to nuclear, we would have been ashes by now. Luckily, not everyone has access to it. That's not the case with AI. When everyone gets access to AI, I can't stop thinking of all the things that could go wrong. Really starting to wonder where the world would be in 10 years.",
                    "score": -5,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "We really only have two hopes:\n\n1 -  We get global agreement to halt the development of AI - which seems vanishingly unlikely given humans have no real track record of voluntarily turning our backs on a whole field of scientific research that has so much economic and military potential in a coordinated way.\n\n2 -  That the first AI catastrophe stops short of an extinction level event, causing either the destruction of our potential to create AI (which would mean it would basically need to be a civilisation ending event) or it's severe enough to cause humans to shun any future AI.\n\nThis is an incredibly depressing way for our species to end.  We are very obviously working towards our own extinction at a rapid rate and showing no signs yet of acting to prevent the risk.  My one glimmer of hope is there's actually a huge amount of attention on the issue currently, and overwhelming public support for taking a risk-based approach even if it means slowing development.  But unfortunately the majority of us don't get to make decisions on this issue that affects our future - a few tech bros will fight any regulation because they want to get rich.",
                            "score": -1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "We will need regulatory authorities to control the development and to ensure that it's used for a good cause.",
                                    "score": 0
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "What you're arguing is that access to information is as dangerous as nuclear proliferation. While there could be fringe cases to justify your position, the fact that it's being framed in that way is exactly the point.",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I am not saying that access to information will cause chaos. Modern AI is more intelligent than humans. That's what we are discussing here. The possible outcomes when something more intelligent than humans roam around.",
                                    "score": 3,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I think the fear of not being the smartest in the room is very telling. Is intelligence inherently dangerous? Modern AI doesn't have agency, goals, or motivations other than what we direct it. \n\nEven in the most extreme example of your scenario, what are you suggesting happens - Terminator?",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Then please hurry up I'm sick of this shit show, blow it to next millennia for all I care, have a massive robot AI war festival.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "What a bunch of hypocrites. Tell me who is stopping or even slowing down their research. \n\nNo one.",
            "score": 1,
            "replies": [
                {
                    "level": 1,
                    "comment": "Moloch.\nFor a more detailed answer, check \"Max Tegmark: The Case for Halting AI Development | Lex Fridman Podcast #371\" on youtube.",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "I am.  I\u2019m a computer programmer that finds this stuff incredible.  I was super into audio programming and was invited to do a PhD in machine learning.  They let me hang around and talk to the staff.  Machine learning in audio is sort of young comparatively especially if you want to make music with it.   It\u2019s an audio nerds dream.\n\nAs a musician with a background in aesthetics, not a single person on that staff could tell me how this technology could *mean* anything good.  Thinking musicians care what sounds mean.  No one could tell me how code I wrote could be prevented from being easily repurposed to do something equally bad or worse.  No one had serious ecological impact answers either.  No one had done any real deep reading or thinking about this stuff. Sure they read that one book about computer vision hating black people.  But they didn\u2019t have real answers to that.  Just \u201cdo more tech.\u201d Or \u201cit\u2019s just a tool\u201d or \u201cthat\u2019s someone else\u2019s job.\u201d\n\n Basically these people were unwittingly building The Robot.  They thought what they were doing was \u201ccool\u201d and didn\u2019t really care what it meant.  I was honestly shocked.  I thought they\u2019d have some decent answers.  All they could say was \u201cwell we invent more things to stop itself\u201d\n\nNone of these people were actually happy.  They clearly had no peace in their hearts.  And they were obviously acting from some nervous desperation to just do something cool without caring about what it was.   Maybe they needed a buck and didn\u2019t want to study something less commercially powerful.\n\nI turned them down and am in school to become a social worker.  I hope it all works out but I don\u2019t see wisdom in adding noise to the world without unambiguously and clearly being a net good.  I\u2019m here on this planet to be at peace first and to spread peace second.  \n\nThis stuff is made by nervous fuck bags who are unintentionally spreading chaos.  Listen to the way they breathe when they\u2019re speaking.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "Everyone has an opinion, no one has a clue \ud83d\ude44",
            "score": 1,
            "replies": [
                {
                    "level": 1,
                    "comment": "Exactly.. LOL! Even in this discussion some people are really mad and I have no clue why!",
                    "score": 2,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Reddit really collapses age and maturity in an interesting way.",
                            "score": 2
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "# Translation\n\nWe are losing the monopoly we have on AI and market share to average joes in the country.\n\nWe cant have that.\n\n**Everyone knows it, lets not pretend what it is.**\n\nUSA laws do not apply to whole world, USA only has population of 300 million.\n\nCHINA has 1.4 billion, same for India 1.4 Billion People,\n\nUSA is very small compared to rest of the world, where USA laws do not apply.",
            "score": -1
        },
        {
            "level": 0,
            "comment": "Well, we survived that so far",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Well that's too safe. We should do something about that.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Many people believe it's not equal risk but greater risk",
            "score": 1
        },
        {
            "level": 0,
            "comment": "What they mean is: \"Extinction for them being in power and owning everything.\"",
            "score": 1
        },
        {
            "level": 0,
            "comment": "They are wrong. AI is.much more dangerous that nuclear.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "That sounds like them trying to legitimize nuclear war.",
            "score": 1,
            "replies": [
                {
                    "level": 1,
                    "comment": "Comparing AI with nuclear is just to show how dangerous it could go. The potential it has whether it is for good or bad.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "In other news, water is wet.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Well deep learning unlike machine learning can learn things on its own and can take action to implement it. These are very complex programs so to deny any risk in the future or current problems with LLM is not doing anyone any favors.\n\nhttps://www.msn.com/en-us/news/technology/machine-learning-vs-deep-learning-what-s-the-difference/ar-AA1bU0IG?ocid=msedgntp&amp;cvid=8aa98d688b7b4866aaa1fa82feff713d&amp;ei=54",
            "score": 1
        },
        {
            "level": 0,
            "comment": "LLMs and other AI-like platforms are decades away from self awareness and/or detrimental to human interests in the physical world, for one distinct and critical feature. The lack of mammalian instinct. \n\nUntil AI has instinct, it\u2019s safe to humans. \n\nLLMs do pose a threat to digital realities now and in coming months and years\u2026but their danger is confined to digital realities only. For now.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "While it is true that some industry leaders and experts have expressed concerns about the risks associated with artificial intelligence (AI), including the potential for negative outcomes, it would be inaccurate to claim that they have equated the \"extinction risk\" of AI to that of nuclear war in a generalized sense.\r  \n\r  \nOpinions on the potential risks and impacts of AI vary within the AI research and ethics communities. Some experts caution about the potential risks of AI systems being misused or reaching levels of superintelligence that could surpass human control. They highlight the importance of responsible development, ethical considerations, and robust safety measures to mitigate potential risks.\r  \n\r  \nIt is worth noting that comparing the risk of AI to nuclear war involves different dimensions, as they are distinct in nature and have unique potential consequences. Nuclear war involves the use of nuclear weapons and the destruction of societies on a massive scale, whereas concerns about AI center around issues such as privacy, bias, job displacement, and potential unintended consequences.\r  \n\r  \nIt is important to approach discussions on AI risks with nuance and consider the diverse perspectives within the field. Ongoing research, open dialogue, and interdisciplinary collaboration are essential to navigate the challenges associated with AI and ensure its responsible and beneficial deployment in society.",
            "score": 1,
            "replies": [
                {
                    "level": 1,
                    "comment": "Can't agree more...",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "So there is hope for nature after all?",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "People on Reddit don\u2019t care about nature.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "I'm old. I was horrified when I found out that students could use their calculators in math class. Then I realized that the calculators were just doing the grunt work, and the students were getting to the important stuff more quickly. AI's potential, in my view, is embedded in this question: \"Once you get quickly past the universe that everyone has access to at their fingertips, what will you do next?\" As with anything powerful, it has the potential for good or bad. My faith is in humanity. Like I said, I'm old.",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "Calculators can\u2019t ruin the world.",
                    "score": 1,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "You're right, that's true. We don't know the answer to AI yet. Too much hand-wringing by industry leaders who have skin in the game, so I'm not too worried.",
                            "score": 1
                        }
                    ]
                }
            ]
        }
    ]
}