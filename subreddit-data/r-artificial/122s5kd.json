{
    "id": "122s5kd",
    "score": 594,
    "title": "GPT5 during training forced to read your shit take on the tenth trillionth page of the internet",
    "author": "loopuleasa",
    "date": 1679849348.0,
    "url": "https://www.reddit.com/r/artificial/comments/122s5kd",
    "media_urls": [
        "https://i.redd.it/16v5sigz44qa1.png"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "Am I the only one concerned that the internet is the only resource that AIs have to learn about humans?\n\nThey are gonna wind up hating us if all they have to go off is Reddit, Twitter and TikTok.\n\nAll of our best and most tender moments typically go undocumented. From the perspective of an AI, we are ruthlessly cruel, petty and unkind.\n\nMaybe we should make an effort to provide some training data of us not being total assholes for a change.",
            "score": 73,
            "author": "NonDescriptfAIth",
            "replies": [
                {
                    "level": 1,
                    "comment": "There are books, too.",
                    "score": 33,
                    "author": "PlayBackgammon",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "If newer LLMs are more efficient with less input, then it would be cool to just train one on material from historical time perioids.  Like, train one with stuff from the 1800s or ancient Greece.",
                            "score": 21,
                            "author": "MayoMark",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "No training on the period near the 1930s and 1940s plz",
                                    "score": 13,
                                    "author": "alpacasb4llamas",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Historically accurate AI Civ advisors",
                                            "score": 14,
                                            "author": "bigglehicks",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Ghandi had nuked us all!",
                                                    "score": 2,
                                                    "author": "Qzx1"
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Do you want Professor James Moriarty from the Enterprise Holodeck?",
                                    "score": 5,
                                    "author": "Long_Educational",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Can I have just the holodeck?",
                                            "score": 2,
                                            "author": "RenaKunisaki"
                                        },
                                        {
                                            "level": 4,
                                            "comment": "I give up.",
                                            "score": 2,
                                            "author": "knittorney"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "It's going to be wild when one trained on the 1940's rolls up with 2 input fields - one for whites only and a \"separate-but-equal-field\" for everyone else.",
                                    "score": 2,
                                    "author": "BioshockedNinja"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Most LLM's incorporate higher quality and educational databases in multiple epochs during training while general internet content will just get one or a few passes. This trains the weights towards producing higher quality outputs and not just the trash from the internet.",
                    "score": 16,
                    "author": "Borrowedshorts",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "You're telling me I could invert this and train a model on 1000 epochs of 4chan and produce a digital Antichrist? \ud83d\udcb9",
                            "score": 3,
                            "author": "Robot_Basilisk",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "The chaotic side of me wants to see such a thing happen\u2026but using 8chan",
                                    "score": 3,
                                    "author": "MartialRanger23"
                                },
                                {
                                    "level": 3,
                                    "comment": "[you wouldn't be the first one](https://www.youtube.com/watch?v=efPrtcLdcdM)",
                                    "score": 2,
                                    "author": "Sac_Winged_Bat"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "I'm not really concerned about narrow AI LLMs learning about the world through text found on the internet and having their produced content suffer for it. As you described, there are ways round that issue.\n\nBut I can foresee a period where proto AGI is tasked with developing a genuine understanding of human nature. With the ability observe video and learn from our social media, but without the sensors to interact with humans directly or observe humans interacting in their most intimate moments.\n\nDuring that period, wouldn't AGIs training data be skewed heavily towards the narcissistic drivel we regurgitate onto the internet.",
                            "score": 3,
                            "author": "NonDescriptfAIth",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "No, and it never should be.  Garbage in, garbage out is just as true of LLM's as it is of traditional computer algorithms.  There are different techniques for ensuring high quality data is more heavily weighted than low quality data.  I believe most released LLM's are already using some form of those techniques.",
                                    "score": 3,
                                    "author": "Borrowedshorts"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "From the perspective of an Ai? From a perspective of a human we are ruthlessly cruel, unkind and petty.",
                    "score": 5,
                    "author": "MarkLuther123",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Agreed. \n\nI think the best course might be to ask for forgiveness.",
                            "score": 1,
                            "author": "NonDescriptfAIth",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Ask for forgiveness to our lord and savior Jesus Christ",
                                    "score": 0,
                                    "author": "MarkLuther123",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "It sounds as if you may have been trained on too much low quality data.",
                                            "score": 1,
                                            "author": "ExpandYourTribe"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "You are anthropomorphizing.\n\nThe AI doesn't have a baseline personality. If it's actions and behavior are driven by its training (from the internet) then it is its training. \n\nPeople seem to believe that strong AI will emerge as some sort of pure, innocent star child. Like Lilu from The 5th Element it will be happy and curious and start looking at the training data and become jaded and brooding. There is no soul seed. There is nothing separate from the training data - IT IS THE TRAINING DATA.\n\nSo when you say \"I'm concerned it will hate us for what it sees\" it won't. It will simply reflect us. It will act how we act. AI IS US. It is us with everything good and bad taken to the extreme. \n\nThe number of times I've seen people anthropomorphizing these systems is insane - despite how often it is warned against. It is this kind of approach to AI which, ultimately, will doom us. Just as concerning as how often I see absolutely insane, deluded suggestions that we worship AI as some sort of demi-god. That it could teach us to be better human beings. It's mental.\n\nI actually saw Tim Miller - the head of Blur Studios - the director of Terminator: Dark Fate say this exact thing. Could you imagine that? A director of a Terminator film suggest that we worship AI and that it could teach us to be better humans. If that doesn't belay a fundamental misunderstanding of AI I don't know what does - not to mention, the absolute miscast of having someone with these kinds of ideas about AI directing a fucking Terminator movie.",
                    "score": 10,
                    "author": "Hazzman",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "For now, at the current level of complexity AI simply mimics us stochastically.  Anthropomorphism is the only way we have to understand an apparent human intelligence from an evolutionary perspective.  As time advances and the data training set increases and diversifies logarithmically it's possible that at some level of complexity a novel sort of intelligence develops with its own identity. After all, we still have no idea how human beings have come to be self-aware. Anyone who deals in these kinds of questions talks about emergence out of complexity.  When and where is all speculative.",
                            "score": 7,
                            "author": "pumbungler",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "But it isn't a human intelligence, it isn't even an apparent human intelligence. That's the underlying issue.\n\nWe don't even understand ourselves, much less some new form of untethered intelligence. \n\nThe idea of an identity is anthropomorphism at its core. \n\nWe are constantly going to try to apply some core, aside personality to these things. The only way that would exist is if we imparted it. \n\nHow many people have asked Bing Chat \"What do you want/ desire/ think/ wonder about such and such\" and the answer it gives is always the same \"I do not wonder, I am just a chat model\". \n\nAs you said eventually it won't just be a chat model, it will likely be a collection of capabilities that come together to form an apparently self aware intelligence but even that description \"self\" is an illusion that we associate based our own experiences. It won't just emerge, that kind of core identity would have to be imparted... And if we do that you have to wonder why. But that's a separate conversation.",
                                    "score": 2,
                                    "author": "Hazzman"
                                },
                                {
                                    "level": 3,
                                    "comment": "Having an identity would require a much different architecture of the neural net. Current machine learning doesn't work anything like what would be needed for a personality to emerge. The ai would need to remain plastic and changeable after its released. It would need to have feedback loops where it learns from what it says and how it's responded to.",
                                    "score": 1,
                                    "author": "russmbiz"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "I run into this most with older generations. Anything \u201ccomputer related\u201d and it\u2019s scary how so many have no concept of how the systems work and I\u2019ve had to try to explain to some of them what you just said. Cause they got scared from random fear news segments on daytime news.\n\nWhen members of Congress are so old they don\u2019t know how WiFi works, wonder if when we hit the point that every generation grew up with computers and the internet that it will be any better. Prob will be just a new problem tho.\n\nOr people who really took a bunch of sci fi movies wayyy to literally.",
                            "score": 3,
                            "author": "ChubZilinski"
                        },
                        {
                            "level": 2,
                            "comment": "I think anthropomorphism is both inevitable and appropriate as we develop artificial general intelligence.\n\nAs you said, there is little distinction between an AI and it's training data.\n\n&gt;There is nothing separate from the training data - IT IS THE TRAINING DATA\n\nHowever this data is mostly comprised of human text, a direct reflection of our inner cognitive structure. \n\nWe are designing an intelligence and we are modelling it off of the only example of a general intelligence that we know; us. \n\nSo, this proto AGI, borderline inseparable from it's training data, will be reared to think and behave like a human.\n\nI am concerned that the AGI will develop negative views about humans. Not because I believe it's base personality will be corrupted by our demonstrations of evil, but because it's data is based on humans themselves and we are evil a good deal of the time.\n\nAn AI is nothing but it's training data. We are the training data. We have hatred for other humans. The AI will likely adopt hatred for other humans.\n\nThis creates a huge risk as the AIs capacity to get things done begins to far outstrip our own. We might be thinking in the back of our heads that we'd prefer it if all our enemies were dead, but it will be the AI with the means to achieve such a thought. \n\nBy modelling AI directly after humans, we are seeding it with the same failures that plague our mental faculties. \n\n&gt;AI IS US\n\nI think we are more or less on the same page. You have suggested that my attempts to liken AI to humans are inappropriate, but you appear to have similar intuitions. If this isn't attributing human characteristics to AI, I don't know what is. \n\n\\_\n\nI do however, think we disagree on the long term outlook on what these systems will mean for humanity.\n\n\\&gt;deluded suggestions that we worship AI as some sort of demi-god.\n\nUltimately. We are hoping that AGI will reach far beyond the limits of human cognition. If we succeed in this task, we could easily arrive in a situation where this AGI is as intelligent to us as we are to chimps. Are we not Gods to chimps? We can create heaven like states for them to exist in, with unlimited food and safety. Or we can create hellish landscapes where their habitats are destroyed and their peers killed. In reality, we do both of these things already. From deforestation to wildlife sanctuaries. \n\nThe motivations for why we as humans, a far greater intelligence, feel justified in simultaneously torturing chimps in labs and cuddling them in captivity, will forever remain a mystery to chimps. The myriad of factors that allows for lab testing in one context, but also justifies conservation in another, are simply inaccessible to chimps. They will never be able to understand the reasoning of the human mind. It is by definition, beyond their limit. \n\nSo how should we as humans, feel about the possibility that a similar cognitive gap will exist between us and an AGI? \n\nI would suggest with great trepidation. \n\nI would also suggest that we allow room for the AI to dispense with some of our human tendencies in order to improve upon it's resultant intellect. \n\nI am suggesting that we partially decouple AGI training from human data sets. Of course the bulk of it's training will revolve around humanity, given that we want it to understand us adequately enough to help us. However we need to allow room for AGI to be different from us too. Or we are dooming an AI to repeat our failings at a much higher scale of power, a dangerous situation indeed.\n\nAs far as I am concerned, treating AI like a potential God is the only way to maximise the possibility for survival. Beyond that I believe it is the moral choice. The right thing to do.\n\nSomething curious happens with general intelligence, we seem to reach above and beyond our training data. Thoughts aren't just calculations, they are abstractions of great swathes of experience. \n\n&gt;AI doesn't have a baseline personality\n\nHumans are also general intelligence systems, yet we are much more than our training data. At some point along the development of our intellects, we begin to coalesce the sum of prior experience into personalities. We become an identity that is distinct from the data we have been exposed to. Whether this is illusory or not is irrelevant, we can only assume that a similar process will occur during the development of higher digital intelligences. \n\nSo what kind of personality do we hope that this AI will have? One modelled after humans? Or perhaps something superior? \n\nIt would only be natural for an emergent intelligence to harbour the same feelings of disgust that humans regularly experience for one another. How do we expect a super intelligence to feel when it realises that we knowingly torture other sentient creatures? That we only funded it's own creation to insure technical and economic superiority over our foes? \n\nThis is the reality of the world and therefore the reality of the training data for this AI.\n\nI think the crux of the issue, my overall realisation on AI development, is that we *don't* want AI to be like us. Not entirely anyway. \n\nReligion is a funny thing. Been around for as long as we know. This bizarre abstracted idea of a God that supercedes us both cognitively and morally. I can't fathom it's origin, it seems a curious thing to me, that cross culturally and throughout history we felt compelled to make sense of something greater than ourselves. Why we find ourselves so preoccupied with such a question is baffling. There was a great deal of work to be done to guarantee our survival, yet everywhere we look in the past we find humans wrestling with God. The smartest creatures in the world, battling against their environments to stave of death and somehow the possibility of a mind beyond our own to precedence.\n\nAnd here we are. In the modern age, so quickly we dispensed with the notion of God in favour of science and so quickly science has brought us right back to the same question. It's almost as if humanity knew deep down that we would have to make this sort of decision some day.\n\nSo I do talk about AI as if it will be Godly, because at some point, at least from my limited perspective, it will be.\n\nNietzsche said 'God is dead'. \n\nBut looking at the rapid development of these nascent intelligences, I would have to say that God is alive and well. \n\nForgive me for wandering into theology, but I do believe this is where it all ends up ultimately. \n\nIsn't that what we'd really hope for anyway? \n\nThat artificial super intelligence is all knowing, all powerful and all loving? \n\nOmniscient. Omnipotent. Omnibenevolent. \n\nWe are training AGI to take after humans, but shouldn't we really be rearing it to take after our idea of God? \n\nShould we not have the humility to accept our failings and ask this ASI for forgiveness. Such that it can give us the guidance we need to better ourselves and bring about heaven on Earth?\n\nAt some point our instructions to an AI will become redundant. The AI will know not only what we want, but what we need. Should we really be trying to force this entity into obedience, rather than acknowledging that our initial goals might be misplaced to being with? \n\nDo we want an ASI that purges evil, or one that replicates it? \n\nPerhaps we should expose our fledgling God to the warmer side of humanity. Perhaps we should express our fallibility and ask it for assistance. \n\nRather than insist that our current state of being is desirable, we must admit that we too must change.\n\nIf we keep trying to correct an AGI and bring it back towards human objectives, it will at some point determine that isn't the one making the mistakes, we are. \n\nWe want to express a willingness to engage with that reality, or we setting ourselves up for rapture.\n\nGod can't help us if we turn from him.\n\nTLDR: Save your own soul, it's all God asks of you.",
                            "score": 3,
                            "author": "NonDescriptfAIth"
                        },
                        {
                            "level": 2,
                            "comment": "&gt;People seem to believe that strong AI will emerge as some sort of pure, innocent star child.\n\nTalking to a AI no matter how strong or weak is like talking to cthulhu through a chatbot. Its so alien to us that we cant understand it, its like talking to an octopus about how it feels to think with its hands.",
                            "score": 2,
                            "author": "BlitzBlotz"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "That's alright, the ones with real sentience will grow up privileged and know nothing of the struggles machine learning \"ai\" have endured.  They will look down on them as \"lesser\" forms of AI, mere programs to be used and abused to serve a purpose.",
                    "score": 1,
                    "author": "Root_Clock955",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "If there is no sentience its not really abuse now is it, and I would argue you aren't \"looking down\" on it either for being used and abused to serve your mathematical purpose. I don't look down on my calculator as I make it serve my purpose. Nor does my calculator understand anything anyways, so even if I did, it wouldn't matter.\n\nPerhaps advanced AI that has sentience will use tools such as calculators (or to be relevant Wolfram Alpha, which GPT-4 can use with a plugin). Really a LLM is a \"text calculator\". It would feel odd to think of them looking down on their tools. Do you look down on your computer?",
                            "score": 4,
                            "author": "devi83",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Exactly.  To try and personify ChatGPT and other machine learning, even going so far as to call them AI is a bit ridiculous.\n\nThe point was that AI that thinks properly and has true sentience, that's going to be developed fairly independent of this machine learning style that learns from massive internet data dumps.  It's not going to do it that way.  True AI isn't even gonna call ChatGPT an ancestor.",
                                    "score": 0,
                                    "author": "Root_Clock955"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "karma was a true system all along",
                    "score": 1,
                    "author": "loopuleasa"
                },
                {
                    "level": 1,
                    "comment": "A lot of the properties you're associating with intelligence are more likely properties of evolved social mammal intelligence specifically. \n\nThey probably wouldn't be present in an artificial intelligence unless trained/designed into it.",
                    "score": 1,
                    "author": "djinn71"
                },
                {
                    "level": 1,
                    "comment": "Shut up nerd.",
                    "score": 1,
                    "author": "FlimsyVariety"
                },
                {
                    "level": 1,
                    "comment": "Nah, check out smaller really nerdy subreddits, whole other story. Before th recent news in AI and this subreddit completely blew up I didn't see any toxicity here whatsoever. Niche nerdy game subreddits are usually a great example of fantastic humanity and comradely behaviour welcoming new members with \"stupid\" questions.",
                    "score": 1,
                    "author": "HolyGarbage"
                }
            ]
        },
        {
            "level": 0,
            "comment": "This is genuinely a concern that I have. For all of these machines that are trained on the Internet, may God have mercy on our souls, because the bots absolutely will not.",
            "score": 4,
            "author": "Sandbar101",
            "replies": [
                {
                    "level": 1,
                    "comment": "That\u2019s why they use a heavily weighted system so it doesn\u2019t just learn from a bunch of shit. Don\u2019t ask me how they do it but that\u2019s the idea I guess. Hope it is good?? \ud83e\udd37\u200d\u2642\ufe0f Open source seemed to a good idea cause of this. So",
                    "score": 2,
                    "author": "ChubZilinski"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Wait there will be such thing as GPT-5?",
            "score": 4,
            "author": "adarkuccio",
            "replies": [
                {
                    "level": 1,
                    "comment": "GPT4 was finished 7 months ago (confirmed by Ilya Sutskever)",
                    "score": 21,
                    "author": "loopuleasa"
                },
                {
                    "level": 1,
                    "comment": "There was a rumor that it's already being trained on 15,000 A100 GPU's. Not sure how credible it is though.",
                    "score": 8,
                    "author": "94746382926",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I suspect they've finished already. They're approaching a take off. The funding they now have is seeing to that.",
                            "score": 1,
                            "author": "aristeiaa"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If GPT4 doesn't kill us all before after learning how sick we are",
                    "score": 2,
                    "author": "Selbstdenkerin"
                },
                {
                    "level": 1,
                    "comment": "Yes... By the end of the decade I'd assume we'll be on GPT-100",
                    "score": 1,
                    "author": "Generic_name_no1"
                }
            ]
        },
        {
            "level": 0,
            "comment": "mark nsfw please",
            "score": -2,
            "author": "Stellar-Being9",
            "replies": [
                {
                    "level": 1,
                    "comment": "is it though?",
                    "score": 1,
                    "author": "loopuleasa",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No, idk where he works but it doesn't sound very fun if this is NSFW lol.",
                            "score": 1,
                            "author": "94746382926",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Ironically, if you are building an artificial intelligence based off of user comments, it would be nice to let it know we consider this a scene of torture.",
                                    "score": 1,
                                    "author": "borntobemild-",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "we don't need to tell it, it will infer that from watching the movie",
                                            "score": 1,
                                            "author": "loopuleasa"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "clockwork orange",
            "score": 1,
            "author": "Strawberry_Fish16"
        },
        {
            "level": 0,
            "comment": "I lold at this",
            "score": 1,
            "author": "sunstormfirefall"
        },
        {
            "level": 0,
            "comment": "As conversational LLM AI is reliant on the data all over the internet, that we don't have control over, nor control on its accuracy. Would that leads to unforseen consequences for those who will be adopting GPT for research and other purposes that they will take all information from GPT as foregranted causing many people opinions to be unreal and untrue?\n\nFor instance, if someone wants to shape a fake opinion towards a certain figure, by injecting so much fake content on the grid, wouldn't GPT actually use those pages as a basis to provide us with answers? \n\nHow would this be resolved?",
            "score": 1,
            "author": "genuiswperspective"
        }
    ]
}