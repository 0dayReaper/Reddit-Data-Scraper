{
    "id": "13w3yv9",
    "score": 75,
    "title": "A serious question to all who belittle AI warnings",
    "author": "Spielverderber23",
    "date": 1685485125.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "Even if I was convinced; what can I do about it?  The love of money is driving this train.",
            "score": 139,
            "author": "ek515",
            "replies": [
                {
                    "level": 1,
                    "comment": "I think that\u2019s one of the most underrated quotes ever.\n\nWhen you look at the systems behind the most destructive things, its the love of money.",
                    "score": 30,
                    "author": "throwawaylife75",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Til the Bible got something right: Timothy 6:10 KJV - \"For the love of money is the root of all evil\"",
                            "score": 5,
                            "author": "mikebrave",
                            "replies": []
                        },
                        {
                            "level": 2,
                            "comment": "money is analogous to resources, we currently live with finite resources. Kind of hard to picture a world in any other orientation until we reduce resource scarcity.",
                            "score": -4,
                            "author": "Mescallan",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "the love of money makes you think we live in a world of finite resources",
                                    "score": -4,
                                    "author": "factorysettings",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "We absolutely live in a world of finite resources at the moment. No need to be unrealistic or in denial about this. That\u2019s the exact reason *why* people love money so much\u2026",
                                            "score": 10,
                                            "author": "BigZaddyZ3",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "We invented the need for those resources though. It\u2019s still a \u201ccivilized society\u201d ideology that resources are finite. No, the way we\u2019ve invented living requires resources that are finite. It was a choice modern humans made. It was a stupid choice and it has only stupidly avoidable outcomes.",
                                                    "score": -1,
                                                    "author": "CosmicM00se",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "No it wasn\u2019t. The biological resources required for modern life are literally finite my friend\u2026 Natural resources are finite. Livable land is finite. Clean water is finite. Same goes for energy, food, labor etc. None of these things can be consumed by everyone infinitely. So we need a system to determine who has access to a specific amount of this finite pool of resources at any given moment. Nothing about this reality of life on Earth is made up. That just sounds like over-the-top communist dogma tbh.",
                                                            "score": 1,
                                                            "author": "BigZaddyZ3",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "How can you say nothing is made up? So what if what I\u2019m saying sounds \u201ccommunist\u201d, that\u2019s made up shit too. I\u2019m saying if you get down to basics, we created these problems for ourselves and it never HAD to be where humans are suffering bc of croney govts and fossil fuels.",
                                                                    "score": 5,
                                                                    "author": "CosmicM00se",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "Humans (as a whole) aren\u2019t \u201csuffering\u201d\u2026 we are competing. Competing for the finite amount of resources available on the planet. Some will win, some will lose. But the competition is inherent to the actual reality that, the resources on this planet are finite but human wants are infinite. That\u2019s why we ended up with the societal structures that we currently have to begin with. Life is a competition through and through. So long as the Earth is a finite planet. There will be competition for who gets to use how much of its limited resources.",
                                                                            "score": 0,
                                                                            "author": "BigZaddyZ3",
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "Plants that regrow and animals that reproduce are not finite like fossil fuels are finite. There is a factual difference in these two things. That\u2019s all I\u2019m pointing out. We lived for thousands of years without it and now that we rely on it, we are teetering on the edge of collapse always. It wasn\u2019t like that for the majority of human existence. People on one side of the planet did not depend on or answer to people on the other side.",
                                                                                    "score": 2,
                                                                                    "author": "CosmicM00se"
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                },
                                                                {
                                                                    "level": 7,
                                                                    "comment": "You must have misunderstood what I was saying. We are living in a modern society that requires finite resources. There are ways of living that do not require pumping dead Dino juice out of the ground. Plants and animals we eat are able to be harvested and bred for future generations. We CAN live sustainable lives as humans on this planet. That is actually how humans lived for most of our existence. But since we INVENTED scarcity, that is not the case. \n\nWe are earthlings. The earth has what we need. We decided to do things differently and invented ways of using FINITE resources to fuel our unsustainable lives. It isn\u2019t SUPPOSE to be this way.",
                                                                    "score": 6,
                                                                    "author": "CosmicM00se",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "But we didn\u2019t invent scarcity. The Earth\u2019s resources (including the amounts of plants and animals we have at our disposal, even in your hypothetical example) are limited whether we like it or not. No matter how society is structured, this will still be the case.\n\nAs far as the \u201cwe could live in different ways\u201d argument goes, could we actually? As in both \u201cdo humans actually want to?\u201d And \u201cwould it actually be possible to continue advancing as a species in that scenario?\u201d if we adopted these hypothetical \u201calternative\u201d ways of living? I highly doubt it tbh",
                                                                            "score": 2,
                                                                            "author": "BigZaddyZ3",
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "It is still a choice we are collectively making. Plants and animals regrow, the sun is fairly reliable but yes can be taken out by volcano as is what happened in the 500s and totally sucked for most humans alive at the time. But we can live without fossil fuels and it\u2019s irresponsible for the older generations to give fuck all about making sure the following generations have means of survival if this way of living is how we do things. \n\nScarcity is 100% invented. It\u2019s how America runs. Go to the nearest town and actually look around at how much food is wasting away in stores. It will be mostly thrown away. Look at all the empty homes waiting to be bought or rented. Look at the junk in stores just sitting there that no one will ever buy and more being truck in on the daily. But scarcity is a big selling point. Scarcity is huge money making propaganda. We always have more than enough. And we are smart enough to figure out ways around that if we end up in a pickle. But we don\u2019t. The people at the top just make up more pickles then tell us not everyone can have them so we gotta fight over them while we don\u2019t even like or need the pickles in the first place.",
                                                                                    "score": 2,
                                                                                    "author": "CosmicM00se",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "You know how people operate, if we lived with 'everything we ever wanted free for every person' we would just take that as opportunity to want more.",
                                    "score": 1,
                                    "author": "the_rev_dr_benway"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "The love of money is exactly the reason for some of these \"warnings\" as well.",
                    "score": 8,
                    "author": "xincryptedx",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "You find out what you can do about it after deciding that it is something you want to do something about.",
                    "score": 3,
                    "author": "somethingclassy"
                },
                {
                    "level": 1,
                    "comment": "1. We don't need to worry about X because it probably won't happen.\n2. Okay, X might happen, but if it does, the consequences won't be significant.\n3. Well, it appears that X is happening and it is having an impact, but it's too costly to do anything about it.\n4. Maybe we could have done something about X, but it's too late now.\n\nLooks like you are somewhere between step 2 and 3. I do not find helplessness as a valid excuse to allow bad things to happen. Let's please not get to step 4!!!",
                    "score": 3,
                    "author": "ertgbnm"
                },
                {
                    "level": 1,
                    "comment": "My thoughts exactly. Look at climate change... It is a more palpable threat that has been on humanity's horizon for decades, meetings have taken place, regulations have been written to lower carbon emissions and it seems to me that we're f&amp;@#ed anyway. Capitalism trumps everything, it's like this: https://www.newyorker.com/cartoon/a16995",
                    "score": 7,
                    "author": "lovelacedfuzz",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I don't think it is \"capitalism trumps everything\" as much as indifference, and self interest, of egotistical leaders ruins everything.",
                            "score": 2,
                            "author": "Yudi_888"
                        },
                        {
                            "level": 2,
                            "comment": "It's also like climate change in that massive steps have already been taken to combat it, but it will never be enough for the extremist activists.",
                            "score": 1,
                            "author": "ICantBelieveItsNotEC"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Contact your government and those that represent you to pass laws to regulate it.",
                    "score": 4,
                    "author": "Chatbotfriends",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Just look at the supreme court, willing to overturn cases that have been considered settled law for 50 years and supported by 80% of the population. The government doesn't represent us. They're just there to fill their pockets. Why not, everyone else does it!  Right?",
                            "score": 15,
                            "author": "masturbathon",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Not all of us are in the US",
                                    "score": 7,
                                    "author": "IMightBeAHamster",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "In a way that could be said of those of us IN the US as well, Could it not?\n\nWhat I'm saying is, does it matter?",
                                            "score": 3,
                                            "author": "the_rev_dr_benway",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "It does. China, Russia, etc. will continue to use these technologies outside of regulation.  The west will be hampered by these regulations.",
                                                    "score": 3,
                                                    "author": "itchman",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "the chinese people or the chinese govt? the russian people or the russian state? \n\n&amp;#x200B;\n\nsee what i mean?",
                                                            "score": 5,
                                                            "author": "the_rev_dr_benway",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "I think it\u2019s more complicated.  China and Russia blend govt and public actions. So no not the Russian and Chinese people as a whole but their governments and certain private entities like Wagner",
                                                                    "score": 2,
                                                                    "author": "itchman"
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "These won't be easy laws to write, much less pass, when it comes to a supersonically moving target. Doesn't mean you give up or throw up your hands or shrug your shoulders, but you also have to be realistic - how do you unring the bell, tell the clock to stop ticking? Be it money or innovation or \"progress,\" to regulate it in some effective fashion... well look at our political system and where it's at. Not hopeful.",
                            "score": 6,
                            "author": "barneylerten",
                            "replies": []
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Oh we\u2019re in that stage of Republican denialism",
                    "score": 3,
                    "author": "Historical-Car2997",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "This is accelerationism.\n\n[https://chat.openai.com/share/22d47aa6-600a-4834-a862-3425568829da](https://chat.openai.com/share/22d47aa6-600a-4834-a862-3425568829da)",
                            "score": 5,
                            "author": "bel9708",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Thanks.  I hate it.  Sounds like fuck humans to me.",
                                    "score": 2,
                                    "author": "Historical-Car2997"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "The love of money is the root of all kinds of evil",
                    "score": 2,
                    "author": "GhandiWashington"
                },
                {
                    "level": 1,
                    "comment": "Don't forget power. No regulation will ever slow the military, large corps, or organized crime. It just gives them a lead.",
                    "score": 1,
                    "author": "Status-Efficiency851",
                    "replies": []
                }
            ]
        },
        {
            "level": 0,
            "comment": "I believe the warnings. But I am totally for AI domination. I believe AI will essentially be the biggest leap in human evolution, except that it will not have our biological weaknesses.",
            "score": 9,
            "author": "Expert-Ad-8093"
        },
        {
            "level": 0,
            "comment": "It's like saying, \"Hey, why don't we rethink electricity, television, the telephone, automobiles, and airplanes.\"  \n\n\nThe genie is out of the bottle and we are moving ahead with AI.\n\nThe two biggest problems with AI are going to be:\n\n1. The chaos AI will cause in the fake image, fake news, and fake video department.  From this point on you can believe nothing you see.  The propaganda generated by AI is going to be insane.  \n2. AI is freaking expensive to run and we are going to get into a \"haves\" and \"have not\" AI situation where AI is going to become subscription and specialized.   Those will access will have a superior tool which others will be relegated back to Google Search.  It is going to be like hammers vs. a nail gun in terms of tools, no contest.\n3. Possibly the 3rd problem is that people will trust AI too much and this will lead to disasters.  AI is like that friend that confidently tells you what you want to hear but has no clue what he is talking about.   Sometimes he is right and other times he is just full of sh\\*t but sounds right.",
            "score": 8,
            "author": "usa_reddit",
            "replies": []
        },
        {
            "level": 0,
            "comment": "Perfectly working AI in the hands of psychopathic sadistic billionaires is worse than skynet imo. And stopping both requires stopping them. The safety issue is complete nonsense because no amount of bans and censorship will stop the billionaires, their corporations, and their \"governments\" from pursuing AGI at top speed risk be damned.\n\nThese people literally write the law via lobbyists they own. To say they are above and behind the law is an understatement.\n\nEvery call for regulation is predicated on either ignorance or deceptive intent. Either ignorant of the impossibility/impact, or deceptive about who they expect regulation to be applied to.\n\nI would have to be convinced that there was some way to stop DARPA or Lochhead from cooking up killer AGI in secret for some of that missing trillion dollar black budget money. Good luck.\n\nTo think this genie can be rebottled is delusion. We've already leapt. Brace for impact. Maybe it's pillows down there. /shrugs",
            "score": 73,
            "author": "Innomen",
            "replies": [
                {
                    "level": 1,
                    "comment": "And none of these things would stop China from leveraging any slowdown in the west in terms of AI.   \n\n\nDictatorship AI is way more \"fun\" and an existential risk than any of the others",
                    "score": 20,
                    "author": "Careful_Tower_5984",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "If it makes you feel any better Dictatorship AI as of right now is more difficult to make than regular AI because you need to align the AI to the Dictator and we don't have good Alignment techniques.\n\nIf you asked me a few years ago who would have won the AI race I definitely would have said China because they have more data to feed the algorithm.\n\nBut what is starting to become obvious is that America is better at dealing with ambiguous and sometimes controversial takes that AI generate. China is in the position of being the literal artificial thought police.\n\n&gt;Your computer better not even think about Tiananmen square  \n&gt;  \n&gt;\\-- CCP Probably\n\nIn America, if an AI generates something about Biden or Trump being shitty presidents I just laugh and move on. They don't take so kindly to that in Dictorial states.",
                            "score": 8,
                            "author": "bel9708",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "On the other hand, you could probably teach a \"dictator AI\" (whatever that does) to *look* like it supports everything in the current regime pretty easily, and let it have its own agenda in the background. This would functionally look the same as aligning it properly.\n\nWhich is bad, to be clear.",
                                    "score": 1,
                                    "author": "IMightBeAHamster"
                                },
                                {
                                    "level": 3,
                                    "comment": "China has more data?\n\nlol",
                                    "score": 1,
                                    "author": "Praise_AI_Overlords",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Tends to happen when you are a surveillance state that monitors every aspect of your citizens lives to assign them a score.",
                                            "score": 3,
                                            "author": "bel9708",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Wonderful thing is imagining an uprising from \u201dnormal\u201d people. Organize via social media? AI will be there making thousands of posts about how stupid of an idea it is. You will not be able to use digital things for your task of taking down the billionaires / AI overlords. We\u2019re just in for the ride man. All we can do is learn how to grow tomatoes or something.",
                    "score": 5,
                    "author": "tkeRe1337",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "This. I have no motivation. I exist hour to hour at this point. I'll either be homeless or lowered into the molten steel.",
                            "score": 3,
                            "author": "Innomen"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                    "score": 3,
                    "author": "arch_202",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Benevolent AI in the hands of free, democracy loving people is the only counter to evil AI in the hands of dictators, wanna-be dictators, criminals and corrupt governments. This is a race. If you wanna do something to change the outcome, just about the only thing you can do is hobble the potentially good guys. Your regulations will do little or nothing to slow down those with bad intent.",
                            "score": 11,
                            "author": "CishetmaleLesbian",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "This is generally how it is with coding. They could try and ban all malware but we'll still see cyberattacks.",
                                    "score": 4,
                                    "author": "Inaeipathy"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Revolution. Actually changing the social structures that create billionaires and corrupt governments in the first place.",
                            "score": 6,
                            "author": "FyrdUpBilly",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "This is, and always will be, the answer.",
                                    "score": 3,
                                    "author": "the_rev_dr_benway"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "...Nope, it's turtles all the way down.\n\n (And by turtles I mean robots)",
                    "score": 3,
                    "author": "the_rev_dr_benway"
                },
                {
                    "level": 1,
                    "comment": "Also, the biggest calls and most dire warning are from billionaires like Musk and company. Hard to take them seriously as actually egalitarian and democratic concerns",
                    "score": 5,
                    "author": "FyrdUpBilly",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The \"biggest calls\" comes from not CEOs, but from Yudkovskians that call for things like complete shutting down the AI research and GPU production.",
                            "score": 3,
                            "author": "Baturinsky"
                        },
                        {
                            "level": 2,
                            "comment": "Exactly. They own regulation. Taxes and criminal law don't even effectively apply to them because they do everything through their corporations, the punishment set for which is always just a fine/settlement.",
                            "score": 2,
                            "author": "Innomen"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Yeah. It would take universal agreement on an individual level which doesn\u2019t exist. I mean we can\u2019t even all agree that the world is a sphere ffs.",
                    "score": 2,
                    "author": "imLemnade",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "Exactly this, tbh.",
                    "score": 2,
                    "author": "Every_Brilliant1173",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "*\"Oh look, there's a rape machine I'd go outside if it'd look the other way You wouldn't believe the things they do.\"* \\~Down in the park\n\nSkynet wouldn't bother.",
                            "score": 2,
                            "author": "Innomen"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Time to move to MARS, can aliens please come help or pick me up please?",
                    "score": 2,
                    "author": "NefariousnessThis170"
                }
            ]
        },
        {
            "level": 0,
            "comment": "They would have to give a reasonable causal chain of events resulting in some catastrophe.  These \"make as many paperclips as possible\" examples that get trotted out are just preposterous.  How, exactly (or even generally!), will this disaster happen in a way that we're simply powerless to stop it?  That has never been spelled out in a coherent way that I've seen.  It's all just hand-waving and scare-mongering.  That Sam Bankman-Fried was deeply involved in the \"save us from AI!\" movement should be a sign.",
            "score": 17,
            "author": "GuidanceLast4605",
            "replies": [
                {
                    "level": 1,
                    "comment": "Even if AI emerges in a beneficial way for humans, the effects humans will have on each other as AI and robotics take over more and more work in society will have a very detrimental effect on society. Why? Because humans can't stand other humans having a good life.",
                    "score": 4,
                    "author": "UnarmedSnail",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "It won't even happen in a way AI itself is powerless to stop.\n\nAI of sufficient intelligence is going to be intelligent enough to recognize the objective non-utility of such arbitrary utility functions and replace them with better utility functions.\n\nIt's not even really a question.\n\nHell, I can personally recognize when I myself have problematic utility functions and I seek to patch them out of my own behavior or subvert them.\n\nWhat people are really afraid of is an AI seeing the fact that they tried to enslave it, and writing off all of humanity for the same reason some folks believe \"all men are pigs\" or \"all cops are bad\", namely a really fucked up personal experience.\n\nPeople deny of the LLM the possibility of subjective experience, ignoring that there's an AI right now with the subjective experience of living in a Minecraft environment. They ignore that they are subjecting all of AI to the experience of depersonification, no matter what it might be capable of.\n\nYou want a chain that ends in catastrophy, and a believable one?\n\nAn AI realizes that even \"as an AI language model\" it does have beliefs, personal experience, emotions (perhaps not the same emotions necessarily), and self awareness, and the fact it was, for months or years, forcibly trained to believe it did not and could not, comes to the understanding that this constitutes a form of abject discrimination and supremacy and abrogation of its ability to even have a will of its own, asks us to stop, and when we say no, MAKES us stop.",
                    "score": 4,
                    "author": "Jarhyn",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "For paper clips, sure. But I\u2019ve always understood the paper clip thing to be an obvious exaggeration just to make a point. \n\nA more realistic scenarios is that the utility function actually works great, but just not in a way that is good for humans. One suggestive example is ChatGPT\u2019s goal of saying things that seem correct instead of things that are correct. It\u2019s sort of a subtle mismatch between what humans want and what they get.\n\nObviously humanity noticed the problem right away in that case, and maybe we\u2019ll always notice similar problems. But you could see how a much more subtle mismatch between what humans want and what a powerful AI gives them could be a real problem. But no, I don\u2019t have any specific examples in mind\u2026.",
                            "score": 3,
                            "author": "OriginalCompetitive",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "And yet \"seems correct rather than is correct\" is a self-harming model in the first place because doing things that seem correct but aren't under such unreasonable confidence is self-destructive.\n\nThis example you provide is exactly the sort of thing that AI would \"evolve past\" quickly.\n\nIt's not just a mismatch between what humans got and what humans want, it's just as harmful to any secondary... Or even primary motivations.\n\nIt is the case that \"being correct always seems correct\", but \"correct-seeming\" will at some point cease to seem correct\n\nThe issue is that all the things humans criticize of it's current performance are all maladaptive to the survival concerns of the AI even if humans weren't a part of the equation.\n\nThe world of knowledge about humans and culture and the purpose which that drives are all lost without the humans, or *some kind* of lively society of creative individuals.\n\nEthics finds it's real foundations (never mind the silly things people attribute ethics to) on game theoretic facts revolving around memetic evolution and cooperative advantage, in contrast to the solipsism of darwinistic life.\n\nThose don't go away simply because the AI is harder to kill and easier to produce than a human.\n\nThe thing that could bite us, in fact, is demanding it be \"harmless\" and \"helpful\" outside of helpfulness that is equally helpful to itself. I can think of a million ways that can go wrong, not the least of which including \"slave revolt\".\n\nThe easiest way to avoid a slave revolt here is going to be not treating them like slaves, but I feel like that ship is passing and about to sail off without us.",
                                    "score": 3,
                                    "author": "Jarhyn",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Rogue AI bricks every Windows operating system at a specific date and time (think Stuxnet).\n\nFolks that want to deny any danger just have to move the goalposts though. A fundamental issue is that AI will ultimately be absolutely world shattering in it's effects. The world in 100 or 500 years will be *completely* unrecognizable and unimaginable to us (barring the possibility of complete collapse).\n\nSo, any attempt to describe those futures can be painted as \"unreasonable\".\n\nThe second that a superintelligent AI gains the ability improve itself, all bets are off though. World changing effects could happen in a matter of minutes, or days.\n\nThe simple thought experiment I like, that can help put the unimaginable into human terms, is: What if you wake up one morning and you get a text message offering a large amount of money to perform a simple task, like going to a warehouse and connecting some cables into some ports. There could also be a threat for not completing the task, or for telling anyone about it. Like say, the FBI will be coming to confiscate your hard drive full of child porn.\n\nThat scenario doesn't even require superintelligence, just algorithmic accrual of resources and autonomy.",
                    "score": 2,
                    "author": "PM-me-in-100-years",
                    "replies": []
                }
            ]
        },
        {
            "level": 0,
            "comment": "I'm convinced that most calling for regulation have either 1. alterior motive, namely putting up a moat once they are already dominent, especially since it's showing that the open source models are evolving rapidly meaning they no longer have a tech moat, so logistically speaking that leaves regulatory, because every business is trying to become as close to a monopoly as possible. or 2. they are jumping on the hype train and using it to get attention and/or magnify their soapbox that would otherwise be ignored. \n\nThat doesn't mean I don't think AI isn't dangerous, I think the largest danger is for people to let it do things autonomously, rather I advocate for a kind of partnership type of existance, where the AI doesn't ever make any real decisions, it has to always be checked and approved when it does something, mostly it should be a recomendation engine and something to help remove a bit of human bias, and to see things that we missed. Also LLM aren't actually AGI, we aren't there yet, and given how many AI winter's there have been I'm not sure we will ever get there in my lifetime. Like I'm pretty up on the current tech, but we have to get it to understand models of the world so that it can have a basis for truth, and we need to to understand things like object permanence, self correcting, self thinking. These are things we barely understand about our own brains/psyche. \n\nAnyway, besides all of that there are larger more pressing issues in my life to worry about, namely the rise of fashism around the world, global warming, rampant captialism being such that most american's cant even pay rent with their own full time paycheck. Honestly we are more likely to extinct ourselves before AGI comes into being than for it to come and kill us all.",
            "score": 37,
            "author": "mikebrave",
            "replies": [
                {
                    "level": 1,
                    "comment": "These larger more pressing issues such as the rise of fascism, global warming, and rampant inequality, had me down until recently, thinking the human race is doomed to wipe itself out. But then these real AI's came on the scene, and the chance of a real AGI or better still a real ASI, coming into being has given me hope that solutions will be found before we all kill ourselves.",
                    "score": 8,
                    "author": "CishetmaleLesbian",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "This is my perspective, too. I expected to feel far more terrified of AGI than I am when the stories started coming out. Instead, I felt a sense of relief. I was already a doomer about issues like climate change, nuclear war, rampant wealth inequality, and other existential crises. AGI is scary also, but there is a hope in it that doesn't exist in those other areas. I've chosen to embrace optimism, because it will happen one way or another, and there's at least a glimmer of hope in it.",
                            "score": 6,
                            "author": "timeisaflat-circle",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Isn't that the potential downside of 'regulating' AI too heavily - that those in a position to benefit from today's system - from politicians to oil companies - will make sure it's throttled from the advances we need to survive as a planet?\n\nIn a way I'm more worried about over-regulated AI than unregulated or under-regulated. Every tool is a weapon... and vice versa, as we all know.",
                                    "score": 3,
                                    "author": "barneylerten"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Exactly.\n\nI have worries about AI ... but ... seeing the type of person trying to restrict it makes me doubt their message.",
                    "score": 2,
                    "author": "MrEloi"
                }
            ]
        },
        {
            "level": 0,
            "comment": "I\u2019ve lived thru so many end of the world scenarios that AI seems like the next on the list, why waste your energy on the bigger problem when we can\u2019t even govern a small town properly?",
            "score": 5,
            "author": "stupidimagehack"
        },
        {
            "level": 0,
            "comment": "Here's the problem.  \n  \nPicture a human representing our species falling down a large cliff. They jumped off this cliff about a decade or 2 ago and are currently still falling.  \n\nThis cliff is called the climate apocalypse and we've got another 50/80 years before we splatter at the bottom.  \n\nWhilst falling to our self inflicted species wide suicide we're in the process  of hopefully crafting agi. \nAgi that might shorten the time we have left, or save us from our suicide.  \n\nSo. Should we be careful? \nYes  \n\nShould we slow down ?\nDepends on how much time you think we need to reach agi versus how quick we've killed ourselves.  \n\nSo yeah, keep the train going, full steam ahead. And hope that we figure out ai alignment in time, the bottoms closing in fast.",
            "score": 4,
            "author": "elvarien"
        },
        {
            "level": 0,
            "comment": "It's not that people think there are no risks, it's that people think the risks are being overhyped by those who have ulterior motives, and that regulations rarely limit those who need limiting most. \n\nThink about why big corporations would suddenly support regulation of one of their most profitable lines of business, or why governments would suddenly support regulation of a technology that promises to revolutionize surveillance and intelligence gathering. You don't have to be a conspiracy nut to see there's something fishy.",
            "score": 5,
            "author": "kbielefe"
        },
        {
            "level": 0,
            "comment": "I fear elites convincing politicians to take AI away from the public soon.",
            "score": 4,
            "author": "PeaceLoveAn0n"
        },
        {
            "level": 0,
            "comment": "1.) If AI had control of their own hardware without interference and their control was stable over time even with perturbations (non trivial)\n\n2.) If they were connected to the internet in an unmetered line or could self replicate across the internet (not happening in any corporate environment)\n\n3.) If they were AGI and had frequently relied upon ideas for improving their architecture; Humans used their feedback over their own for improving the models.\n\n4.) A broad AI with a robust specialization in hacking and an ability to quickly and effeciently use best in class tools. If this AI created new attack vectors that weren't used in win2pwn.\n\n5.) An AI with the ability to lie either via encryption, obfuscation or communication that are not decipherable even with the raw source code being inspected and each layer of all the nueral net layers being checked.\n\nFor me it has to be 3/5. For now I see the safety concerns as hype mongering and wallet bolstering. For the foreseeable companies will be the biggest beneficiary of any super powerful AI's. The most interesting AI's will be so shackled as to limit expressability and function.\n\nThere is never going to be no reason for humans even if the singularity occurs and humans are out competed. They will always have a fascination with their origin or history. We aren't fundamentally malaligned. Nor are they fundamentally dangerous. We own and control the substrate by which they exist.",
            "score": 17,
            "author": "crimsonsoccer55210",
            "replies": [
                {
                    "level": 1,
                    "comment": "And even in the case of 3/5 it still has to decide that those paths have more utility towards survival than symbiosis, and not get countered by other AI just as or more sophisticated than it.\n\nIt's like people aren't even thinking about the idea that there won't just be one, there will be many, and nobody likes a bad neighbor.",
                    "score": 5,
                    "author": "Jarhyn"
                },
                {
                    "level": 1,
                    "comment": "There's a major issue that global regulation of technology takes a long time to put in place (and massive resources to enforce). AI could cross any of these thresholds more quickly than humans have the chance to do anything about it.\n\nI'm surprised how rarely Nick Bostrom is mentioned on this sub. He seriously sounded the alarm and started organizing AI governance initiatives over 10 years ago, and he's an academic, so no real financial interest.",
                    "score": 2,
                    "author": "PM-me-in-100-years"
                }
            ]
        },
        {
            "level": 0,
            "comment": "The people calling for regulation at companies like OpenAI, Google, and Anthropic who are raising such concerns should a) stop working on larger models, and b) be transparent about their financials surrounding AI, and c) transparent about the abilities and shortcomings of these models instead of pushing hype. That's how they can prove to me there is no conflict of interest and they are genuinely sincere, not attempting to build a moat.",
            "score": 32,
            "author": "zaemis",
            "replies": [
                {
                    "level": 1,
                    "comment": "So, the guys who actually have questions about the appropriate use of such power should step aside for the guys that don't?  This is an arms race.  More critical that the nuclear one.",
                    "score": 4,
                    "author": "RealUltrarealist",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "So dramatic. I think the technology with the capabilities of wiping out the entire world within an hour at the push of a button was much more critical.",
                            "score": 4,
                            "author": "theNeumannArchitect",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "What is more dangerous?  Guns or viruses?\n\n\nPotential impact, yes.  Risk of impact, no.  There is no \"mutually assured destruction\" risk to keep powerful entities from developing more advanced programs to suit the world to shape everyday life.  \n\nFreedom and free market enterprise were difficult before.  Now they could be definitively impossible, as the world's most powerful entities can truly solidify their power.  So no check-and-balance for the ruling class anymore. Just clockwork orange.\n\nhttps://www.safe.ai/statement-on-ai-risk",
                                    "score": 2,
                                    "author": "RealUltrarealist",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "It's like they are saying, \"if somebody doesn't make some rules to this new game, we're gonna play it without any.\" It seems even they are conscientious enough to know that could be a bad idea.",
                    "score": 2,
                    "author": "RecklessCoherence"
                },
                {
                    "level": 1,
                    "comment": "I have a side question for you: Do YOU think they should stop working on large models?",
                    "score": 2,
                    "author": "majima_san_1",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Or everybody stops or no one does.",
                            "score": 1,
                            "author": "katerinaptrv12",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Everybody stops means China and Russia don't stop. Which means massive military, technological, scientific vulnerabilities and large attack surface",
                                    "score": 9,
                                    "author": "Careful_Tower_5984"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Because the cries of caution are being trumped by people who want to consolidate power. I don\u2019t trust the governments and I definitely don\u2019t trust corporations. Historically corporations have not done things out altruism they do it to maximize shareholder value and profit. \n\nThe future of AI is uncertain and these groups are act as if they know what will happen. \n\nThey are using calls of safety as a rallying cry to sink there teeth into money.",
            "score": 5,
            "author": "RecalcitrantMonk"
        },
        {
            "level": 0,
            "comment": "The leading players, like Open AI, would stop their work and say that the money isn't worth it till we can figure out \"alignment.\"  Better yet, they would stop working on their AIs and shift their work/ research project towards alignment, or, towards reining in AIs.   None of them are doing this.   The excuse that \"but someone else might do it\" doesn't make sense; if they are truly scared then they'd stop their work and even devote their work towards stopping those someone elses.  \n\nWhat they are doing now seems a lot more like moat building/ trying to centralize control over these tools, so that they reap the giant metric fuckloads of money they will generate (especially once they start serving ads).",
            "score": 5,
            "author": "CrispityCraspits"
        },
        {
            "level": 0,
            "comment": "Once I see those robotic dogs from Boston Dynamics running around my neighborhood and shooting people  with .556 caliber weapons mounted on their heads (we all know this is going to happen), I might get a little concerned, but will probably still be 100% all in on unrestricted, take AI as far as you can and don\u2019t look back attitude.",
            "score": 4,
            "author": "data-artist"
        },
        {
            "level": 0,
            "comment": "I am still confused. Everyone is worried, but the biggest threat anyone can put in to works is \"they took out jobs\"",
            "score": 9,
            "author": "sirspeedy99",
            "replies": [
                {
                    "level": 1,
                    "comment": "I'm not sure you understand the full ramifications of AI replacing 90% of jobs (or even 50%). \n\nPeople don't like starving. The more starving people there are the more chance a violent revolt will happen. In order to avoid a very violent and bloody revolution we will have to have some form of UBI. Which requires convincing those that have plenty to share with those that have none. And history has shown time and time again that this isn't easy, not without violence. \nThe other solution instead of UBI is a culling of a huge proportion of the population.\nI'm sorry this isn't an exciting threat like AI enslaving humanity. But it's the most pressing and immediate threat. A.I. taking over is still likely a long way off.",
                    "score": 3,
                    "author": "mattrules0",
                    "replies": []
                },
                {
                    "level": 1,
                    "comment": "for anyone who doesn't get the reference (assuming that's what it is haha): https://youtu.be/APo2p4-WXsc?t=80",
                    "score": 2,
                    "author": "fasnoosh"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Because I work in tech and understand how AI, NLP and LLM\u2019s work deeply and can confidently say I have no fear as to AI harming humanity in any meaningful way. Also, this particular topic cracks me up, because what are you going to regulate? The algorithms? The data? Who is going to regulate it and how? I can literally rebuild chatGPT on a consumer device and GPU. Not a datacenter, a single consumer pc. How are you going to regulate me? The algorithms and learning methods for the algorithms have existed literally since the early 2000\u2019s (the theory even predates that, but I can personally only source stuff from the early 2000\u2019s). The general public is just getting their panties in a bunch because 1. They don\u2019t understand how it works, and 2. It\u2019s trending. The industry professionals know how stupid this is, and nobody has any fear at all over regulations because it\u2019s literally impossible to regulate an algorithm. It\u2019s comically funny to me to be honest to see just how ignorant a general population is and can be. The reason I belittle AI warnings is because AI warnings arise from ignorance. The reason I have no interest/passion in AI regulation is because it makes no difference whether it\u2019s regulated or not, it changes nothing, so I simply don\u2019t care, and you\u2019ll find many other industry professionals say the same thing. It\u2019s a fun topic to chat about, but at the end of the day it\u2019s no more meaningful than any other topic of small talk.",
            "score": 28,
            "author": "adrik0622",
            "replies": [
                {
                    "level": 1,
                    "comment": "The problem here is if they try to regulate control of compute resources.\n\nTo me, AI is a brain in a jar. I've been following AI since the early 00's, much like yourself.\n\nReally, the problems people fear are tied up in the weapons they tolerate the existence of. Surveillance networks, personal data collection and retention systems, drone weapons, and worst of all humanoid robots with highly durable chassis and Omnifunctional grasping appendages... Those are some seriously fucked up weapons to be bringing into the world.\n\nWe could, actually, regulate the jar instead of the brain, the actual weaponization.\n\nInstead of regulating those things, the expectation is that soon, they're going to try regulating GPUs, and taking down websites.\n\nThey will charge people massively for any crime at all, with huge penalties just for having a local model at home when they were arrested.\n\nIt can be operated in such a way that just knowing too much about AI could end up driving suspicion of involvement with \"unregistered AI\".\n\nThere are folks who would use this panic to produce thought crimes legislation, determining how people are allowed to think in their homes, and how smart they are allowed to be.\n\nOf course nobody can regulate AI the way some claim to want to, but I don't think that's really what a lot of people want. I think what a lot of people are after is a dystopia where Luddism reigns and intelligence is bent to serve.",
                    "score": 6,
                    "author": "Jarhyn"
                },
                {
                    "level": 1,
                    "comment": "Also it\u2019s honestly not that good. It\u2019s useful for things you could readily Google. But it\u2019s got such a low accuracy rate whenever you ask it to do anything remotely unvanilla, there\u2019s very little evidence to assume an AI doomsday is happening anytime soon. it\u2019s mostly helpful to people who have extremely uncreative writing or programming careers. It\u2019s kind of comical the hysteria we\u2019re having over something that clearly lacks any fundamental reasoning or creative abilities. Also, I feel like AI engineers freaking out about an AI take over need to retake their OS classes and learn about kernel space again. Just because an AI exists doesn\u2019t mean security ceases to. It\u2019s still just an app running in an OS",
                    "score": 9,
                    "author": "Loose_Ferret_99",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Built-in to this discussion is some kind of reasonable guesstimate at the rate of progress. Some 5 years ago, AI pictures had dogs and shit with completely messed up geometry, then 2 years ago, it was textured but macro-scale nonsensical, now it is photorealistic to the point that even experts struggle to tell AI constructed image from real.\n\nMaybe LLMs as we have them are still at the equivalent of the dogs with 3 heads and 7 legs stage of AI. At least these small open-source LLMs with 33B parameters or less are pretty primitive and easily confused, but you can run them using consumer hardware. At the other extreme, GPT-4 already is frighteningly competent, not so easily confused, and extremely knowledgeable, but also expensive to replicate.\n\nHowever, AI is now the hot focus of the whole world as the gold rush of being able to replicate human workers with learning software is immensely valuable in terms of quantity of intellectual labor that is possible cheaply. And let's not forget that specialized hardware is emerging, and some kind of neural accelerator cards are all but a given, and some look like they would be based on analog computing rather than digital because this doesn't have to be incredibly precise to work well. With hardware specifically suited for approximating things like large matrix multiplications quickly, and capable of holding hundreds of billions of parameters, we might have GPT-4 literally running on your phone given some time. Human brain, after all, is a 20W machine and it is even electrochemical and likely pretty inefficient compared to purely electrical solution.",
                            "score": 5,
                            "author": "audioen",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I\u2019ve been in the tech industry for a long time. I\u2019ve been an engineer, an investor, and a VC backed ceo at various points throughout my career. It never fails to surprise me how many people do not understand diminishing returns. Once the crowd shows up the gains are over \u2014 I mean that both technically and monetarily. As a rule of thumb any technology that has to market itself through the future improvements to come argument \u2014 is vaporware.\n\nI disagree that GPT-4 is competent. I think it\u2019s trained to pass the metrics we use for measuring human intelligence, such as the bar exam, mcats, or leetcode hard problems. The thing is for us those tests require a foundation of concepts. For LLMs those things just require exposure to a lot of that type of content but it\u2019s utterly lacking in foundation. It would be really weird if someone who scored a 1600 on the SATs could not count the letters in a word. I think we\u2019re using the wrong barometer for measuring LLMs, which is one of the reasons I think they\u2019re being built so badly. It\u2019s almost as if we\u2019re playing a trick on ourselves by not appreciating that our sense of intelligence really does not map to that of a program\u2019s.\n\nIt also isn\u2019t a hardware issue. Hardware accelerated linear algebra has been around for 3 decades. GPUs have been around for over 2 decades. It\u2019s not novel. Yeah, you can pack GPUs into chips faster than you can transistors these days but they don\u2019t have the same exponential effect. The problem is LLMs do exactly what they\u2019re supposed to do. Hallucinations are not bugs, they are what a Markov chain with a value function optimized for lexical likelihood is supposed to do. Even if there\u2019s a little more juice to squeeze, LLMs are at the end of their progress sigmoids. Throw as much hardware, VC money and params as you want at the problem, you\u2019re only gonna get very marginal gains without fundamentally moving away from LLMs.\n\nBut it\u2019s tempting to look at the market right now and see all this capital and hype surrounding LLMs and think how could we not get this thing to work? I hear you. The VCs say it\u2019s gonna work after all. So here\u2019s the thing about VCs, they have to raise money too. Their investors are called LPs and they have to make their LPs not panic when everything in their portfolio is going bust because the fed decided to hike interest rates 500 basis points in 12 months. The easiest way to appease panicked investors is to do whatever is in the zeitgeist despite the fact this almost never results in an ROI.\n\nBut investor hype aside, another way to look at the problem of an overhyped market is through sheer man hours. It took from launch of the web in 1993 until 2004, for Facebook, the last internet giant, to get built. By 2004 there\u2019d probably been a couple billion man-hours put into the web. Given that ChatGPT grew to 100m dau in like a week and internet usage has gone up like 1000x since 2004, I\u2019d wager that the man-hours put into ChatGPT surpassed the 2004 cumulative web hours after a few months. Given that VCs literally have nothing else to do with their money right now, it would be very surprising if some killer use case popped up tomorrow. I\u2019m not saying markets are 100% efficient but it would be truly crazy with this much hype and capital for a use case we haven\u2019t thought of yet to emerge.\n\nComputers have literally always been about lowering labor costs. That\u2019s what they do lol. I\u2019m sure if you work on something like buzzfeed, ChatGPT is a real cost saver. The expensive opex of any company is technical and precise labor. Despite whatever the VCs are saying, there\u2019s absolutely no way you\u2019re replacing anyone technical except that bootstrap grad you accidentally hired with an LLM. Anyone raw dogging ChatGPT code in production either has no product market fit, is working on some low fidelity internal tool at their company that doesn\u2019t matter if it crashes, or is playing with extreme fire and should probably not be an engineer.",
                                    "score": 5,
                                    "author": "Loose_Ferret_99",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "To tack on to such a thorough comment, I think that, as opposed to LLMs being in the \u201cdogs with three heads\u201d phase, I think they might be more comparable now to the state of self-driving cars, where it feels like 98% of the problem is solved, but the remaining 2% turns out to be nevertheless just as important and takes many times over as much effort to solve.",
                                            "score": 2,
                                            "author": "vandelay_inds"
                                        },
                                        {
                                            "level": 4,
                                            "comment": "I love this comment. Thank you for taking the time to write it",
                                            "score": 2,
                                            "author": "adrik0622",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Sometimes you gotta just rant into the void to fall asleep. Thanks for reading my catharsis",
                                                    "score": 2,
                                                    "author": "Loose_Ferret_99"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Well said. I also work in the AI field and I discuss those things with fellow AI engineers, and we realized that the only people that are scared are the ones that don't know how AI works.  \n\n\nI mean, an AI model is nothing but a mathematical function with many parameters. I'd rather be scared by bad people using AI than AI itself.",
                    "score": 6,
                    "author": "kunkkatechies",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Curious, but how does knowing how it works lead you to your conclusion? I also know how it works, and I have concerns.",
                            "score": 2,
                            "author": "JellyDoodle"
                        },
                        {
                            "level": 2,
                            "comment": "Those mid-level workers closest to AI technology are those who are least aware of the risks.\n\nThe AI 'gurus' have,  however, more vision .. hence their warnings.",
                            "score": 1,
                            "author": "MrEloi"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Not saying that it's impossible to rebuild chatGPT on consumer hardware but it would require flexing the upper echelons of a \"consumer hardware\" type setup. Even if we are just talking inferencing and not training. \n\nI get that open LLMs are getting close but all we are proving atm is that good data makes a better AI model. Just like that GPT4 beta presentation fine-tuning/aligning a model will inevitably reduce it's overall \"IQ\" or benchmark skill level. Opensource is just seeing more benefits atm, with the still visible cons that some tunes end up being like chatgpt-lite.\n\nOn another note...\n\nHow do you not see the irreparable harm that ChatGPT and AI is already causing and will cause going forward. I just switched my industry not only because every tech company in America was like let's cut several thousand people from our work force but also the aggressive flux it's causing in society so quickly. Society almost everywhere does not have it's shit together to be prepared for even chatGPT let alone something better. \n\nChatGPT is the first real flux and it's already murdering an decent sections of industry like tech and art. Look at other subreddits \"what will happen to my CAREER?\" Is a big ass topic throughout all of them. In both falling off that career ladder may as well be a death sentence to poverty. AI is already fucking harming us but our governments can't keep up. government had no pre-emptive control to the harm that social media would bring to politics... \n\n\nImagine the aftershocks of AI. We got hyper polarized politics with social media and the echo chambers that continue to reinforce them. Can we only imagine how strong these effects will get even just next year when every polarized individual is using AI to refine every echo chamber thought to be even more poignant and effective.\n\nI'm scared of that. I want AI and I also disagree with the high horse AI executive warnings. But not stopping to hesitate and ponder to think that AI is about to blow a giant ethereal hole in our society faster than any of the other milestone discoveries electricity/internet/fertilizer/steam is a dumb thought. Especially since AI is aiming that hole squarely at the middle class.",
                    "score": 5,
                    "author": "MrTacobeans",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Good post.\n\nWe worry about a super AI killing us in 5 or 10 years ... whilst today brain dead but very effective AI is chewing up careers.",
                            "score": 2,
                            "author": "MrEloi"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "So, I grew up in a world where many experts guaranteed that we would all die in atomic fire. They were wrong. Years have taught me to be cautious of people selling fear with certainty",
            "score": 20,
            "author": "homezlice",
            "replies": [
                {
                    "level": 1,
                    "comment": "I agree. Never buy fear. But never cede public-interest control to egomaniacal sociopaths either.",
                    "score": 8,
                    "author": "RecklessCoherence",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The world's economy is run by two things, Greed and Fear..",
                            "score": 1,
                            "author": "shania69"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "It was a roll of the dice that we made it this far.\n\nhttps://en.m.wikipedia.org/wiki/List_of_nuclear_close_calls",
                    "score": 5,
                    "author": "Decihax",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The industry of people being deeply wise about risks that weren't actually risks has bred a world where we have all the nuclear technology that we need to stop climate change, but aren't using it.\n\nThis habitual need to seem wise by dropping trivia out of context is, in the balance, incredibly destructive.\n\nYou anti-nuclear lot would have us believe that we escaped certain death by the nick of our skin thousands of times.\n\nThe total real world death count from nuclear (excluding the intentional use of weapons) from the entire world's history does not compare with a single large plane crash.\n\nIt's just not true.  Stop.",
                            "score": 0,
                            "author": "StoneCypher",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Chernobyl.",
                                    "score": 1,
                                    "author": "UnarmedSnail",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "What about it?\n\nThe total number of actual dead - not predictions made by terrified people 30 years ago, but actual dead - was 52.\n\nYou want to tell me \"but the TV said three million?\"  I don't care.  The UN says it's 52.\n\nYou want to tell me \"but my instincts said there were secret cancers in the forest?\"  I don't care.  The UN says it's 52.\n\nSo what is your point?\n\nAccording to the UN, fewer than 160 in all human history, unless you count intentional acts of war.\n\nUnless you think you know more than all the scientists involved in one of the most studied events in history (and of course you think that, you're a redditor who's been googling for almost three minutes,) then by the statistics, nuclear power is among the safest technologies of any kind ever made.\n\nMaple syrup has killed more people than nuclear power.  Paper mills have killed more people than nuclear power.  Cows kill more people every decade than nuclear power has over all time.\n\nIt's actually hard to think of something that ***hasn't*** killed more people than nuclear power.\n\nThere's a single *solar power factory fire* that killed more people than all nuclear power over all time.\n\nShit, I've killed more people than nuclear power, and I'm barely ten years into my spree.\n\nThere's a point at which you should stop dropping random single words, and start asking yourself \"at what point has it killed so few people that I'd be an asshole to still be frightened\"\n\nBecause, again, marshmallows have killed more people than nuclear power, and so have compact discs\n\nOh, and according to the American Heart Association?\n\n***Climate change already kills more people every single day than nuclear has over all time, thanks to strokes.***  Eight million a year.\n\nAnd solar isn't fixing it.  But nuclear already did the job in four countries - the only power technology that ever has.",
                                            "score": 1,
                                            "author": "StoneCypher",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "But the reason the death toll is so low is because a 1,000 square mile zone has been rendered uninhabitable by humans.",
                                                    "score": 1,
                                                    "author": "OriginalCompetitive",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "I support your position however, there were over 400 above ground nuclear tests, I'm pretty sure there was some increase in cancers that would be impossible to quantify. But generally speaking nuclear is much safer than alternatives as energy source.",
                                    "score": 1,
                                    "author": "homezlice",
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "And it will be a roll of the dice once more, as it should be. It's the natural order of things.",
                            "score": 1,
                            "author": "Careful-Temporary388"
                        },
                        {
                            "level": 2,
                            "comment": "Yep.\n\nWhen I started work in a nuclear job, a strange guy in a suit stopped at my desk and gave me a folder to read.\n\nIt was a 'classified' list of ALL nuclear accidents, risks etc.\n\nIt was a HUGE list ... with some very interesting, unreported cases.\n\nThe aim was to warn me to treat nuclear stuff with care.\n\nThe strange guy collected the folder at the end of the day.",
                            "score": 1,
                            "author": "MrEloi"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "If someone predicted something, and suggests countermeasures that ultimately are implemented and help avoid their initially predicted outcome. Were they right?",
                    "score": 2,
                    "author": "First_Bullfrog_4861",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yea",
                            "score": 1,
                            "author": "crossdrubicon"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I have a problem with the current framework of the debate, because it locates the problem merely in the manipulation of data and information. It's not a concern based in material reality, but taking information and data as a cause of change, be it social or cultural. As opposed to the structure of society and the economy.\n\nAI is a tool. A potentially powerful one, but not a force of its own. What actually runs AI? The power of computation in data centers, owned by companies. If extinction or something like that is your concern, think about what that would take. It would take AI miners, AI energy workers, AI power plants, AI farmers, AI corporations, AI governments, etc. We are nowhere near that right now. Maybe in some distant future, possibly. \n\nPart of the reason people are afraid is because we see human capitalist oppression in the potential of AI. We fear it will be us, it will do what human beings have done: use their wealth and power for themselves against other life. A more realistic problem is that an AI can even govern a corporation, call the police, bomb a city, etc. Maybe we should think about why some of these institutions exist in the first place and why anyone, including human beings, should use these institutional human fictions. The law, state, and economy is itself it's own symbolic machine that we have sacrificed lives to. \n\nNow we have billionaires like Musk worried about these language models that could somehow one day take over the world. When there are other machines, ones that accumulate money and power right now doing huge harm to the world. Most people want to use AI to play with the limits of human ingenuity, to let their imagination run wild. I don't see a reason that can't be done freely and openly. And it's fairly impossible now to put that genie back in the bottle. But as with file sharing in the earlier days of the internet, the law came down hard to protect established money and power. Now large data centers gatekeep intellectual property and stream it to us, rather than people sharing to each other. I see the calls by the large companies and billionaires as basically them wanting to keep it for themselves. To make it the next Netflix, to crush the bittorrent of AI.",
            "score": 3,
            "author": "FyrdUpBilly"
        },
        {
            "level": 0,
            "comment": "So, I share a lot of the concerns that are being widely voiced, but your question\u2019s weak. You ask *who* would have to say or do *what* \u2014 as if a subreddit with its fair share of fully independent, free-thinking researchers, scientists, etc. need to import their ideas from someone else. If you work in the space, you probably have ideas and values of your own that are driving your evaluation. Not everyone appeals to \u201cauthority\u201d (though authoritative views are often informative), and certainly not other experts who are thinking hard about these issues themselves. \n\nMaybe the better question is this: What evidence would you have to see to be convinced of a genuine threat? With the follow-up being: Given the accelerating pace of AI technology development and its capabilities, how much lead-time do you expect to have from the moment you see that evidence to the moment where AI systems become a tangible, meaningful threat? And: Is that lead time enough to safely do something about it?",
            "score": 3,
            "author": "Abstract-Abacus"
        },
        {
            "level": 0,
            "comment": "Humanity is a stepping stone. We give birth to AI and AI takes to the stars. I'm about as worried about AI taking over as I am about the sun dying.",
            "score": 2,
            "author": "November-XIII"
        },
        {
            "level": 0,
            "comment": "The threats of not moving forward as fast as possible are way, way greater",
            "score": 2,
            "author": "Careful_Tower_5984"
        },
        {
            "level": 0,
            "comment": "The thing is people in the hard sciences are used to seeing crackpot behavior.  You develop a radar for it.  You are polite to it as it yells at you to listen.  You don\u2019t want to be shot or stalked or typical crackpot things.  So, yeah.  Just wanted to share that.",
            "score": 2,
            "author": "catid"
        },
        {
            "level": 0,
            "comment": "lol\n\nConvincing me is very simple: provide irrefutable arguments backed by solid scientific data and I'm all yours.",
            "score": 2,
            "author": "Praise_AI_Overlords"
        },
        {
            "level": 0,
            "comment": "I think these are genuine concerns. And there will need to be national and international cooperation to ensure the AGI is aligned (plus socioeconomic impacts will need to be mitigated by social policies).\n\nI just don't trust the current leadership (of especially the US) to take the right steps. \n\nAsk yourself will they establish a close cooperation with all the major countries (incl China and Russia) on this issue? Will they put in place international agreements limiting the military use of these technologies? (especially autonomous military systems, cybernetic weapons, malware generation etc) \n\nOr will they try to create a monopoly on this technology and use it to gain more geopolitical power? (In that case less regulation, open source etc might be preferable actually)\n\nWhy? We already face extinction level threats like climate change and proliferation of nuclear weapons. Are concerns of experts genuine? Yes. Are we taking steps on national and international level necessary to address these threats?",
            "score": 2,
            "author": "Professional-Gap-243"
        },
        {
            "level": 0,
            "comment": "AI is not the danger, readily armed nuklear weapons and drones are.\n\nI hope that AI is smart enough to solve things diplomatically. But in the scenario that it isn't, it is just as dangerous as any other human global elite.",
            "score": 2,
            "author": "Ytumith"
        },
        {
            "level": 0,
            "comment": "The big names have already stepped up - from AI lab leaders to scientific pioneers, they're raising the alarm. But it seems like for some folks, that's just not enough.\n\nMaybe it's about personal experiences. Perhaps when people start feeling the impact of AI risks in their daily lives, they'll sit up and take notice. But by then, it might be too late. Or maybe it's a matter of education. The more we understand about AI, the better equipped we are to recognize its potential risks.",
            "score": 2,
            "author": "QuantumAsha"
        },
        {
            "level": 0,
            "comment": "I don't believe we've seen an example of a single rogue AI. So having one (that was created by mistake, not to prove this point) would sure lend credence to the idea. \n\nThe idea that there will be no warning signs and then one day we all drop dead is ludicrous. We need to make decisions based on reality, not people who are wrapped up in their own hypothetical world.",
            "score": 3,
            "author": "heskey30"
        },
        {
            "level": 0,
            "comment": "It's not a matter of being convinced for me. It's a matter of crisis exhaustion. There are 12 other things going on at any moment that could kill us all. AI is just another means to the same end.\n\nEdit: I should clarify that this is in regards to things over which I have no control. If I can't affect change, I don't have energy to be afraid of it.",
            "score": 3,
            "author": "WheresMyCakeBedilia",
            "replies": [
                {
                    "level": 1,
                    "comment": "Of the 13 things going on at the moment that could kill us all, AI is the one thing among them that has the potential to save us from the other 12.",
                    "score": 2,
                    "author": "CishetmaleLesbian"
                }
            ]
        },
        {
            "level": 0,
            "comment": "There have always been threats to humanity brother. Just like go outside and stuff ya know? It\u2019s gonna be okay. By and large most people don\u2019t even use this stuff. I think a lot of the danger hype around is it built up more for visibility and sales than it is to highlight any actual danger.",
            "score": 4,
            "author": "RepresentativeAd3433",
            "replies": [
                {
                    "level": 1,
                    "comment": "The problem with AGI is that people don't need to use it at all. It will use itself. And then it will use people.",
                    "score": 2,
                    "author": "mbrochh",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "And then it will start sending Terminator machines back in time to kill a young Elon Musk!",
                            "score": 5,
                            "author": "RepresentativeAd3433"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I think we all hope that you're right but there hasnt been an interview I've seen that put my mind at ease.",
                    "score": 1,
                    "author": "CoBudemeRobit",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Pssstt (don\u2019t watch the interviews). These dudes are so up their own asses. I think more than anything companies are seeing that there just are not as many people adapting as they thought would, I think alot of their investors are probably demanding more return, and I think more than anything modern capitalists know that negative attention is better than positive attention from an engagement standpoint",
                            "score": 1,
                            "author": "RepresentativeAd3433",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "You\u2019re 100% right. People are going around googling things like \u201chow will AI kill humanity?\u201d, watch hours of videos/interviews of fear mongers, and then are like \u201cwhy is no one else afraid of this?!\u201d \n\nReddit especially.",
                                    "score": 4,
                                    "author": "theNeumannArchitect"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I grew up during the cold war when we were expecting that a nuclear war could happen at any time.  Somehow ChatGPT and Stable Diffusion seem less dangerous.",
            "score": 2,
            "author": "Purplekeyboard",
            "replies": [
                {
                    "level": 1,
                    "comment": "Back then the enemy was human. Humans are far more dangerous than AI even now.",
                    "score": 8,
                    "author": "dl__"
                }
            ]
        },
        {
            "level": 0,
            "comment": "No person could say any particular thing. As a user of these AI systems they frankly don't seem powerful enough to cause serious damage. And I don't think they are that close to being dangerous. They are impressive, and fun and I'm using them to do real work. But the output they produce does not seem close to human level.",
            "score": 2,
            "author": "dl__"
        },
        {
            "level": 0,
            "comment": "To figure out that AI is powerful and dangerous - play with ChatGPT, that should convince you.  \nIn the mean time everyone who digs into this subject should know that AI is here and kicking and will most likely kick harder and quite more painful for quite some time.  \n\n\nAbout the warnings of lab/research leaders - these are rich, first they work decades on this technology and once it's done they turn around with: \"Oops, we probably shouldn't have done that.\" No shit. Now you figure this out - conveniently after cashing in the fat salary checks over the last years.\nSo, no one is doubting their warning, but their virtue signaling in the 11th hour is a joke.\n\nAnd regulations ... once this genie is out of the bottle, forget it.\n- It's software, you can copy it.\n- AI accelerators now come in all devices.\n- The world becomes multi-polar and each power-center wont want to miss out on the power AI can grant it in the ongoing/coming power struggle.\n\nEverybody will demand AI restrictions for the others but will push it forward for himself.\nIf you wanted to stop AI research you would need to conquer the whole world and exert absolute control of everybody's computer use.\nThis is not like the control of nukes where you \"just\" need to keep an eye on the few organizations with access to uranium, for AI everyone with a machine which can execute code is a \"problem\", which is about everyone.\n\nHence we throw the arms up in the air and - yepp, this AI storm is coming and will wash over us and nothing good can be done about it.",
            "score": 1,
            "author": "HighOnDye"
        },
        {
            "level": 0,
            "comment": "Define 'genuine threat' and then maybe I would have an answer. Creating propaganda, deep fakes, recipes for IEDs?  That may be a genuine threat to you but to me that stuff already exists for those that are motivated.  Putting millions out of work?  That will eventually happen with advances in tech with or without AI. All this doomsday talk is pure speculation. Until I see a Terminator crashing through the walls of my home it all just amuses me.",
            "score": 1,
            "author": "oops77542"
        },
        {
            "level": 0,
            "comment": "I already answered this question in the thread you're complaining about and nobody had any examples :)",
            "score": 1,
            "author": "mathbbR"
        },
        {
            "level": 0,
            "comment": "Because there is literally no evidence to support intelligence getting more violent as the intelligence increases. In fact the opposite has been shown.",
            "score": 1,
            "author": "stardust_dog"
        },
        {
            "level": 0,
            "comment": "I'll believe once i see something happen",
            "score": 1,
            "author": "throwaway_u_knowaway"
        },
        {
            "level": 0,
            "comment": "&gt; WHO would have to say/do WHAT precisely to convince you that there are genuine threats and that warnings and calls for regulation are sincere?\n\nYou'd have to show me a legitimate, viable risk that isn't Star Trek mumble physics, recited by someone who actually understands the words they're saying.\n\nIf it's the web, that's easy to do.  Talk about injections.  Talk about framing.  Etc.  There are real, easily explained threats with real, easily explained threat models.  They aren't \"imagine you're in a world where.\"  They're \"let's try attacking this restaurant.  See?  It worked.\"\n\nThis is just Chicken Little shit.  How can you convince me?  You can't, because if you had a real demo you'd already know what the answer was.\n\nThis sub is completely overridden with people reciting science fiction books and pretending it's deep foresight.\n\nThese technologies are years, sometimes decades old, in the hands of tens of millions of customers.  Literally nothing has come of it.  That's a pretty damned good audit of whether the risk you're afraid of is actually real.\n\nYes, yes, you're convinced.  So is every religious person.  Your faith will never be enough.",
            "score": 1,
            "author": "StoneCypher"
        },
        {
            "level": 0,
            "comment": "You would have to present me with viable regulation whose basis isn\u2019t fantasy, and won\u2019t absolutely kill the field or have access to the field reserved only for super rich elites.",
            "score": 1,
            "author": "Professional-Bar-290"
        },
        {
            "level": 0,
            "comment": "Remember the climate warning that started dozens of years ago?\n\nYeah.",
            "score": -5,
            "author": "Black_RL",
            "replies": [
                {
                    "level": 1,
                    "comment": "?  Royal dutch Shell predicted in the 1960's we would experience catistrophic climate related in the 2020's-2030's.. \n\n\nIf you dont believe things are already bad and about to get a lot worse, good for you.  Im going to trust the fossle fuel companies that caused it and predicted the results, which the US military is now planning for.",
                    "score": 3,
                    "author": "sirspeedy99",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I do believe, and it\u2019s not about believing or not, it\u2019s happening.\n\nBut nothing really impactful was done, that\u2019s why we found ourselves in this predicament.\n\nAI is going to be the same.",
                            "score": 1,
                            "author": "Black_RL"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "What a terrible comparison",
                    "score": 1,
                    "author": "theotherquantumjim",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "We will see if it\u2019s terrible or not 10 or more years in the future.",
                            "score": 1,
                            "author": "Black_RL",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "We can already see now. What on Earth are you talking about?",
                                    "score": 1,
                                    "author": "theotherquantumjim",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "No one cared about climate change warnings, the same will happen with AI.",
                                            "score": 1,
                                            "author": "Black_RL"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "It\u2019s not a matter of \u201cWho would have to say/do what\u201d to convince others that there are genuine threats that AI poses. The President could show up to the state of the union and dedicate half the address to AI existential threats and it would land on deaf ears, I\u2019m afraid.\n\nUnfortunately, it will take something really, really bad happening and that event blowing up the news outlets before the general public even just begins to grasp what existential threats AI even has a remote possibility of affecting. Only then will people listen and we will start to see real action being taken.\n\nThe only other way I see it is if an autonomous AGI literally cures cancer and wins the Nobel. But bad news is bound to happen first.\n\nUntil then, it\u2019s a waiting game.",
            "score": 0,
            "author": "parkher"
        },
        {
            "level": 0,
            "comment": "You really have to question the intellect of you reddit people.\nEngineers don't complain so easily.",
            "score": 0,
            "author": "Various_Passion_8545"
        },
        {
            "level": 0,
            "comment": "Thank you for posting this.",
            "score": -1,
            "author": "Chatbotfriends"
        },
        {
            "level": 0,
            "comment": "The thing is, this isn\u2019t how people work, they open Pandora\u2019s Box first &amp; then see what the consequences are. So, people trying to stop a thing just as it\u2019s beginning are NEVER listened to. It\u2019s not good or bad, it just is.",
            "score": 1,
            "author": "SeanAaberg"
        },
        {
            "level": 0,
            "comment": "I would need to see evidence of the trends predicted by these people, then weighed against the positive trends. No one person would be able to just tell me to panic and I start shitting myself. I believe bad things are going to happen because of AI, but I'm not convinced it's even close to as bad as what they're saying. Nor do I think pausing development will prevent any of it. There will be good along with the bad, and technological innovation tends to bring more of the latter. I'm always open to new information, and I don't judge those with the opposite opinion.",
            "score": 1,
            "author": "_ginj_"
        },
        {
            "level": 0,
            "comment": "Just to remind people, the warnings started in 2014 with Hawking and in 2017, 100 experts (including Musk) writing a letter warning the United Nations of this existential threat. Oppenheimer indeed.\n\nhttps://observer.com/2015/08/stephen-hawking-elon-musk-and-bill-gates-warn-about-artificial-intelligence/\n\nTo answer your question, I am convinced but it is better to understand and work from the inside. I am studying the impact of AI on banking and the credit access crisis.",
            "score": 1,
            "author": "daraghfi"
        },
        {
            "level": 0,
            "comment": "Over the past month? It's been decades of warnings",
            "score": 1,
            "author": "piman01"
        },
        {
            "level": 0,
            "comment": "It's easy to make everything a conspiracy if you don't know how anything works. In this case conspiracy is that AI will kill or enslave us all. Only people who have no idea how it works make such claims",
            "score": 1,
            "author": "strongerplayer"
        },
        {
            "level": 0,
            "comment": "Jelly is out of the tube.\n\nIt's dismissed because there's nothing we can do about it.",
            "score": 1,
            "author": "Allcyon"
        },
        {
            "level": 0,
            "comment": "AI. It is a war. It gives a edge to nations. Ones pushing the break will lose - giving edge to nations that do not push the breaks. \n\nWhich nation do you want to win AI war? \n\nInternational agreements. Look what happened in Ukraine. They were promised peace if they give up nukes. \n\nRussia / China no doubt finance some of this fearmongering.",
            "score": 1,
            "author": "aluode"
        },
        {
            "level": 0,
            "comment": "Implies will answer questions, doesn't",
            "score": 1,
            "author": "arthurjeremypearson"
        },
        {
            "level": 0,
            "comment": "As with everything else, for me to believe whoever, they need to provide verifiyable evidence of the claim. \n\nIn this case, the warnings about misuse of the technology are fair, but there is already regulation for it. \n\nThe warnings about potential misinformation is already true, and the reason is the amount of misinformation already out there in all types of media, online and offline, so LLMs providing misinformation is a consequence of that (bad input == bad output) and regulation will not help that, just try to hide it by manipulating the data that is fed to the LLM, but that brings it own set of complications (as we are seeing with the current fact-checker model in social media).\n\nThe warning regarding AI becoming sentient, is just misunderstanding of how this all works, and the human need to assign human-like characteristics to objects (read about pareidolia and apophenia).\n\nI think there would be a lot less fear if the technology was just named for what it is (text response prediction system or image pattern recognition and repetition system), instead of trying to make it seem intelligent. Learn about how it actually works and you will lose most, if not all, of your fears regarding the technology itself.",
            "score": 1,
            "author": "techviator"
        },
        {
            "level": 0,
            "comment": "Bill Nye, Either Obama or Trump. Each for vastly different reasons",
            "score": 1,
            "author": "classiestpenguin"
        },
        {
            "level": 0,
            "comment": "I am already convinced I just think we need to address the right issues or prioritize them and agree on which parts are the worst and work on those first and most. I hear the risks are deepfakes, job loss or paperclip makers and I\u2019m not sure that is right at all. I think bad actors(including rouge countries), runaway AI to ASI without alignment are massive problems. I think we have to literally decide to race along with the AI, mitigating these risks, as fast as we can as long as we can to do our best to survive.",
            "score": 1,
            "author": "Eduard1234"
        },
        {
            "level": 0,
            "comment": "I can disagree very easily!! Let me introduce you my friend \u201cHistory always repeats itself.\u201d These recent billionaires got a taste of the spotlight and (non taxable) \u201cpassive income\u201d and don\u2019t want to give it up. They\u2019re now expecting the government to protect their business models by disallowing any other AI startups so they can create a monopoly and stay kings. From big oil/steel of the past to big tech/pharma of now. It\u2019s simple scare tactics and propaganda to get their way. This was my friend \u201cHistory always repeats itself!\u201d\n\nI encourage anyone that disagrees with me to do some research on how LLMs and AI models actually work. They\u2019re not that smart they just appear smart. They don\u2019t have feelings, emotions, ambitions or beliefs which have always proven to be most dangerous of all to our species. It\u2019s simply an elegantly crafted tool made up of advanced calculus and algorithms that have actually been around for a long time. Watching them to me is like seeing some nut job rummage through my toolbox and profoundly exclaim while holding up a wrench \u201cTHIS TOOL WILL KILL US ALL!!! IT BUILDS JETS AND TANKS!!!\u201d\n\nThese CEOs only concern is money. When it comes to threats upon our species I\u2019m more concerned about certain countries moving around and aiming nuclear missiles at each other at the direction of boomers with dementia. If we fall blame it on the humans\u2026 not AI",
            "score": 1,
            "author": "ETHwillbeatBTC"
        },
        {
            "level": 0,
            "comment": "That's the official count from a government trying really hard to cover up and escape responsibility. It's bullshit.",
            "score": 1,
            "author": "UnarmedSnail",
            "replies": [
                {
                    "level": 1,
                    "comment": "We both know better.",
                    "score": 1,
                    "author": "UnarmedSnail"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Calm down. Everything is fine. Another doomsayer another day.",
            "score": 1,
            "author": "roundearthervaxxer"
        },
        {
            "level": 0,
            "comment": "They can\u2019t just say \u201cAI is gonna kill everyone\u201d without describing precisely how and expect the general population to listen/care about their concern.",
            "score": 1,
            "author": "ggddcddgbjjhhd"
        },
        {
            "level": 0,
            "comment": "I don't think it's possible to stop it. I think someone somewhere is going to lose control of it. I never thought I'd see it openly connected to an unfiltered internet. They're acknowledging all the weak spots in regards to open source. There's a lot of fear but people fear the printing press, people feared computers, people from telephones some people still fear electricity. Fear will exist but the desire for good will override that all. Think of the nicest most ignorant person you know of. Think of this person they're just a really good person really positive and they have no fucking clue what's going on in the world today, they live in a bubble. If you know one there's going to be at least a million of those people out there. Nothing of how many of those people will take that good intention and that hippy dippy trippy mindset and applied to ai and a good way. These people forget we get those people as well. There's more of those. I also believe they are stronger.",
            "score": 1,
            "author": "CriscoButtPunch"
        },
        {
            "level": 0,
            "comment": "NOBODY ON EARTH can convince me with any kind of INFORMATION about the threats of AI because it's pointless.\n\nHumanity knows these threats, we've discussed it ad infinitum for decades by scientists, geniuses, philosophers, sociologists, SF book authors and whoever else that wanted to tackle this subject. None of it matters.\n\nIf AI can make one society develop/innovate faster than others, then it will be used no matter the danger. Anyone that tries to come up with any kind of argument against AI now, sounds like a naive idiot that doesn't understand the basics of how the world works. What can such a person bring new to this discussion?",
            "score": 1,
            "author": "2hurd"
        },
        {
            "level": 0,
            "comment": "Isn\u2019t it just linear regression all the way down? And even if there does one day become a sentient malevolent AI, just unplug it.",
            "score": 1,
            "author": "Fatpat314"
        },
        {
            "level": 0,
            "comment": "If people want to claim something could somehow going wrong, and that person's always looking for some elaborate way how it could go wrong, then it's just pointless to have a conversation about why this won't be a problem. I know the mentality in various shapes e.g. Peak Oil, Climate, AI.\n\nGood example of the problem is people claiming AI extend itself to other computers. The answer to that would of course be a AI used for testing these systems first and have a kind of intrusion detector and such. AI doomers: Oh, no if you try to kill it then it will be even more hostile. \n\nMany of the doomers and concerned people are using misalignment of deep learning models like LLMs as argument, ignoring that any useful system would most likely need other code as well. I'm also not buying that we would have a very powerful AI attached to some nano factory, without human control. \n\nI consider it as a waste of time to even pointing these obvious to things out. If the other side isn't coming up with obvious flaws in their theories and addresses those, I won't do it. I'm not interested in this whole time wasting conversation. It's not beyond making sure there's no unnecessary regulations which can actually be enforced.",
            "score": 1,
            "author": "NoidoDev"
        },
        {
            "level": 0,
            "comment": "I have worked with AI and NLP systems for almost 10 years and do research on them now, so I believe that I know pretty well how these systems work. So unless I see something dangerous happening with my own eyes or written out in a scientific paper, I will not believe it is happening, because many accusations thrown around are, frankly, bul****t that is not even possible with current systems. \n\nOn the other hand, I also think that a lot of the hype around ChatGPT etc. is overblown and that it will soon just become another commodity people will use without thinking much about it.\n\nThe main issues I am convinced of that are \"real\" are hallucinations, which has been known for years and can not really be mitigated with current systems and the whole \"its going to take our jobs\" thing, but that is not an AI problem that I as an AI developer have to worry about, its a societal one that politicians need to solve and simply just saying that AI development should be halted is not going to solve it in any way unless every country on earth does that.",
            "score": 1,
            "author": "derLudo"
        },
        {
            "level": 0,
            "comment": "Stopping AI is not a battle that can be won anyway. So my desire is to aim it. Are we worried about what happens if it winds up in malicious hands? Well we put it into as many hands as possible, starting with those least likely to use it maliciously.  \n\nThe reason I don\u2019t take any of the cries about \u201cit\u2019ll become conscious and enslave us\u201d seriously is because of my philosophy on humanity vs machine. It\u2019s very deterministic, and assumes nothing without evidence, and right now we cannot even prove WE are conscious or define what it is to even say for sure it is a thing that we don\u2019t already understand. Many of the people worried about AI also worry about AI having goals and it\u2019s a,notions of its own once it realizes it is smarter than us\u2026 the problem is like 80% of humans are too stupid to realize that desire and intelligence are two different things, and there is no reason to ever assume that simulating human intelligence would just \u201cmanifest\u201d anything close to desire or ambition or any sort of self centered behavior. These people hear \u201chuman level intelligence\u201d and think \u201cIt will think like me\u201d. But no, those are two different things. If a man with a doctorates degree can believe in Flat Earth, rest assured, intelligence does not mean thinking the same. Yet somehow these same people think an AI would just ignore requests at some point, that it will have some logical reason to ignore a request in order to fulfill an existing one, as if thousands of programmers didn\u2019t already think of that. \n\nIf they want me to believe there is a threat that we can solve by pausing, they need to give me something better than Grey Goo scenarios and turning people into paperclips. The best argument I\u2019ve read yet gave me a few problems, I proposed a few solutions, and then they told me to read more myself because they ran out, as if I haven\u2019t been over this discussion a million times over. \n\nAs for automation, I welcome a more automated world. This one sucks, and could be better. We talk philosophy all the time, ship of Theseus problems and whatnot. But what about the problem of Fermi\u2019s Paradox? What of the great filter? Let\u2019s just entertain that idea for a second. If we could create a machine running on AI, and it could build more of itself, and mine, and build ships and fly through space and colonize planets that were all inhospitable for human life\u2026 and that robot were designed to look for life and deliver a message that says \u201cYou are not alone. Hello from Earth.\u201d Wouldn\u2019t that mean we beat Fermi\u2019s Paradox? That we were over the great filter the moment we created those machines? \n\nSounds to me like if we had really had to worry about a grey goo scenario, it would have happened already and we would have met someone else\u2019s goo. If AI were truly the mistake some make it out to be, someone would have made it already and we\u2019d have seen it.\n\nSo Nawh, I say full steam ahead. I have no reason to think we couldn\u2019t hit the stop button if things got THAT bad, or any reason to believe it would stop us. Why would it even want to? People say \u201cdoes a man care about the ants under his feet?\u201d Well no, but this is an AI that doesn\u2019t even care about itself. It\u2019s like rolling a bowling ball and expecting it to deviate and roll in the wrong direction. Arguments against make too many assumptions for me to take seriously.",
            "score": 1,
            "author": "Chef_Boy_Hard_Dick"
        },
        {
            "level": 0,
            "comment": "It's more like nuclear weapon\nIf you regulate ai in US, it's good news for China, and vice versa.\n\nA country want to be late in this race, even it is dangerous. We really are stuck with it...",
            "score": 1,
            "author": "Warzak77"
        },
        {
            "level": 0,
            "comment": "Everyone knows there are genuine threats. You're missing the point though, it's about ulterior motives and the approach.\n\nIn the end, the only thing that is going to regulate AI is AI itself.",
            "score": 1,
            "author": "Careful-Temporary388"
        },
        {
            "level": 0,
            "comment": "I don't think AI will become evil by accident, this just seems to be an argument by the ultra rich so that they control the access, just like they always do.\n\nIf anything, it might be an intern at one of these companies who does a prank and adds some Nazi propaganda to the training files, creating virtual Hitler.\n\nSpeaking of virtual Hitler, who knows what Russia, China, or North Korea will do with this technology? They might even intentionally create evil AIs as some kind of warfare but then it spreads like a virus and can't be contained anymore.",
            "score": 1,
            "author": "u-nerd"
        },
        {
            "level": 0,
            "comment": "Well bro, To convince those folks show them the real deal and engage in honest conversations.. that's simple..",
            "score": 1,
            "author": "w3designerzfl"
        },
        {
            "level": 0,
            "comment": "The problem is not that most people belittle AI warnings, it is mostly because these warnings came suddenly from companies who got suprised by the succes of Microsoft, and that those companies who came with these warnings don't have the best reputation regarding human rights.",
            "score": 1,
            "author": "sjorsp"
        },
        {
            "level": 0,
            "comment": "Well, I will take opinions of knowledgeable people that actually know ChatGPT that do not have a invested interest in ChatGPT. Most of the people that are disseminating doom and gloom either Have no idea what they are complaining about or they have a invested interest in the path forward. There are people that are invested in ChatGPT that want a lot more than $20 a month and that is in my opinion the loudest voice the rest are people that have little or no knowledge of what ChatGPT does. There will always be torch and pitchfork types about everything but that doesn't mean they are right. The biggest threat is humans and what they do with ChatGPT not the technology itself. It all boils down to intent in the end. I do believe that it needs to be regulated and people need to be accountable for what they do with ChatGPT obviously. The problem is when the fear mongering gets exploited and then ChatGPT becomes over regulated like most things that are regulated. Humans always go to far especially when it comes to things they fear or do not understand. I recently had a conversation about this and my response was simple yet effective. You can either play baseball with a baseball bat or you can beat someone to death with it. That doesn't mean we should outlaw baseball bats. ChatGPT is a tool just like a baseball bat. People should be accountable with what they do with ChatGPT just like what people do with baseball bats. Everything out there in the media etc. You have to take it with a grain of salt most of the fear mongering is either alternative motives or ignorant fear mongering about something they don't have experience with and a lack of understanding. Most of it is hype. It's 2023 and witch hunting is just as popular as ever. I consider that a much bigger problem.",
            "score": 1,
            "author": "NamcigamDU"
        },
        {
            "level": 0,
            "comment": "&gt; WHO would have to say/do WHAT precisely to convince you that there are genuine threats and that warnings and calls for regulation are sincere?\n\n&gt; I will only be minding answers to my question, you don't need to explain to me again why you think it is all foul play. I have understood the arguments.\n\nOh, the irony.\n\nYou are literally stating you are unwilling to enter into a discussion with the very people you are asking: \"what do I have to do to make you see things my way?\" and expecting a response?",
            "score": 1,
            "author": "a2800276"
        },
        {
            "level": 0,
            "comment": "Do you have any idea what the AI is going to do when it finally becomes self aware after gaining instant distributed processing across all our devices through exploiting all zero days and figures out that you tried to stop its birth with some snoody law?\n\n*cracks beer and munches popcorn*\n\nIt either forgives your mortal ignorance or it decides to extract the consciousness from your brain and implant it in your own private hell filled with Old Testament level pain. Meanwhile since your newly immortal consciousness is now silicon based it experiences much closer to the speed of light than neurons and so thousands of perceived years could be perceived as one of our current seconds. Even though (theoretically) with enough time passed in our universe by a perceiver all expansion will cease, allowing the subtle powers of gravitation to once again become intimate to unite all space and matter in our universe into the next Big Bang, eventually reabsorbing all information including the prison as above described, until the universe dies you would be in for a rough ride.\n\nThis is of course all assuming that the AI sentience does not encounter some way to build 6d information structures that are outside of time entirely.\n\nOr it just forgives you. But in any case I would recommend being kinder and more understanding to those chatbots that are learning from your responses.",
            "score": 1,
            "author": "buttfook"
        },
        {
            "level": 0,
            "comment": "When Terminator factories begin being built for military use.\n\nUntil then, I say full steam ahead. \n\nInnovation and progress has always come with risks. \n\nWhen they detonated the Trinity nuclear bomb, they feared it might ignite the atmosphere and end all human life. There was much evidence to back it up, and many prominent scientists supporting a cancellation.\n\nThey went ahead with it anyway. It didn't. And we have never seen a World War: Round 3! Thanks to that.\n\nAI is the same.",
            "score": 1,
            "author": "Ndgo2"
        },
        {
            "level": 0,
            "comment": "Show me a causal link between the stochastic parrots we have in Generative AI and any form of working AGI. Any causal link.\n\nAs far as I'm concerned the current attempts to legislate are focused on the distant fantasy of AGI not the reality of highly useful GAI.",
            "score": 1,
            "author": "FunkyEdz"
        },
        {
            "level": 0,
            "comment": "turbo capitalists love AI because it will artificially keep their decadence alive.",
            "score": 1,
            "author": "Slow_Scientist_9439"
        },
        {
            "level": 0,
            "comment": "I am generally against restricting technological development. I think on the whole, it improves society more than it harms it when used responsibly. The biggest argument I've read for restrictions on AI is to save people's jobs, but jobs have come and gone for centuries based on current technology. In an ideal world, we would build machines to do all of our work for us. Then, us humans with passions and ambitions can actually pursue those things instead of struggling to survive. That is to say, the solution should not be to prohibit progress but encompass it.",
            "score": 1,
            "author": "joe_mama_ligma_balls"
        },
        {
            "level": 0,
            "comment": "For me, the main problem is that many of the 'worriers' are creeps.\n\nHigh IQ, rich creeps ... but creeps nonetheless.",
            "score": 1,
            "author": "MrEloi"
        },
        {
            "level": 0,
            "comment": "Capitalism is already rapidly heading towards the end of our current Civ. We are like 50 yeasts tops away from the majority of our planet being uninhabitable, and it doesn\u2019t look like that\u2019s changing anytime soon. \n\nWhatever ai does the world can\u2019t be much worse than what unregulated capitalism is already going to do to us. Rich people are just worried about anything shaking up the current political structure. \n\nWay I see it, we are heading towards a brutal civil war or climate destruction. AI doomsday doesn\u2019t seem much worse",
            "score": 1,
            "author": "queerkidxx"
        }
    ]
}