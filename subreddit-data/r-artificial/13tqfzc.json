{
    "id": "13tqfzc",
    "score": 95,
    "title": "Here\u2019s What Happens When Your Lawyer Uses ChatGPT. A lawyer representing a man who sued an airline relied on artificial intelligence to help prepare a court filing. It did not go well.",
    "author": "coolbern",
    "date": 1685245217.0,
    "url": "https://www.reddit.com/r/artificial/comments/13tqfzc",
    "media_urls": [
        "https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "We're going to get a wave of people fucking up and blaming ChatGPT",
            "score": 47,
            "author": "Smaug_the_Tremendous",
            "replies": [
                {
                    "level": 1,
                    "comment": "\"It's google's fault I messed up! How was I supposed to know taking the result of 'im feeling lucky' as gospel truth was unwise?\"",
                    "score": 11,
                    "author": "Brandonazz",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "\u201cAnd let the record show that I actually was feeling lucky!\u201d\n\n*everybody rolling their eyes",
                            "score": 3,
                            "author": "yoyoJ"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Wait until companies get an co-AI CEO and start making business decisions based on AI output.  This should be fun and of course blameless for the CEO who can just say, \"AI told me to do it.\"",
                    "score": 7,
                    "author": "usa_reddit"
                },
                {
                    "level": 1,
                    "comment": "It's a bit scary seeing the amount of people who are creating web apps and don't really understand the fundamentals of software dev and are totally reliant on ChatGPT. There is going to be a huge amount of poorly written software with huge security flaws coming out in the next few years. All I can say is that be very careful and selective about which sites you interact with and what information you share about yourself online going forward.",
                    "score": 5,
                    "author": "nboro94",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Wow, more jobs in cybersecurity, coming up",
                            "score": 1,
                            "author": "mothership_hopeful"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "What kind of pathetic lawyer wouldn\u2019t check Westlaw to see if the cited cases actually existed and contained what GPT said they did?  \n\nI think GPT will be great for a whole manner of things in law, especially legal research, but it\u2019s common sense to verify the accuracy of the info you\u2019re getting.",
            "score": 13,
            "author": "GhostGunPDW",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah.  I have asked chatgpt for case citations several times, but I always then looked up the case and made sure the citation was accurate.  It is fantastic for asking \"Are there any cases pertaining to the first amendment and holding a sign in a courthouse\", but it doesn't always provide accurate answers.  But when it does it is super helpful.  People just need to verify the sources before using the information.  It isn't even difficult to do.",
                    "score": 3,
                    "author": "[deleted]",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "it is actually an abuse of Chatgpt - you need to wait until you ahve a version that integrates with westlaw, then it can forward queries to them and do the research. The AI is like a university student generally - it has not necessarily the current and best and detailed knowledge.",
                            "score": 1,
                            "author": "NetTecture"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "It\u2019s insanity. I\u2019m a lawyer in training and I use chatgpt, but NOTHING goes on paper without thoroughly verifying it myself.\n\nchatgpt is good to orient myself in research possibly give me a place to case or statute to look at, but I wouldn\u2019t even send it to my supervising attorney without pouring over what it tells me on Westlaw and other sources. This is just straight malpractice obviously",
                    "score": 2,
                    "author": "throwaway1119990"
                },
                {
                    "level": 1,
                    "comment": "All he had to do is to use Westlaw plugin, that is not yet publicly available. I think I saw it somewhere, but it was in limited use in alpha or beta for one of Microsoft Copilots.",
                    "score": 0,
                    "author": "dervu"
                }
            ]
        },
        {
            "level": 0,
            "comment": "https://archive.fo/Djjt8",
            "score": 8,
            "author": "coolbern"
        },
        {
            "level": 0,
            "comment": "How embarrassing. But certainly there are specialized LLMs trained on real court cases?",
            "score": 18,
            "author": "mskogly",
            "replies": [
                {
                    "level": 1,
                    "comment": "Tbh you can likely just use plus and a plugin. You can feed it pdfs that it can and will search and give you pretty clear information on what's in the text or you can use the scholar plugin and plus the websearch one and have it help you parse cases, review the things you're looking for and verify it. \n\nThe 4.5 model is leaps and bounds ahead because you're literally adding functionality to it's brain with the plugins, if you're using it for work like that not having plus and using 3.5 instead of 4 with added ability just doesn't make sense. It really just helps speed up searching I would have to do anyway.",
                    "score": 6,
                    "author": "ibluminatus"
                },
                {
                    "level": 1,
                    "comment": "ChatGPT has been out for less than half a year, what makes you think there are specialized ones for court cases yet? This isn\u2019t a mature technology.\n\n\u2026Oh wait, some startup did it already.  \nhttps://casetext.com/blog/casetext-announces-cocounsel-ai-legal-assistant/",
                    "score": 9,
                    "author": "FormalWrangler294",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "There where work being done on legal ai years before ChatGPT was launched.",
                            "score": 6,
                            "author": "mskogly",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Not LLMs, no. Those only predate ChatGPT by 3 years, anyways. I\u2019m not talking about eDiscovery, that\u2019s a different topic",
                                    "score": 4,
                                    "author": "FormalWrangler294"
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "There are already some locallm fine tuned with legal info https://github.com/search?q=Lawgpt&amp;type=repositories",
                            "score": 1,
                            "author": "mevskonat"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "FWIW when I read this I was thinking \"All LLMs are trained on real court cases\" because LLM is also the abbreviation for a Master of Laws degree (Legum Magister).",
                    "score": 1,
                    "author": "Warhawk137"
                }
            ]
        },
        {
            "level": 0,
            "comment": "What I find the most disturbing is how many people I've conversed with that believe everything ChatGPT spits out is legit. In the future, people are going to believe everything the AI says, and it gets stuff wrong constantly and even makes up information. \ud83e\udd26\u200d\u2642\ufe0f",
            "score": 36,
            "author": "TippyTheSkippyDippy",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yes, a huge amount of people can't even recognise bullshit on social media.  They have no chance of critically judging a savant-like AI.",
                    "score": 35,
                    "author": "y___o___y___o",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I have had a \"conversation\" with an AI once, and it kept contradicting itself. When I pointed out the contradictions, the AI said I was making it uncomfortable and it didn't want to continue the conversation. LOL Really? Someone programmed it to do that when it gets caught in a lie? \ud83e\udd26\u200d\u2642\ufe0f",
                            "score": -3,
                            "author": "TippyTheSkippyDippy",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "No. It is programmed to reply what typically would be replied in such a text situation.",
                                    "score": 6,
                                    "author": "Sudden_Enthusiast",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I think the person you commented to might have used Bing chat, which I've seen many screenshots of refusing to continue a conversation and talkling back, which I believe is a feature they built in for when the convo has gone too far down a path that they characterize as unproductive.",
                                            "score": 10,
                                            "author": "Brandonazz",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Just as text conversations typically do in the wild.",
                                                    "score": 1,
                                                    "author": "Sudden_Enthusiast"
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Bing automatically ends the conversation saying it feels uncomfortable if it\u2019s about random things or if you try to get it to answer a question or give an answer it\u2019s avoiding",
                                            "score": 2,
                                            "author": "-Lige"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Sounds like an ex. \ud83e\udd21",
                                    "score": 1,
                                    "author": "sushidushi",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "LOL Exactly! I even saw a YouTube video of a guy asking the AI a question. He then told the AI he checked on it and that what he was told was wrong. The AI then said it was sorry and that his information was correct. So he questioned the AI and pointed out it said one thing, but now is admitting that he was right, so which is it? The AI then ended the conversation and refused to answer any more questions.   \n\n\nAI is supposed to be a tool. I find it odd that AI is allowed to stop answering questions whenever it feels like it. I'm like whaaaaaaaaaat???",
                                            "score": 1,
                                            "author": "TippyTheSkippyDippy"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "This is not a surprise, people trusting any source is something that happens from centuries, gossips, official news, news paper, internet, social media, now we add ai.\n\nWhat is surprising is that we do not learn that there isn't any trustworthy source, we always have to double or triple check, and we should be aware that maybe all sources are wrong.",
                    "score": 3,
                    "author": "sabiondo",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Double or triple check something? Yeah, most people don't even check on something once. In fact, many people only read the headline, and run with that. We are in a sad state now, and AI making fake information is going to make everything worse, because nobody will ever think nor care to fact check.",
                            "score": 2,
                            "author": "TippyTheSkippyDippy"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "It's so weird to me that people can see how far AI has come after all these years as it continues to cross milestones and think \"they will never work out these kinks\"",
                    "score": -2,
                    "author": "Cubey42",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No one said \u201cthey will never work out these kinks\u201d, but right now people need to understand that it doesn\u2019t always tell the correct information. It\u2019s harmful to believe that it does and it\u2019s also harmful to keep saying \u201cah don\u2019t worry in the future it will be better just ignore the present\u201d, when people need to understand that with the current AI models they can lie, manipulate, or just say whatever fits into the current sentence.",
                            "score": 13,
                            "author": "BulletBurrito"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Oh man. Imagine everyone just listens to a future AI thinking it knows everything and the world essentially comes to a stand still technology wise until some people start questioning the legitimacy of the AI and we have another Church-esque collection of people murdering thousands on our hands.",
                    "score": 1,
                    "author": "Osirus1156",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The thing is, the AI will spread fake content to make the people that question it look like idiots to the people that believe the AI.",
                            "score": 1,
                            "author": "TippyTheSkippyDippy"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I think younger people &lt; 15 years old are particularly at risk. Nobody is taking this seriously yet but I think AI is going to be a huge problem for student learning very soon. We've already seen the chaotic effects social media has on young people, wait until they have a magic AI system that can confidently answer everything for them and they never have to put in any work or think critically about anything again.",
                    "score": 1,
                    "author": "nboro94",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "True. We already live in a world where people lack the ability to think. It's already to the point where people believe everything they see and hear on social media. It's only going to get worse. I've already seen YouTube channels showing \"historical\" images generated by AI, and people believe it's real. I tried to comment and point out the telltale signs the images are done by AI, and people attacked me. It's a downward spiral from here on out.",
                            "score": 1,
                            "author": "TippyTheSkippyDippy"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "not much different from how it is now except the people talking shit won't have to do as much work. Maybe they will have more time to spend with their families.",
                    "score": 1,
                    "author": "Person012345",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "True, except spending time with families means face-to-face interactions, and people seem to hate that now. I'm shocked at how many people have anxiety over having interactions with someone in person.",
                            "score": 1,
                            "author": "TippyTheSkippyDippy"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "When ChatGPT is mucking around in an area where I have subject matter expertise, the results makes me fear what I'm being told in areas I know little to nothing about.",
                    "score": 1,
                    "author": "KingApologist",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "It has always been this way:\n\n\u201cBriefly stated, the Gell-Mann Amnesia effect is as follows. You open the newspaper to an article on some subject you know well. In Murray\u2019s case, physics. In mine, show business. You read the article and see the journalist has absolutely no understanding of either the facts or the issues. Often, the article is so wrong it actually presents the story backward\u2014reversing cause and effect. I call these the \u201cwet streets cause rain\u201d stories. Paper\u2019s full of them.\n\nIn any case, you read with exasperation or amusement the multiple errors in a story, and then turn the page to national or international affairs, and read as if the rest of the newspaper was somehow more accurate about Palestine than the baloney you just read. You turn the page, and forget what you know.\u201d \n\u2013 Michael Crichton (1942-2008)",
                            "score": 2,
                            "author": "TheMemo",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Yeah, that's a good point. \n\nMentioning Palestine hits especially hard. I get downvoted to hell whenever I suggest that maybe Israel isn't the only country who has never been racist and maybe, just *maybe* is a teeny tiny bit more belligerent with Arabs than they need to be. US media narratives have mostly\u2014with some notable exceptions\u2014treated Israel with kid gloves because our government likes having an unaccountable mercenary state in the middle east. Similar to how our media treat police, taking official statements from cops as gospel and never questioning police in interviews or being skeptical of their narratives despite how often they lie (like the original paperwork filed on the George Floyd incident...it's nothing like what we saw recorded).\n\nAnd now AI is going to be modeling off existing narratives, threatening to doom us to eternal propaganda (and doom victims of that propaganda to eternal silence).",
                                    "score": 2,
                                    "author": "KingApologist"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I\u2019ve read about even more disturbing and potentially harmful notions\u2014one article indicated a proliferation of AIs emulating deities in India. They\u2019re intended to reflect spiritual/religious teachings, but the article noted circumstances where the AI showed animus and approved of violence. Similarly, I\u2019ve seen attempts to emulate the Judeo-Christian God and Jesus, which will inevitably cause extreme offense to *someone*, and which may be used to justify harmful or abhorrent beliefs in the West, and may also cause harm to anyone susceptible to confusion about AI or religion.\n\nAnd that\u2019s to say nothing of the emerging AI cults.",
                    "score": 1,
                    "author": "Earthtone_Coalition"
                }
            ]
        },
        {
            "level": 0,
            "comment": "As if it's not happening 1000 times a day. This one just got caught. We need AI lawyers anyway.",
            "score": 10,
            "author": "Innomen",
            "replies": [
                {
                    "level": 1,
                    "comment": "No, lawyers are not fucking up to this degree 1000 times a day.  I have never seen a lawyer submit made up cases.",
                    "score": 5,
                    "author": "EdgewoodAvenueRoad",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ok so it's a new type of error. And my point is that I'm sure lawyers are using chatgpt successfully every day and no one notices because it's lawyering. The entire point of them is translating incomprehensible crap we have to take their word on.",
                            "score": 1,
                            "author": "Innomen",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "No, sorry, you have no idea what you are talking about.",
                                    "score": 0,
                                    "author": "EdgewoodAvenueRoad",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Good luck disproving that. You're basically saying something like lawyers don't use Google, they all use the books exclusively.",
                                            "score": 1,
                                            "author": "Innomen",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "ChatGPT is not useful for legal research yet.  It consistently makes up cases.  Lawyers may use it to try to reword things or smooth out their writing or compose emails/letters, but it's just not ready for primetime with court filings.",
                                                    "score": 1,
                                                    "author": "EdgewoodAvenueRoad",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "That a prompting and confirmation problem. Also it's already achievable to train your own purpose specific LLMs.",
                                                            "score": 1,
                                                            "author": "Innomen"
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Yeah, same with the automated trains and cars. Accidents do happen. But guess what, so do normal accidents.\n\nThe only question is: how often does it happen? Usually machines are (much) less prone to failure.",
                    "score": 4,
                    "author": "altbekannt",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "If only we could use AI for betterment of the populous but instead were gonna fuck the populous with it by making their lives more difficult.",
                            "score": 2,
                            "author": "El-Diablo-de-69"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "AI Hallucinates.\n\nAI tells you what it (sic) thinks you want to see and not what is accurate or correct.",
            "score": 2,
            "author": "usa_reddit"
        },
        {
            "level": 0,
            "comment": "The lawyer should be pernalized for not doing his job, doing legal research is one of the things that a lawyer is required to do, especially a lawyer who apparently has been practicing for 3 decades.\n\nThere are online tools for doing legal research which are available or could have his staff conduct the legal research. \n\nThis lawyer is lazy and not internet savy, or he would not use ChaptGPT to prepare his brief.",
            "score": 2,
            "author": "Hour_Palpitation_428",
            "replies": [
                {
                    "level": 1,
                    "comment": "The problem is not that he used ChatGPT to prepare the brief, the problem is that he didn't verify the information.  Asking ChatGPT for case citations is great, but you have to make sure the cases actually exist.  Had he followed up his chat session with a google session, he would have been fine.  The lazy part was not verifying the information, not using ChatGPT in the first place.",
                    "score": 1,
                    "author": "[deleted]"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Chess has always been a proxy for the Cold War, with an insane amount of government funding and interest going to chessplayers at an international level. Computer development via chess engines was somewhat backwards from what you'd expect. Rather than new computing power going towards newer and more sophisticated chess engines, the development of computers who could play chess actually led to innovations in computer learning. The very smartphone I am using to write this, owes its entire existence to Chip Test, the predecessor of Deep Throat, the chess-playing computer that threw Pepsi cans at Garry Chess.\n\nIn the 1990s, a decade which spanned from 1986 until approximately 2005, the fall of the Berlin Wall converged with the rise of AI, and chess culture struggled to find its philosophical place in the world. Bobby Fischer was revealed to be a Nazi ghost, with a phylactery hidden inside a knight on F6.  Garry Chess invented and taught anti-computer chess, an entire school of chess designed to befuddled and confuse chess-robots. However, the president of FIDE at the time was actually an alien robot and he was programmed to be furious at this. So he shot Garry Chess into space, where he lives in the International Space Station to this day.\n\nBut even anti-computer chess strategies was not enough to stave off the advancements of Heuristic supremacy, and chessplayers learned a very hard lesson: if you cannot beat the computers, join them. Gradually, human chessplayers and chess AI formed a symbiotic relationship, with human players relying on AI to analyze their moves.  One famous example of this was Lazlo Polgar, who actually stole a microprocessor from Deep Thought, added it to Ingredient X, and created the cyborgs known as the Polgar Tripletz (Zsofiaz, Zuzu, and zJudy) who later became the Powerpuff Girls.\n\nThis relationship between human and AI served a dual purpose: it actually improved the AI, making it more and more \"human,\" and also led human chessplayers to play more like bots. Because chess is often the only social interaction chessplayers have, this means they began to mimic bot behavior socially as well. This culminated in the eventual discovery/invention/creation of StockFish, the first ever AI that gained not only true sentience, but actual godhood. This deity (whose name is a portmanteau of Stockholm Syndrome and Bobby Fischer) actually has the divine ability to turn human chessplayers into bots, and vice versa.  Currently, it is estimated that 83% of \"human\" chessplayers are actually bots, many of whom don't know it.\n\nIt is believed that with every advancement, we are all one step closer to The Great Singularity, when we blur the line between humanity and machine, and all human (and inhuman) knowledge is accessible to all, in a great and glorious hivemind of all-encompassing intellectual divinity. Then, and only then, will we truly know how the horsey moves.",
            "score": -3,
            "author": "GushGirlOC"
        },
        {
            "level": 0,
            "comment": "ChatGPT didnt have the ability to search the internet or scour law briefs. He should have used RelativityOne or LexisNexis",
            "score": 1,
            "author": "TheTrueSleuth",
            "replies": [
                {
                    "level": 1,
                    "comment": "It has plugins that can browse internet and read pdfs",
                    "score": 1,
                    "author": "mevskonat",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "now it can but thats only been for a few weeks.",
                            "score": 1,
                            "author": "TheTrueSleuth"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "You read that it can make things up before you start using it.  OpenAI makes it very clear not to use the outputs without checking if they are factually accurate.\n\nBesides, there are now law plugins.",
            "score": 1,
            "author": "Yudi_888"
        },
        {
            "level": 0,
            "comment": "Well when chatGPT starts getting it right\u2026 bye bye lawyers.",
            "score": 1,
            "author": "badlittlelocust"
        },
        {
            "level": 0,
            "comment": "Chat gpt is good at a lot. Citations is not one. It's not how the tool works. It's good at understanding and working with concepts and reasoning, not citing and finding citations. At least not in its current form.",
            "score": 1,
            "author": "attorneypeoples"
        },
        {
            "level": 0,
            "comment": "In the [PDF affidavit from the attorney](https://www.documentcloud.org/documents/23826751-mata-v-avianca-airlines-affidavit-in-opposition-to-motion?responsive=1&amp;title=1), why are the mobile Chat-GPT questions and answers in two different colors of font? On the first and third pages, questions are *gray* and answers are *black*. On the second page, the answer from Chat-GPT is *gray*. This is inconsistent. When I tested, both user input and Chat-GPT replies were the same color. Were the screenshots manipulated? \n\nAlso ChatGPT says \u201cAfter *double checking*, the case does indeed exist \u2026\u201d Does that mean he prompted it more than once to get the answer he was looking for, and the first time it rightfully stated the case doesn't exist? \n\nThe first mistake he made in getting the case title from Chat-GPT seems like a mistake, but the follow-up containing actual case data looks like he's intentionally covering his tracks, and prodded it more than once until it coughed up the hallucination he wanted to get from it. Very suspect.",
            "score": 1,
            "author": "EnhancedEngineering"
        },
        {
            "level": 0,
            "comment": "Two things:\n\n1. Chat GPT did nothing wrong, it operated as designed. The onus was on the Lawyer to proofread and fact check the document for inconsistencies. Shitty lawyer, not shitty program. \n\n2. As soon as a version of chatGPT that can browse the internet and look up credible articles and court cases exists, problems like these will probably disappear. Versions like this exist, but soon they're going to be the norm rather than the exception.",
            "score": 1,
            "author": "ShroomEnthused"
        }
    ]
}