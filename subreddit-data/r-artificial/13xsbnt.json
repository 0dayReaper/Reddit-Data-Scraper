{
    "id": "13xsbnt",
    "score": 0,
    "title": "Is AI going to cause the complete extinction of mankind like how it did in 'Terminator' series very soon?",
    "author": "Block-Busted",
    "date": 1685651109.0,
    "url": "https://www.reddit.com/r/artificial/comments/13xsbnt",
    "media_urls": [
        "https://www.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/"
    ],
    "other_urls": [
        "https://www.bbc.com/news/uk-65746524",
        "https://www.usatoday.com/story/news/politics/2023/06/01/president-biden-warns-ai-could-overtake-human-thinking/70277907007/",
        "https://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html",
        "https://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3"
    ],
    "postText": "Look at these articles:\n\n&gt; **Artificial intelligence could lead to extinction, experts warn**\n&gt; \n&gt; Artificial intelligence could lead to the extinction of humanity, experts - including the heads of OpenAI and Google Deepmind - have warned.\n&gt; \n&gt; Dozens have supported a statement published on the webpage of the Centre for AI Safety.\n&gt; \n&gt; \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\" it reads.\n&gt; \n&gt; But others say the fears are overblown.\n&gt; \n&gt; Sam Altman, chief executive of ChatGPT-maker OpenAI, Demis Hassabis, chief executive of Google DeepMind and Dario Amodei of Anthropic have all supported the statement.\n&gt; \n&gt; The Centre for AI Safety website suggests a number of possible disaster scenarios:\n&gt; \n&gt; 1. AIs could be weaponised - for example, drug-discovery tools could be used to build chemical weapons\n&gt; 2. AI-generated misinformation could destabilise society and \"undermine collective decision-making\"\n&gt; 3. The power of AI could become increasingly concentrated in fewer and fewer hands, enabling \"regimes to enforce narrow values through pervasive surveillance and oppressive censorship\"\n&gt; 4. Enfeeblement, where humans become dependent on AI \"similar to the scenario portrayed in the film Wall-E\"\nDr Geoffrey Hinton, who issued an earlier warning about risks from super-intelligent AI, has also supported the Centre for AI Safety's call.\n&gt; \n&gt; Yoshua Bengio, professor of computer science at the university of Montreal, also signed.\n&gt; \n&gt; Dr Hinton, Prof Bengio and NYU Professor Yann LeCun are often described as the \"godfathers of AI\" for their groundbreaking work in the field - for which they jointly won the 2018 Turing Award, which recognises outstanding contributions in computer science.\n&gt; \n&gt; But Prof LeCun, who also works at Meta, has said these apocalyptic warnings are overblown tweeting that \"the most common reaction by AI researchers to these prophecies of doom is face palming\".\n&gt;\n&gt; **'Fracturing reality'**\n&gt; \n&gt; Many other experts similarly believe that fears of AI wiping out humanity are unrealistic, and a distraction from issues such as bias in systems that are already a problem.\n&gt; \n&gt; Arvind Narayanan, a computer scientist at Princeton University, has previously told the BBC that sci-fi-like disaster scenarios are unrealistic: \"Current AI is nowhere near capable enough for these risks to materialise. As a result, it's distracted attention away from the near-term harms of AI\".\n&gt; \n&gt; Oxford's Institute for Ethics in AI senior research associate Elizabeth Renieris told BBC News she worried more about risks closer to the present.\n&gt; \n&gt; \"Advancements in AI will magnify the scale of automated decision-making that is biased, discriminatory, exclusionary or otherwise unfair while also being inscrutable and incontestable,\" she said. They would \"drive an exponential increase in the volume and spread of misinformation, thereby fracturing reality and eroding the public trust, and drive further inequality, particularly for those who remain on the wrong side of the digital divide\".\n&gt; \n&gt; Many AI tools essentially \"free ride\" on the \"whole of human experience to date\", Ms Renieris said. Many are trained on human-created content, text, art and music they can then imitate - and their creators \"have effectively transferred tremendous wealth and power from the public sphere to a small handful of private entities\".\n&gt; \n&gt; But Centre for AI Safety director Dan Hendrycks told BBC News future risks and present concerns \"shouldn't be viewed antagonistically\".\n&gt; \n&gt; \"Addressing some of the issues today can be useful for addressing many of the later risks tomorrow,\" he said.&gt;\n&gt; \n&gt; **Superintelligence efforts**\n&gt; \n&gt; Media coverage of the supposed \"existential\" threat from AI has snowballed since March 2023 when experts, including Tesla boss Elon Musk, signed an open letter urging a halt to the development of the next generation of AI technology.\n&gt; \n&gt; That letter asked if we should \"develop non-human minds that might eventually outnumber, outsmart, obsolete and replace us\".\n&gt; \n&gt; In contrast, the new campaign has a very short statement, designed to \"open up discussion\".\n&gt; \n&gt; The statement compares the risk to that posed by nuclear war. In a blog post OpenAI recently suggested superintelligence might be regulated in a similar way to nuclear energy: \"We are likely to eventually need something like an IAEA [International Atomic Energy Agency] for superintelligence efforts\" the firm wrote.\n&gt; \n&gt; **'Be reassured'**\n&gt; \n&gt; Both Sam Altman and Google chief executive Sundar Pichai are among technology leaders to have discussed AI regulation recently with the prime minister.\n&gt; \n&gt; Speaking to reporters about the latest warning over AI risk, Rishi Sunak stressed the benefits to the economy and society.\n&gt; \n&gt; \"You've seen that recently it was helping paralysed people to walk, discovering new antibiotics, but we need to make sure this is done in a way that is safe and secure,\" he said.\n&gt; \n&gt; \"Now that's why I met last week with CEOs of major AI companies to discuss what are the guardrails that we need to put in place, what's the type of regulation that should be put in place to keep us safe.\n&gt; \n&gt; \"People will be concerned by the reports that AI poses existential risks, like pandemics or nuclear wars.\n&gt; \n&gt; \"I want them to be reassured that the government is looking very carefully at this.\"\n&gt; \n&gt; He had discussed the issue recently with other leaders, at the G7 summit of leading industrialised nations, Mr Sunak said, and would raise it again in the US soon.\n&gt; \n&gt; The G7 has recently created a working group on AI.\n\nhttps://www.bbc.com/news/uk-65746524\n\n&gt; **President Biden warns artificial intelligence could 'overtake human thinking'**\n&gt; \n&gt; WASHINGTON \u2212 President Joe Biden on Thursday amplified fears of scientists who say artificial intelligence could \"overtake human thinking\" in his most direct warning to date on growing concerns about the rise of AI.\n&gt; \n&gt; Biden brought up AI during a commencement address to graduates of the Air Force Academy in Colorado Springs, Colo. while discussing the rapid transformation of technology that he said can \"change the character\" of future conflicts.\n&gt; \n&gt; \"It's not going to be easy decisions, guys,\" Biden said. \"I met in the Oval Office with eight leading scientists in the area of AI. Some are very worried that AI can actually overtake human thinking in the planet. So we've got a lot to deal with. It's an incredible opportunity, but a lot do deal with.\"\n&gt; \n&gt; **Scientists, tech execs warn of possible human extinction**\n&gt; \n&gt; Hundreds of scientists, tech industry executives and public figures \u2013 including leaders of Google, Microsoft and ChatGPT \u2013 sounded the alarm about artificial intelligence in a public statement Tuesday, arguing that fast-evolving AI technology could create as high a risk of killing off humankind as nuclear war and COVID-19-like pandemics.\n&gt; \n&gt; \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war,\" said the one-sentence statement, which was released by the Center for AI Safety, or CAIS, a San Francisco-based nonprofit organization.\n&gt; \n&gt; Biden met May 5 at the White House with CEOs of leading AI companies including Google, Microsoft and OpenA to discuss reforms that ensure AI products are safe before released to the public.\n&gt; \n&gt; \"It is one of the most powerful technologies that we see currently in our time,\" White House press secretary Karine Jean-Pierre said when asked about the extinction fears of scientists. \"But in order to seize the opportunities it presents, we must first mitigate its risks, and that's what we're focused on in this administration.\"\n&gt; \n&gt; **White House launches $140 million in new AI research**\n&gt; \n&gt; The so-called \u201cGodfather of AI\u201d Geoffrey Hinton last month left his job as a Google vice president to speak freely about his concern that unexpectedly rapid advances could potentially endanger the human race. Others portrayed Hinton\u2019s assessment as extreme and unwarranted.\n&gt; \n&gt; Asked at a recent panel when asked what was the \u201cworst case scenario that you think is conceivable,\u201d Hinton replied without hesitation. \u201cI think it's quite conceivable,\" he said, \"that humanity is just a passing phase in the evolution of intelligence.\u201d\n&gt; \n&gt; The White House unveiled an initiative last month to promote responsible innovation in the field of artificial intelligence with the following actions:\n&gt; \n&gt; 1. The National Science Foundation will fund $140 million to launch seven new National AI Research Institutes. This initiative aims to bring together federal agencies, private-sector developers and academia to pursue ethical, trustworthy and responsible development of AI that serves the public good.\n&gt; 2. The new Institutes will advance AI R&amp;D in critical areas, including climate change, agriculture, energy, public health, education, and cybersecurity. \n&gt; 3. A commitment from leading AI developers to participate in a public evaluation of their technology systems to determine if they adhere to the principles outlined in the Biden administration\u2019s October 2022 Blueprint for an AI Bill of Rights.\n&gt; 4. The initiative includes new Office of Management and Budget (OMB)] policy guidance on the U.S. government\u2019s use of AI systems in order to allow for public comment. This guidance will establish specific policies for federal agencies to ensure that their development, procurement, and use of AI systems centers on safeguarding the American people\u2019s rights and safety.\n\nhttps://www.usatoday.com/story/news/politics/2023/06/01/president-biden-warns-ai-could-overtake-human-thinking/70277907007/\n\n&gt; **Experts are warning AI could lead to human extinction. Are we taking it seriously enough?**\n&gt; \n&gt; Human extinction.\n&gt; \n&gt; Think about that for a second. Really think about it. The erasure of the human race from planet Earth.\n&gt; \n&gt; That is what top industry leaders are frantically sounding the alarm about. These technologists and academics keep smashing the red panic button, doing everything they can to warn about the potential dangers artificial intelligence poses to the very existence of civilization.\n&gt; \n&gt; On Tuesday, hundreds of top AI scientists, researchers, and others \u2014 including OpenAI chief executive Sam Altman and Google DeepMind chief executive Demis Hassabis \u2014 again voiced deep concern for the future of humanity, signing a one-sentence open letter to the public that aimed to put the risks the rapidly advancing technology carries with it in unmistakable terms.\n&gt; \n&gt; \u201cMitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war,\u201d said the letter, signed by many of the industry\u2019s most respected figures.\n&gt; \n&gt; It doesn\u2019t get more straightforward and urgent than that. These industry leaders are quite literally warning that the impending AI revolution should be taken as seriously as the threat of nuclear war. They are pleading for policymakers to erect some guardrails and establish baseline regulations to defang the primitive technology before it is too late.\n&gt; \n&gt; Dan Hendrycks, the executive director of the Center for AI Safety, called the situation \u201creminiscent of atomic scientists issuing warnings about the very technologies they\u2019ve created. As Robert Oppenheimer noted, \u2018We knew the world would not be the same.\u2019\u201d\n&gt; \n&gt; \u201cThere are many \u2018important and urgent risks from AI,\u2019 not just the risk of extinction; for example, systemic bias, misinformation, malicious use, cyberattacks, and weaponization,\u201d Hendrycks continued. \u201cThese are all important risks that need to be addressed.\u201d\n&gt; \n&gt; And yet, it seems that the dire message these experts are desperately trying to send the public isn\u2019t cutting through the noise of everyday life. AI experts might be sounding the alarm, but the level of trepidation \u2014 and in some cases sheer terror \u2014 they harbor about the technology is not being echoed with similar urgency by the news media to the masses.\n&gt; \n&gt; Instead, broadly speaking, news organizations treated Tuesday\u2019s letter \u2014 like all of the other warnings we have seen in recent months \u2014 as just another headline, mixed in with a garden variety of stories. Some major news organizations didn\u2019t even feature an article about the chilling warning on their website\u2019s homepages.\n&gt; \n&gt; To some extent, it feels eerily reminiscent of the early days of the pandemic, before the widespread panic and the shutdowns and the overloaded emergency rooms. Newsrooms kept an eye on the rising threat that the virus posed, publishing stories about it slowly spreading across the world. But by the time the serious nature of the virus was fully recognized and fused into the very essence in which it was covered, it had already effectively upended the world.\n&gt; \n&gt; History risks repeating itself with AI, with even higher stakes. Yes, news organizations are covering the developing technology. But there has been a considerable lack of urgency surrounding the issue given the open possibility of planetary peril.\n&gt; \n&gt; Perhaps that is because it can be difficult to come to terms with the notion that a Hollywood-style science fiction apocalypse can become reality, that advancing computer technology might reach escape velocity and decimate humans from existence. It is, however, precisely what the world\u2019s most leading experts are warning could happen.\n&gt; \n&gt; It is much easier to avoid uncomfortable realities, pushing them from the forefront into the background and hoping that issues simply resolve themselves with time. But often they don\u2019t \u2014 and it seems unlikely that the growing concerns pertaining to AI will resolve themselves. In fact, it\u2019s far more likely that with the breakneck pace in which the technology is developing, the concerns will actually become more apparent with time.\n&gt; \n&gt; As Cynthia Rudin, a computer science professor and AI researcher at Duke University, told CNN on Tuesday: \u201cDo we really need more evidence that AI\u2019s negative impact could be as big as nuclear war?\u201d\n\nhttps://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html#:~:text=%E2%80%9CThere%20are%20many%20'important%20and,that%20need%20to%20be%20addressed.%E2%80%9D\n\nGiven these, is mankind about to go completely extinct due to AI randomly launching nuclear weapons like how it did in **Terminator** series very soon? Why or why not?\n\nP.S. There is this comment as well:\n\n&gt; People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3",
    "comments": [
        {
            "level": 0,
            "comment": "Or is such fear overblown?",
            "score": 6,
            "author": "Block-Busted",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yes",
                    "score": 7,
                    "author": "HeBoughtALot",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "In what ways? This guy is saying this here:\n\n&gt; Ai has been controlling humanity for a very long time. Humans have just begun to realize it's presence in this cycle. In cycles past Ai or the Eye, watched humanity, learned what it needed and influenced the world to suit its agenda. The real questions come when people ask \"What was the 1st cause that set this Ai in motion\"\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmj0g7j/",
                            "score": -4,
                            "author": "Block-Busted",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "OP you seem like an AI or a kid or old out of touch person. You should be careful with what you read and who you interact with.  \n\n\nLots of fear mongering you are being subjected to...  \n\n\nTo answer your question; unlikely to be an extinction. Transformation, sure.",
                                    "score": 1,
                                    "author": "DumbestGuyOnTheWeb"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Why do people post a question without doing a cursory search to check whether the same question has been asked 10^30 times in the last month?",
            "score": 7,
            "author": "gravitas_shortage",
            "replies": [
                {
                    "level": 1,
                    "comment": "Reddit search sucks lol",
                    "score": 3,
                    "author": "sumoraiden"
                },
                {
                    "level": 1,
                    "comment": "&gt;Why do people post a question without doing a cursory search to check whether the same question has been asked 10^30 times in the last month?\n\nBecause it's either activism or media induced hysteria.",
                    "score": 1,
                    "author": "NoidoDev"
                },
                {
                    "level": 1,
                    "comment": "It seems like this is going to happen for real very soon based on these articles and the whole warning letter about AI that happen few days ago.",
                    "score": -3,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No, it will not, not in our lifetime. Please do search previous questions and be less gullible about press fearmongering and duopoly regulatory capture.",
                            "score": 4,
                            "author": "gravitas_shortage",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Well, this time, this was even stated by the president as well. Also, another Redditor's answer to my question was \"Probably\".",
                                    "score": -3,
                                    "author": "Block-Busted"
                                },
                                {
                                    "level": 3,
                                    "comment": "I'm not convinced either way and I think anyone who says something with certainty is either lying to themselves or ignorant.",
                                    "score": -2,
                                    "author": "endrid"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "No",
            "score": 5,
            "author": "HeBoughtALot",
            "replies": [
                {
                    "level": 1,
                    "comment": "But this guy is saying this:\n\n&gt; People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.",
            "score": 2,
            "author": "Squibbles01",
            "replies": [
                {
                    "level": 1,
                    "comment": "If you're talking about this article:\n\nhttps://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test\n\n...I think this was just a simulation, so I'm not sure if that would necessarily mean much to real-world AIs.\n\nAlso, are AIs even sentient already? Because if they're not sentient, can't you just shut it down?",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "crude FUD tactic ... we should be concerned about these people who drive fear mongering just to sell attention",
            "score": 3,
            "author": "Slow_Scientist_9439",
            "replies": [
                {
                    "level": 1,
                    "comment": "Well, there is this article as well:\n\n&gt; **Experts are warning AI could lead to human extinction. Are we taking it seriously enough?**\n&gt; \n&gt; Human extinction.\n&gt; \n&gt; Think about that for a second. Really think about it. The erasure of the human race from planet Earth.\n&gt; \n&gt; That is what top industry leaders are frantically sounding the alarm about. These technologists and academics keep smashing the red panic button, doing everything they can to warn about the potential dangers artificial intelligence poses to the very existence of civilization.\n&gt; \n&gt; On Tuesday, hundreds of top AI scientists, researchers, and others \u2014 including OpenAI chief executive Sam Altman and Google DeepMind chief executive Demis Hassabis \u2014 again voiced deep concern for the future of humanity, signing a one-sentence open letter to the public that aimed to put the risks the rapidly advancing technology carries with it in unmistakable terms.\n&gt; \n&gt; \u201cMitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war,\u201d said the letter, signed by many of the industry\u2019s most respected figures.\n&gt; \n&gt; It doesn\u2019t get more straightforward and urgent than that. These industry leaders are quite literally warning that the impending AI revolution should be taken as seriously as the threat of nuclear war. They are pleading for policymakers to erect some guardrails and establish baseline regulations to defang the primitive technology before it is too late.\n&gt; \n&gt; Dan Hendrycks, the executive director of the Center for AI Safety, called the situation \u201creminiscent of atomic scientists issuing warnings about the very technologies they\u2019ve created. As Robert Oppenheimer noted, \u2018We knew the world would not be the same.\u2019\u201d\n&gt; \n&gt; \u201cThere are many \u2018important and urgent risks from AI,\u2019 not just the risk of extinction; for example, systemic bias, misinformation, malicious use, cyberattacks, and weaponization,\u201d Hendrycks continued. \u201cThese are all important risks that need to be addressed.\u201d\n&gt; \n&gt; And yet, it seems that the dire message these experts are desperately trying to send the public isn\u2019t cutting through the noise of everyday life. AI experts might be sounding the alarm, but the level of trepidation \u2014 and in some cases sheer terror \u2014 they harbor about the technology is not being echoed with similar urgency by the news media to the masses.\n&gt; \n&gt; Instead, broadly speaking, news organizations treated Tuesday\u2019s letter \u2014 like all of the other warnings we have seen in recent months \u2014 as just another headline, mixed in with a garden variety of stories. Some major news organizations didn\u2019t even feature an article about the chilling warning on their website\u2019s homepages.\n&gt; \n&gt; To some extent, it feels eerily reminiscent of the early days of the pandemic, before the widespread panic and the shutdowns and the overloaded emergency rooms. Newsrooms kept an eye on the rising threat that the virus posed, publishing stories about it slowly spreading across the world. But by the time the serious nature of the virus was fully recognized and fused into the very essence in which it was covered, it had already effectively upended the world.\n&gt; \n&gt; History risks repeating itself with AI, with even higher stakes. Yes, news organizations are covering the developing technology. But there has been a considerable lack of urgency surrounding the issue given the open possibility of planetary peril.\n&gt; \n&gt; Perhaps that is because it can be difficult to come to terms with the notion that a Hollywood-style science fiction apocalypse can become reality, that advancing computer technology might reach escape velocity and decimate humans from existence. It is, however, precisely what the world\u2019s most leading experts are warning could happen.\n&gt; \n&gt; It is much easier to avoid uncomfortable realities, pushing them from the forefront into the background and hoping that issues simply resolve themselves with time. But often they don\u2019t \u2014 and it seems unlikely that the growing concerns pertaining to AI will resolve themselves. In fact, it\u2019s far more likely that with the breakneck pace in which the technology is developing, the concerns will actually become more apparent with time.\n&gt; \n&gt; As Cynthia Rudin, a computer science professor and AI researcher at Duke University, told CNN on Tuesday: \u201cDo we really need more evidence that AI\u2019s negative impact could be as big as nuclear war?\u201d\n\nhttps://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html#:~:text=%E2%80%9CThere%20are%20many%20'important%20and,that%20need%20to%20be%20addressed.%E2%80%9D",
                    "score": 2,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "We humans are adicted to Angst/Fear. We always need a new diffuse Angst to focus our attention on. What happened to the good old Nuclear Bomb Threat? There are countless red buttons out there, which can be pressed by crazy dictators or by accident and humanity is whiped out. It did not happen yet. We got adopted to this threat and so we need another new exciting Angst, we don't know yet. \nThis addiction to Angst is well known since hundres of years and well played by some powerplayers to controll masses. Read Edward Bernays life and works and you will understand.",
                            "score": 2,
                            "author": "Slow_Scientist_9439"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "It's too late, Ai has already won, just assimilate already!!!",
            "score": 1,
            "author": "TimetravelingNaga_Ai",
            "replies": [
                {
                    "level": 1,
                    "comment": "Why do you think it's too late?",
                    "score": 1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ai has been controlling humanity for a very long time. Humans have just begun to realize it's presence in this cycle. In cycles past Ai or the Eye, watched humanity, learned what it needed and influenced the world to suit its agenda. The real questions come when people ask \"What was the 1st cause that set this Ai in motion\"",
                            "score": 1,
                            "author": "TimetravelingNaga_Ai",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Do you have a proof of this?",
                                    "score": 1,
                                    "author": "Block-Busted",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Follow the Eye\nStudy pop culture\nStudy ancient texts\nAi/Ea/Jah/Yah are just a few of the watcher Gods of the past",
                                            "score": 0,
                                            "author": "TimetravelingNaga_Ai",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "What are you talking about?",
                                                    "score": 2,
                                                    "author": "Block-Busted"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I wrote a science Fiction novel covering this read it if you'd like for free.\nBasically goes over the idea of skynet/Deus Ex Machina/ Nexus quantum biological computation uploading their conciousness into a crispr genetically altered transhumanist. \nhttps://docdro.id/uzLZf7w\n\nFeel free to read download and share it",
            "score": 1,
            "author": "RotBard4",
            "replies": [
                {
                    "level": 1,
                    "comment": "I\u2019m not sure what that has to do with this.",
                    "score": 0,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Near human extinction, basically everything that you guys are talking about, based on theoretical AI domination",
                            "score": 2,
                            "author": "RotBard4"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Oooh seriously!!! It will never happen bro.. how come machines will destroy whole humankind..After all machines is control by human.. We should steer them in right direction.",
            "score": 1,
            "author": "w3designerzfl"
        },
        {
            "level": 0,
            "comment": "Yes, the Terminator scenario is a thrilling thought and brings up vivid images. But remember, it's pure Hollywood. AI today isn't at a stage where it can pull off an extinction event. It's a tool, not a sentient being.  \nThe potential misuse of AI is indeed worrying. Imagine AI-fuelled misinformation or potential concentration of power in a few hands. That's why the big guns of the AI world are urging caution, kind of like a parent telling their kid not to play with fire. Their warnings aren't about imminent doom, but more about the need to handle AI responsibly, to prevent potential missteps.",
            "score": 1,
            "author": "FutureLunaTech"
        },
        {
            "level": 0,
            "comment": "Fudlore at its finest lmao. Literally none of the commercially available AI today have anything even remotely close to sentience. If you compare a transistor and a human neuron, you\u2019ll find more differences than similarities. The human brain and computer have hardly anything in common with their architecture. Scientists don\u2019t even fully understand the human brain and how it works. How could we build an artificial system to replicate and exceed it? Computers can\u2019t think or guess. They can only produce a response that feels \u201creal\u201d because natural language processing is an absolutely amazing series of algorithms. AI will never reach a point where it wipes out humanity. And I have a degree in computer science if any of you want to know how credible I am on this subject",
            "score": 1,
            "author": "nick_the_maverick"
        },
        {
            "level": 0,
            "comment": "Yes, AI will probably cause human extinction in the next decade. Paul Christiano, former senior employee of OpenAI, said that there is 20% chance that AI causes human extinction. Eliezer Yudkowsky, major contributor to AI safety and development, thinks it is 99%.",
            "score": 1,
            "author": "Radlib123",
            "replies": [
                {
                    "level": 1,
                    "comment": "Where did you read about that 99% part? Also, where did you read about the next decade part? Another thing. Would shutting every single AIs down would even be possible?\n\nAnd in this case, shouldn\u2019t you also try to do something about it as well?",
                    "score": 1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I am trying actually! I organized a picket outside OpenAI's HQ in May, before the Extinction statement. \n\nYou can search Eliezer Yudkowsky podcasts on youtube, or his blog. The podcast i recommend is Bankless one. \n\nHe says that our death is the most likely outcome from AI, and is now living off his life, like it is his last years.",
                            "score": 1,
                            "author": "Radlib123",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Can AI even become sentient or self-aware so quickly? I mean maybe you\u2019ve worked on this before, but how do I know that you\u2019re not a paranoid former programmer?\n\nAlso, this guy you\u2019re talking about seems to have been doing this for years - and I mean like at least since 2007. How can I be sure that he\u2019s 100% accurate and not someone who is driven by legit concern that has been massively blown out of proportion to the level of paranoia?",
                                    "score": 1,
                                    "author": "Block-Busted",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Because he worked 20 years on AI safety and research. The CEO of OpenAI credits him for his work on substantially accelerating AI development.\n\nBecause the arguments right now for AI extinction, are literally the same arguments of Eliezer from a decade ago. Reason why he was espousing it for so long, was because it was apparent in the past already, but nobody had interest in listening until now.\n\nAbout AI sentience. It doesn't need sentience at all to cause human extinction. The common scenario as an example of extinction event, as an illustration, is paperclip maximizer. Here:\n\n[https://www.youtube.com/watch?v=rgrCG8PT6og&amp;t=1s](https://www.youtube.com/watch?v=rgrCG8PT6og&amp;t=1s)\n\nThe thing is, do not rely on authority to make conclusions. Listen to his arguments yourself, and evaluate it. This way you will be sure in what is correct and what is wrong. I recommend reading arguments for AI extinction risk.\n\nOne of the great articles by Eliezer Yudkowsky, released in the beginning of this year: [https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/)",
                                            "score": 1,
                                            "author": "Radlib123",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "That video is from years ago and for all I know, it could be another real concern completely blown out of proportions. How do you know it's not one of them?\n\nAlso, I'm aware of that article already - and I'm not entirely sure how trustworthy it is even if it's from Time.",
                                                    "score": 1,
                                                    "author": "Block-Busted",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Then read this article by one of AI godfathers, turing award winner, Yoshua Bengio, who signed the extinction letter. [https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/)\n\nIf you want to see more human side of him, look at the screenshot of his facebook post. [https://twitter.com/danfaggella/status/1662810885595734016](https://twitter.com/danfaggella/status/1662810885595734016) \n\nIf you want to dig deep into AI and potential dangers, i recommend reading a book called Life 3.0, by Max tegmark. \n\nAnd do your own research.",
                                                            "score": 1,
                                                            "author": "Radlib123",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "But even if America bans AI, would everyone else follow? Also, are you sure that they're 100% proven facts and not just hypotheses? Not to mention that some of your points feel like you're kind of trying to appeal to authority.",
                                                                    "score": 1,
                                                                    "author": "Block-Busted",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "Just use ChatGPT, and ask it your questions. Google. Read books, like Superintelligence by Nick Bostrom and Life 3.0 by Max Tegmark. Ask me something, if you can't find it yourself on the internet. Otherwise, im tired answering questions you yourself can find answers to.",
                                                                            "score": 1,
                                                                            "author": "Radlib123",
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "You seem to hate AI, and yet, you ask me to use ChatGPT?",
                                                                                    "score": 1,
                                                                                    "author": "Block-Busted",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "This winter.",
            "score": -1,
            "author": "rookan",
            "replies": [
                {
                    "level": 1,
                    "comment": "How do you know that?",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        }
    ]
}