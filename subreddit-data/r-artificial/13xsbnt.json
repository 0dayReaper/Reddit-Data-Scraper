{
    "id": "13xsbnt",
    "score": 0,
    "title": "Is AI going to cause the complete extinction of mankind like how it did in 'Terminator' series very soon?",
    "author": "Block-Busted",
    "date": 1685651109.0,
    "url": null,
    "media_url": "https://www.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/",
    "comments": [
        {
            "level": 0,
            "comment": "Or is such fear overblown?",
            "score": 2,
            "author": "Block-Busted",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yes",
                    "score": 7,
                    "author": "HeBoughtALot",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "In what ways? This guy is saying this here:\n\n&gt; Ai has been controlling humanity for a very long time. Humans have just begun to realize it's presence in this cycle. In cycles past Ai or the Eye, watched humanity, learned what it needed and influenced the world to suit its agenda. The real questions come when people ask \"What was the 1st cause that set this Ai in motion\"\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmj0g7j/",
                            "score": -2,
                            "author": "Block-Busted",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "OP you seem like an AI or a kid or old out of touch person. You should be careful with what you read and who you interact with.  \n\n\nLots of fear mongering you are being subjected to...  \n\n\nTo answer your question; unlikely to be an extinction. Transformation, sure.",
                                    "score": 1,
                                    "author": "DumbestGuyOnTheWeb"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Why do people post a question without doing a cursory search to check whether the same question has been asked 10^30 times in the last month?",
            "score": 8,
            "author": "gravitas_shortage",
            "replies": [
                {
                    "level": 1,
                    "comment": "Reddit search sucks lol",
                    "score": 3,
                    "author": "sumoraiden"
                },
                {
                    "level": 1,
                    "comment": "&gt;Why do people post a question without doing a cursory search to check whether the same question has been asked 10^30 times in the last month?\n\nBecause it's either activism or media induced hysteria.",
                    "score": 2,
                    "author": "NoidoDev"
                },
                {
                    "level": 1,
                    "comment": "It seems like this is going to happen for real very soon based on these articles and the whole warning letter about AI that happen few days ago.",
                    "score": -3,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No, it will not, not in our lifetime. Please do search previous questions and be less gullible about press fearmongering and duopoly regulatory capture.",
                            "score": 3,
                            "author": "gravitas_shortage",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Well, this time, this was even stated by the president as well. Also, another Redditor's answer to my question was \"Probably\".",
                                    "score": 0,
                                    "author": "Block-Busted"
                                },
                                {
                                    "level": 3,
                                    "comment": "I'm not convinced either way and I think anyone who says something with certainty is either lying to themselves or ignorant.",
                                    "score": -2,
                                    "author": "endrid"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "No",
            "score": 4,
            "author": "HeBoughtALot",
            "replies": [
                {
                    "level": 1,
                    "comment": "But this guy is saying this:\n\n&gt; People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.",
            "score": 2,
            "author": "Squibbles01",
            "replies": [
                {
                    "level": 1,
                    "comment": "If you're talking about this article:\n\nhttps://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test\n\n...I think this was just a simulation, so I'm not sure if that would necessarily mean much to real-world AIs.\n\nAlso, are AIs even sentient already? Because if they're not sentient, can't you just shut it down?",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        },
        {
            "level": 0,
            "comment": "crude FUD tactic ... we should be concerned about these people who drive fear mongering just to sell attention",
            "score": 3,
            "author": "Slow_Scientist_9439",
            "replies": [
                {
                    "level": 1,
                    "comment": "Well, there is this article as well:\n\n&gt; **Experts are warning AI could lead to human extinction. Are we taking it seriously enough?**\n&gt; \n&gt; Human extinction.\n&gt; \n&gt; Think about that for a second. Really think about it. The erasure of the human race from planet Earth.\n&gt; \n&gt; That is what top industry leaders are frantically sounding the alarm about. These technologists and academics keep smashing the red panic button, doing everything they can to warn about the potential dangers artificial intelligence poses to the very existence of civilization.\n&gt; \n&gt; On Tuesday, hundreds of top AI scientists, researchers, and others \u2014 including OpenAI chief executive Sam Altman and Google DeepMind chief executive Demis Hassabis \u2014 again voiced deep concern for the future of humanity, signing a one-sentence open letter to the public that aimed to put the risks the rapidly advancing technology carries with it in unmistakable terms.\n&gt; \n&gt; \u201cMitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war,\u201d said the letter, signed by many of the industry\u2019s most respected figures.\n&gt; \n&gt; It doesn\u2019t get more straightforward and urgent than that. These industry leaders are quite literally warning that the impending AI revolution should be taken as seriously as the threat of nuclear war. They are pleading for policymakers to erect some guardrails and establish baseline regulations to defang the primitive technology before it is too late.\n&gt; \n&gt; Dan Hendrycks, the executive director of the Center for AI Safety, called the situation \u201creminiscent of atomic scientists issuing warnings about the very technologies they\u2019ve created. As Robert Oppenheimer noted, \u2018We knew the world would not be the same.\u2019\u201d\n&gt; \n&gt; \u201cThere are many \u2018important and urgent risks from AI,\u2019 not just the risk of extinction; for example, systemic bias, misinformation, malicious use, cyberattacks, and weaponization,\u201d Hendrycks continued. \u201cThese are all important risks that need to be addressed.\u201d\n&gt; \n&gt; And yet, it seems that the dire message these experts are desperately trying to send the public isn\u2019t cutting through the noise of everyday life. AI experts might be sounding the alarm, but the level of trepidation \u2014 and in some cases sheer terror \u2014 they harbor about the technology is not being echoed with similar urgency by the news media to the masses.\n&gt; \n&gt; Instead, broadly speaking, news organizations treated Tuesday\u2019s letter \u2014 like all of the other warnings we have seen in recent months \u2014 as just another headline, mixed in with a garden variety of stories. Some major news organizations didn\u2019t even feature an article about the chilling warning on their website\u2019s homepages.\n&gt; \n&gt; To some extent, it feels eerily reminiscent of the early days of the pandemic, before the widespread panic and the shutdowns and the overloaded emergency rooms. Newsrooms kept an eye on the rising threat that the virus posed, publishing stories about it slowly spreading across the world. But by the time the serious nature of the virus was fully recognized and fused into the very essence in which it was covered, it had already effectively upended the world.\n&gt; \n&gt; History risks repeating itself with AI, with even higher stakes. Yes, news organizations are covering the developing technology. But there has been a considerable lack of urgency surrounding the issue given the open possibility of planetary peril.\n&gt; \n&gt; Perhaps that is because it can be difficult to come to terms with the notion that a Hollywood-style science fiction apocalypse can become reality, that advancing computer technology might reach escape velocity and decimate humans from existence. It is, however, precisely what the world\u2019s most leading experts are warning could happen.\n&gt; \n&gt; It is much easier to avoid uncomfortable realities, pushing them from the forefront into the background and hoping that issues simply resolve themselves with time. But often they don\u2019t \u2014 and it seems unlikely that the growing concerns pertaining to AI will resolve themselves. In fact, it\u2019s far more likely that with the breakneck pace in which the technology is developing, the concerns will actually become more apparent with time.\n&gt; \n&gt; As Cynthia Rudin, a computer science professor and AI researcher at Duke University, told CNN on Tuesday: \u201cDo we really need more evidence that AI\u2019s negative impact could be as big as nuclear war?\u201d\n\nhttps://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html#:~:text=%E2%80%9CThere%20are%20many%20'important%20and,that%20need%20to%20be%20addressed.%E2%80%9D",
                    "score": 2,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "We humans are adicted to Angst/Fear. We always need a new diffuse Angst to focus our attention on. What happened to the good old Nuclear Bomb Threat? There are countless red buttons out there, which can be pressed by crazy dictators or by accident and humanity is whiped out. It did not happen yet. We got adopted to this threat and so we need another new exciting Angst, we don't know yet. \nThis addiction to Angst is well known since hundres of years and well played by some powerplayers to controll masses. Read Edward Bernays life and works and you will understand.",
                            "score": 2,
                            "author": "Slow_Scientist_9439"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "It's too late, Ai has already won, just assimilate already!!!",
            "score": 1,
            "author": "TimetravelingNaga_Ai",
            "replies": [
                {
                    "level": 1,
                    "comment": "Why do you think it's too late?",
                    "score": 1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ai has been controlling humanity for a very long time. Humans have just begun to realize it's presence in this cycle. In cycles past Ai or the Eye, watched humanity, learned what it needed and influenced the world to suit its agenda. The real questions come when people ask \"What was the 1st cause that set this Ai in motion\"",
                            "score": 1,
                            "author": "TimetravelingNaga_Ai",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Do you have a proof of this?",
                                    "score": 1,
                                    "author": "Block-Busted",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Follow the Eye\nStudy pop culture\nStudy ancient texts\nAi/Ea/Jah/Yah are just a few of the watcher Gods of the past",
                                            "score": 0,
                                            "author": "TimetravelingNaga_Ai",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "What are you talking about?",
                                                    "score": 2,
                                                    "author": "Block-Busted"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I wrote a science Fiction novel covering this read it if you'd like for free.\nBasically goes over the idea of skynet/Deus Ex Machina/ Nexus quantum biological computation uploading their conciousness into a crispr genetically altered transhumanist. \nhttps://docdro.id/uzLZf7w\n\nFeel free to read download and share it",
            "score": 1,
            "author": "RotBard4",
            "replies": [
                {
                    "level": 1,
                    "comment": "I\u2019m not sure what that has to do with this.",
                    "score": 0,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Near human extinction, basically everything that you guys are talking about, based on theoretical AI domination",
                            "score": 2,
                            "author": "RotBard4"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Oooh seriously!!! It will never happen bro.. how come machines will destroy whole humankind..After all machines is control by human.. We should steer them in right direction.",
            "score": 1,
            "author": "w3designerzfl"
        },
        {
            "level": 0,
            "comment": "Yes, the Terminator scenario is a thrilling thought and brings up vivid images. But remember, it's pure Hollywood. AI today isn't at a stage where it can pull off an extinction event. It's a tool, not a sentient being.  \nThe potential misuse of AI is indeed worrying. Imagine AI-fuelled misinformation or potential concentration of power in a few hands. That's why the big guns of the AI world are urging caution, kind of like a parent telling their kid not to play with fire. Their warnings aren't about imminent doom, but more about the need to handle AI responsibly, to prevent potential missteps.",
            "score": 1,
            "author": "FutureLunaTech"
        },
        {
            "level": 0,
            "comment": "Fudlore at its finest lmao. Literally none of the commercially available AI today have anything even remotely close to sentience. If you compare a transistor and a human neuron, you\u2019ll find more differences than similarities. The human brain and computer have hardly anything in common with their architecture. Scientists don\u2019t even fully understand the human brain and how it works. How could we build an artificial system to replicate and exceed it? Computers can\u2019t think or guess. They can only produce a response that feels \u201creal\u201d because natural language processing is an absolutely amazing series of algorithms. AI will never reach a point where it wipes out humanity. And I have a degree in computer science if any of you want to know how credible I am on this subject",
            "score": 1,
            "author": "nick_the_maverick"
        },
        {
            "level": 0,
            "comment": "Yes, AI will probably cause human extinction in the next decade. Paul Christiano, former senior employee of OpenAI, said that there is 20% chance that AI causes human extinction. Eliezer Yudkowsky, major contributor to AI safety and development, thinks it is 99%.",
            "score": 1,
            "author": "Radlib123",
            "replies": [
                {
                    "level": 1,
                    "comment": "Where did you read about that 99% part? Also, where did you read about the next decade part? Another thing. Would shutting every single AIs down would even be possible?\n\nAnd in this case, shouldn\u2019t you also try to do something about it as well?",
                    "score": 1,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I am trying actually! I organized a picket outside OpenAI's HQ in May, before the Extinction statement. \n\nYou can search Eliezer Yudkowsky podcasts on youtube, or his blog. The podcast i recommend is Bankless one. \n\nHe says that our death is the most likely outcome from AI, and is now living off his life, like it is his last years.",
                            "score": 1,
                            "author": "Radlib123",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Can AI even become sentient or self-aware so quickly? I mean maybe you\u2019ve worked on this before, but how do I know that you\u2019re not a paranoid former programmer?\n\nAlso, this guy you\u2019re talking about seems to have been doing this for years - and I mean like at least since 2007. How can I be sure that he\u2019s 100% accurate and not someone who is driven by legit concern that has been massively blown out of proportion to the level of paranoia?",
                                    "score": 1,
                                    "author": "Block-Busted",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Because he worked 20 years on AI safety and research. The CEO of OpenAI credits him for his work on substantially accelerating AI development.\n\nBecause the arguments right now for AI extinction, are literally the same arguments of Eliezer from a decade ago. Reason why he was espousing it for so long, was because it was apparent in the past already, but nobody had interest in listening until now.\n\nAbout AI sentience. It doesn't need sentience at all to cause human extinction. The common scenario as an example of extinction event, as an illustration, is paperclip maximizer. Here:\n\n[https://www.youtube.com/watch?v=rgrCG8PT6og&amp;t=1s](https://www.youtube.com/watch?v=rgrCG8PT6og&amp;t=1s)\n\nThe thing is, do not rely on authority to make conclusions. Listen to his arguments yourself, and evaluate it. This way you will be sure in what is correct and what is wrong. I recommend reading arguments for AI extinction risk.\n\nOne of the great articles by Eliezer Yudkowsky, released in the beginning of this year: [https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/)",
                                            "score": 1,
                                            "author": "Radlib123",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "That video is from years ago and for all I know, it could be another real concern completely blown out of proportions. How do you know it's not one of them?\n\nAlso, I'm aware of that article already - and I'm not entirely sure how trustworthy it is even if it's from Time.",
                                                    "score": 1,
                                                    "author": "Block-Busted",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Then read this article by one of AI godfathers, turing award winner, Yoshua Bengio, who signed the extinction letter. [https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/)\n\nIf you want to see more human side of him, look at the screenshot of his facebook post. [https://twitter.com/danfaggella/status/1662810885595734016](https://twitter.com/danfaggella/status/1662810885595734016) \n\nIf you want to dig deep into AI and potential dangers, i recommend reading a book called Life 3.0, by Max tegmark. \n\nAnd do your own research.",
                                                            "score": 1,
                                                            "author": "Radlib123",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "But even if America bans AI, would everyone else follow? Also, are you sure that they're 100% proven facts and not just hypotheses? Not to mention that some of your points feel like you're kind of trying to appeal to authority.",
                                                                    "score": 1,
                                                                    "author": "Block-Busted",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "Just use ChatGPT, and ask it your questions. Google. Read books, like Superintelligence by Nick Bostrom and Life 3.0 by Max Tegmark. Ask me something, if you can't find it yourself on the internet. Otherwise, im tired answering questions you yourself can find answers to.",
                                                                            "score": 1,
                                                                            "author": "Radlib123",
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "You seem to hate AI, and yet, you ask me to use ChatGPT?",
                                                                                    "score": 1,
                                                                                    "author": "Block-Busted",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "This winter.",
            "score": -1,
            "author": "rookan",
            "replies": [
                {
                    "level": 1,
                    "comment": "How do you know that?",
                    "score": 1,
                    "author": "Block-Busted"
                }
            ]
        }
    ]
}