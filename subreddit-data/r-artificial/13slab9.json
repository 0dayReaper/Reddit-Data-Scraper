{
    "id": "13slab9",
    "score": 14,
    "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models - Nvidia 2023 - LLM-powered (GPT-4) embodied lifelong learning agent in Minecraft that continuously explores the world!!!!",
    "author": "Singularian2501",
    "date": 1685127041.0,
    "url": "https://www.reddit.com/r/artificial/comments/13slab9",
    "media_urls": [],
    "other_urls": [
        "https://arxiv.org/abs/2305.16291](https://arxiv.org/abs/2305.16291)",
        "https://github.com/MineDojo/Voyager](https://github.com/MineDojo/Voyager)",
        "https://voyager.minedojo.org/](https://voyager.minedojo.org/)",
        "https://preview.redd.it/k3tasgu1j92b1.jpg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e6314292d36f9221d561221b1023f008b0aa3cdd",
        "https://preview.redd.it/4pev8ku1j92b1.jpg?width=1374&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c99a08c5f764eb70155a3330c3eca6a28b2d3305",
        "https://preview.redd.it/c6izmiu1j92b1.jpg?width=1366&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=252bb65e66a42ef38b3b69ff54ba4a8ceb7b2f5a",
        "https://preview.redd.it/ito1mku1j92b1.jpg?width=1202&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0ce4eda9291298202f0d4f8f109e10ee6d877b7b",
        "https://preview.redd.it/1qhlulu1j92b1.jpg?width=1006&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5c691343d3c18ae0e880d447f960eac5776bfa27",
        "https://preview.redd.it/9h4ikou1j92b1.jpg?width=988&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d3011f1c33fbce92c4cf3b7f68c8c0a7dd155f40"
    ],
    "postText": "Paper: [https://arxiv.org/abs/2305.16291](https://arxiv.org/abs/2305.16291)\n\nGithub: [https://github.com/MineDojo/Voyager](https://github.com/MineDojo/Voyager) \n\nBlog: [https://voyager.minedojo.org/](https://voyager.minedojo.org/) \n\nAbstract:\n\n&gt;We introduce Voyager, the first **LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.** Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with **GPT-4** via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager **shows strong in-context lifelong learning capability** and exhibits exceptional proficiency in playing Minecraft. **It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA.** Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize.\n\n**Conclusion:**\n\n&gt;In this work, we introduce VOYAGER, the first LLM-powered embodied **lifelong learning agent**, which leverages **GPT-4** to **explore the world continuously**, develop increasingly sophisticated skills, and make new discoveries consistently without human intervention. VOYAGER exhibits superior performance in discovering novel items, unlocking the Minecraft tech tree, traversing diverse terrains, and applying its learned skill library to unseen tasks in a newly instantiated world. **VOYAGER serves as a starting point to develop powerful generalist agents without tuning the model parameters.**\n\nhttps://preview.redd.it/k3tasgu1j92b1.jpg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e6314292d36f9221d561221b1023f008b0aa3cdd\n\nhttps://preview.redd.it/4pev8ku1j92b1.jpg?width=1374&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c99a08c5f764eb70155a3330c3eca6a28b2d3305\n\nhttps://preview.redd.it/c6izmiu1j92b1.jpg?width=1366&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=252bb65e66a42ef38b3b69ff54ba4a8ceb7b2f5a\n\nhttps://preview.redd.it/ito1mku1j92b1.jpg?width=1202&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0ce4eda9291298202f0d4f8f109e10ee6d877b7b\n\nhttps://preview.redd.it/1qhlulu1j92b1.jpg?width=1006&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5c691343d3c18ae0e880d447f960eac5776bfa27\n\nhttps://preview.redd.it/9h4ikou1j92b1.jpg?width=988&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d3011f1c33fbce92c4cf3b7f68c8c0a7dd155f40",
    "comments": [
        {
            "level": 0,
            "comment": "Awesome, any idea what other applications it's been tested on?",
            "score": 1,
            "author": "RhinoWesl"
        },
        {
            "level": 0,
            "comment": "Is this similar to Reflexion(https://paperswithcode.com/paper/reflexion-an-autonomous-agent-with-dynamic) or Parsel(https://paperswithcode.com/paper/parsel-a-unified-natural-language-framework)?\nCan these techniques be paired with StarCoder/StarChat(https://huggingface.co/HuggingFaceH4/starchat-beta), Falcon40B(https://huggingface.co/tiiuae/falcon-40b-instruct), Claude+ or Google PaLM2/Bard?",
            "score": 1,
            "author": "dannyp777"
        }
    ]
}