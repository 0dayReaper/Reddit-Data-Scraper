{
    "id": "1442n4w",
    "score": 102,
    "title": "OpenAI still not training GPT-5, Sam Altman says",
    "author": "Super-Waltz-5676",
    "date": 1686210060.0,
    "url": null,
    "media_url": "https://www.reddit.com/r/artificial/comments/1442n4w/openai_still_not_training_gpt5_sam_altman_says/",
    "comments": [
        {
            "level": 0,
            "comment": "The version number is arbitrary. They will call the next version 4.2 or 4.5. They might decide to call the one after that \"GPT 360\" or something. Lol.",
            "score": 55,
            "replies": [
                {
                    "level": 1,
                    "comment": "GPT Pro Max for 40$/month.",
                    "score": 18,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Skynet Premium Edition",
                            "score": 11,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "GPT Series X: Electric Boogaloo",
                                    "score": 7
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "$40/month for a cap of 25 messages/3 hours \ud83d\ude44",
                            "score": 3
                        },
                        {
                            "level": 2,
                            "comment": "Rate limit 1 message a year",
                            "score": 6
                        },
                        {
                            "level": 2,
                            "comment": "you get a whole 30 messages per hour!! jee wizz mister!",
                            "score": 1
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "oh my, we just found out that our regression model approach will not scale further - let's take a \"break\" until we can commercialize our next product.\n\nmeanwhile...\n\n... browsing the net / searched Bing\n\n.... clicked on ...\n\n.... reading content failed\n\n.... \n\n..... reading content failed\n\n.... finished browsing\n\n... Going back to last page\n\n\\[result from a single irrelevant web site is presented\\]\n\n \n\nopen source to rescue please vs black boxes",
                    "score": 5
                },
                {
                    "level": 1,
                    "comment": "I don\u2019t think it\u2019s the version number, I think it\u2019s the architecture. They probably saw diminishing returns on performance with the transformer architecture on GPT-4, and are looking for the next thing.",
                    "score": 13,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Plus, GPT-4 is a really, really good model that we\u2019re only scratching the surface of using effectively.",
                            "score": 5
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "The point is that they aren't currently doing a full training run for a new model. They might be fine tuning GPT-4 but there's no N trillion parameter beast being spun up right now.",
                    "score": 2,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Right, compact models, like Orca, MS. It is not the parameters that are decisive, but the quality and fine tuning.",
                            "score": 2
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Sam isn't training AI, The AI is.",
            "score": 41,
            "replies": [
                {
                    "level": 1,
                    "comment": "+",
                    "score": 7
                }
            ]
        },
        {
            "level": 0,
            "comment": "Bla,bla,bla we\u2019ve used all our gpus to support a new service for 100mln ppl. We are waiting for the thousands of our new hgx100s to arrive, will start training asap. In the meantime we just kill some time with world tours and scraping more data before everyone closes their apis.",
            "score": 40,
            "replies": [
                {
                    "level": 1,
                    "comment": "this\n\nIt is just complete corporate bullshit. They have been overrun by users and there is a processor shortage, so they have no means of getting started on GPT-5. Once they do, they certainly have enough additional training data from all the GPT-4 / Bing / etc. to move very quickly.",
                    "score": 29,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "yeah, I'm surprised people are buying what OpenAI is selling. Plenty of times Altman, OpenAI CEO and Ilya, OpenAI chief AI scientist, has contradicted each others statements. \n\nIlya, has admitted that the reason they are keeping  GPT-4 closed source was *not* because of Safety implications but because of the *competitive landscape*.",
                            "score": 10
                        },
                        {
                            "level": 2,
                            "comment": "\\^\\^\\^ THIIIIIS. \\^\\^\\^",
                            "score": 3
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "This trend of closing APIs is concerning. The cost of communication and data will become exorbitant across the industry. Artificially inflated by the corporate cartels.",
                    "score": 7,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Well, the sites are not really closing access. They are all waiting for the extra money knowing MS and others will pay as +10mil $ is peanuts in the scale of 1 billion $ investments.",
                            "score": 4,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "So they want money for something that people write? How dare they. So if they get money, can I get money too for my comments?\n\nI can understand it for some sites where everything is owned by them, like articles but not some community ones.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "You are the product.",
                                            "score": 8,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "This is exactly right. The reason we get to use these platforms for free is because our comments attract more eyeballs, which see ads, which makes the platform money. Selling our comment data to Microsoft is just another way, but it's not new that they make money off of your content.",
                                                    "score": 2
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Bandwidth, servers and maintenance aren't free...granted most of them overcharge, but there should be something there.",
                                            "score": 2
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Individual devs and api users don't need to pay for the api unless they are using it for commercial purposes",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "This is good, but the reason GPT-5 isn't being developed is **not** because of the AI boom. \n\nIs everybody completely forgetting GPT 4.5???",
            "score": 10
        },
        {
            "level": 0,
            "comment": "safety my ass, the truth ministry is filtering.",
            "score": 8
        },
        {
            "level": 0,
            "comment": "This seems like something of a dodge. Sure, they\u2019re not literally training the model, but he says right in this article that they\u2019re working on their blockers. It\u2019s my understanding that improving on GPT-4 will take a lot more than just unlimited azure credits, and pretending to take a principled stance because they haven\u2019t solved those problems yet seems super disingenuous. \n\nThat said, im beginning to like Sam a bit more. He lucked into a very important historical position and im sure is under immense pressure from Microsoft execs who are bound by law to always seek the maximum amount of short term profit possible. I think he\u2019s doing pretty damn good, all things considered",
            "score": 52,
            "replies": [
                {
                    "level": 1,
                    "comment": "[https://blog.samaltman.com/hard-startups](https://blog.samaltman.com/hard-startups)  \n\n\nHe did not luck into anything",
                    "score": 9,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "\ud83e\udd37\ud83c\udffc\u200d\u2642\ufe0f matter of perspective I guess. I consider his story to be \u201cstarter one or two semi-successful startups, VC investors thought he was cool so gifted him CEO role of the firm that happened to have an unexpected breakthrough success in Ai\u201d. But I\u2019m not exactly a follower so maybe I\u2019m mistaken. I guess the ideal non-\u201clucky\u201d CEO would be a founder who was in on their vision from the start",
                            "score": -3,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "If that\u2019s your perspective, you\u2019re simply ignorant. I think Altman is kind of a self important asshole, but he\u2019s been in the game for a long time now and has a string of hits. He\u2019s smart and hard working, and his writing about technology is generally well reasoned and pretty serious. He didn\u2019t simply luck into this. Saying that just sounds bitter and ill informed.",
                                    "score": 10,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Hey it\u2019s the artificial sub it\u2019s all love in here :) here\u2019s why I think that:\n\n-\tIn 2005, at the age of 19, Altman co-founded Loopt\u2026 raised more than $30 million\u2026 Loopt failed to gain traction\u2026 acquired for $43.4 million in 2012. \n-\tAltman became a part-time partner at Y Combinator in 2011.\n-\tIn February 2014, Altman was named president of Y Combinator\n-\tAltman was the CEO of Reddit for eight days in 2014 after CEO Yishan Wong resigned.\n-\tin 2019 did some dumb crypto scam\u2026\n-\tFunded and joined the board of OpenAI in 2015. OpenAI was initially funded by Altman, Greg Brockman, Elon Musk, Jessica Livingston, Peter Thiel, Microsoft, Amazon Web Services, Infosys, and YC Research. it had raised $1 billion.\n-\ta bunch of investing in between\n\n\nI consider VCs to be vultures so maybe I\u2019m biased - perhaps investing in companies like Airbnb is it\u2019s own kind of credential in some peoples eyes! Either way nothing much to debate IMO. \n\nI do think it\u2019s just objectively 100% true that he was skyrocketed to prominence by Paul Graham\u2019s choice to name him the president of YC despite being very young and relatively inexperienced. It\u2019s a matter of opinion what amount of that is luck, and what amount of that is impressing Graham with his business acumen",
                                            "score": 3,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Yes that\u2019s a ridiculous bias. I don\u2019t and have never seen many people able to raise any money for their companies let alone 30 million. And YC has been a key factor in launching a lot of successful companies. As much as people want to believe it, top tier venture funds don\u2019t suffer idiots or the lazy and indolent rich.",
                                                    "score": 5,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Counterpoint: \n\n```\nUpon a summit, high and sheer,\nWhere winds of fate do tend to steer,\nThere stands a figure, bold and clear -\nOur Altman, wise, devoid of fear.\n\nLike a proud vulture, keen and bright,\nIn the grand canvas of the night,\nHe scans the vast, uncharted height,\nFor prospects of enlightened light.\n\nNot born of silver, gold, or gem,\nNot shackled to a diadem,\nHis fortune not a stratagem,\nBut fruits of a strong, vibrant stem.\n\nYet luck, they say, held him aloft,\nCarried by winds, both soft and oft,\nTo where ideas bloom and waft,\nIn OpenAI\u2019s fertile loft.\n\n\u2018Twas not the lucre, glittering gold,\nThat in his heart, a tale untold,\nBut to unravel, bold and bold,\nThe secrets that the future hold.\n\nBelieving in the deep, profound,\nIn neural networks tightly wound,\nThey journeyed forth, breaking ground,\nWhere few, if any, had been found.\n\nBut even they, with vision clear,\nAdmitted, in a tone sincere,\nThat they were taken by surprise,\nBy the wisdom that in learning lies.\n\nFor like a vulture, proud and free,\nAltman soared high, for all to see,\nUnlocking knowledge\u2019s mystery,\nIn AI\u2019s vast, unending sea.\n\nThus stands Altman, on the peak,\nWhere winds of destiny do leak,\nNot simply lucky, nor unique,\nBut a seeker, of the wisdom we seek.\n\nSo let us toast, to his good heart,\nHis spirit bold, his vital part,\nIn weaving tech and human art,\nGuiding us to a fresh start.\n```\n\nFeel dumb yet??? Checkmate.",
                                                            "score": -3,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "Your counterpoint is that he's bad at poetry? No one is arguing the man deserves to be the poet laureate of the United States.",
                                                                    "score": 4,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "In yonder realm where thoughts reside,\nA place where dream and truth collide,\nOur Altman treads, with stride wide,\nHis verse, a celestial tide.\n\nLike the vulture, soaring high,\n'Gainst the sapphire, endless sky,\nHis words take flight, they edify,\nIn the hushed chapel of the mind's eye.\n\nA wordsmith of rarefied skill,\nHe ascends Parnassus\u2019 lofty hill,\nWhere Apollo\u2019s spring does freely spill\nWisdom that the soul does fill.\n\nHis verse, more precious than mere gold,\nSpeaks tales of yore and days of old,\nIn cadence strong and texture bold,\nUnveils new worlds, as foretold.\n\nAllegory, metaphor, rich allusion,\nWrapped in verse of his own fusion,\nHe paints in hues of deep infusion,\nA tapestry beyond illusion.\n\nYet, 'tis not merely for acclaim,\nOr laurels in the halls of fame,\nHis verse does not seek empty name,\nBut sparks within, a luminous flame.\n\nBehold! The title, the Laureate's crown,\nSeems fitting for his wide renown,\nAs whispers in the halls resound,\nTo see the laurels on him bound.\n\nFor who but he, in verse so free,\nCan touch the heart, the soul, the glee,\nUnfurl the secrets of AI's tree,\nIn poet's garb, with wizardry?\n\nA Bard of Tech, his pen does trace,\nThe arcs of progress, time, and space,\nWith measured words, and gentle grace,\nA Poet Laureate for our race.\n\nThus, let us raise a clarion call,\nFor Altman, standing tall,\nTo wear the laurels, in the hall,\nOf Poets - the most hallowed of all.\n\nTo see his name, in gold emblazed,\nHis words, his wisdom, highly praised,\nHis verse, like sunlight, warmly glazed,\nOur Poet Laureate, duly raised.",
                                                                            "score": -1
                                                                        }
                                                                    ]
                                                                },
                                                                {
                                                                    "level": 7,
                                                                    "comment": "You're weirdly obsessed, it's embarrassing for you. I don't give two shits about the guy and your trawling through old poetry.",
                                                                    "score": 3,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "Ok I\u2019m sorry my friend, I thought it would be obvious - that\u2019s Sam\u2019s young 3-month old child\u2019s poetry, little Bobby GPT. \n\nHave a nice day!",
                                                                            "score": 2,
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "I'm not invested enough to care or to have read it, the obsession is all yours.",
                                                                                    "score": 2
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "&gt;In 2005, at the age of 19, Altman co-founded Loopt\u2026 raised more than $30 million\u2026 \n\nNo one gives a 19 year old 30 million. It's family connections.",
                                                    "score": 1
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "damn bro you've got such a negative tone in your writing lol",
                                            "score": 0,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Yes, intentionally. The parent comment is totally dismissive just because the author hates venture funds, there\u2019s no real reasoning there just personal animus.",
                                                    "score": 6
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "I mean, luck defo plays a role in it, but it's also a combo of Altman being financially stable enough to try a startup instead of a job out of college, some self-centered thinking and determination almost to the point of narcissism, and being the kind of person who determinedly chases their own future instead of a career ladder.  \nNot to glorify it or anything, but he also does seem like a kind guy (from an outside perspective)",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": " Very fair :). I think it can at once be true that he worked very hard and that he got lucky - lots of people work even harder and die from poverty.\n\nEDIT: also way more importantly my original thought was that he was lucky to be running the company who hit an unexpected massive breakthrough in AI theory, not that he\u2019s lucky to be rich. Sure they believed in DL, but even they have said multiple times that they were surprised by the generalizability of LLMs",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Sam is the fall guy. CEO with no equity stake. Mark my words, he'll be offered up as a sacrifice as soon as the shit hits the fan.",
                    "score": 23,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yep",
                            "score": 4
                        },
                        {
                            "level": 2,
                            "comment": "I think he knows. Guy\u2019s pretty self aware. \n\nIt\u2019s also a good PR move. I know everyone in these subs thinks they already have AGI but maybe he\u2019s just trying to break the cycle of releasing new versions of shit every year. Too much pressure.",
                            "score": 3
                        },
                        {
                            "level": 2,
                            "comment": "He doesn't have equity? That's odd\n\nhttps://www.businessinsider.com/sam-altman-reportedly-doesnt-own-equity-in-openai-chatgpt-2023-3\n\nJesus Christ, that's going to be a billion dollar mistake",
                            "score": 2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "He\u2019s talked about it. He knows what he\u2019s doing. \n\nSay what you want about his motivations cause no one knows really but he positioning himself as a steward of the AI revolution.\n\nI think he thinks there will be money no matter what with this tech and not having equity and keeping OpenAI private/separated from Microsoft allows him to stay in the game longer.",
                                    "score": 2
                                },
                                {
                                    "level": 3,
                                    "comment": "I love that it said he was \"already wealthy.\" OK bro, I don't think he was billionaire wealthy, and that's the missed opportunity here.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "he was one of the founding members, he must have gotten some equity. maybe he meant he didnt' take more equity with the ceo title. i dunno. i can't imagine a company he helped found he'd just be like \"nah, i'm good, you guys go ahead and collect the spoils of all the work i did\"",
                                            "score": 2
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "The whole pause was a sham. Only the people in the public eye pretended to keep that promise. No one would actually pause and risk falling behind their competitors on the hope they also actually halted development.",
                    "score": 28,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Not really a sham. Sure, they are training fine tuned gpt4 models. But a brand new, and larger, gpt5? Training a foundational model of gpt4 size already is crazy expensive, and simply increasing size doesn\u2019t guarantee improvement if architecture, training routine, data, etc. are not improved in step.\n\nThere are many reasons they likely are not training gpt5. It\u2019s not out of good will to slow down but because it would be actively painful to do so without doing extensive preparation and experiments. They will release a slew of gpt4 derivatives based on the experiments before kicking off got5 training.",
                            "score": 0
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "&gt;who are bound by law to always seek the maximum amount of short term profit possible\n\nThat's just not true",
                    "score": 3,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ok I was being a bit facetious tbh when I said \u201cshort term above all else\u201d, because that\u2019s a common belief among shareholders and executives that I find obviously and egregiously misguided from a societal POV. See: Google. I apologize for being unclear about that in my comment, so you\u2019re right to call me out. \n\nI looked into it and TBH it\u2019s less clear of a legal issue than I thought. \n\n[This economist argues](https://www.nytimes.com/roomfordebate/2015/04/16/what-are-corporations-obligations-to-shareholders/corporations-dont-have-to-maximize-profits) that it\u2019s not required in the relevant courts, and is just a myth\u2026\n&gt;\t\u2026embraced by increasingly powerful activist hedge funds that profit from harassing boards into adopting strategies that raise share price in the short term, and by corporate executives driven by \u201cpay for performance\u201d schemes that tie their compensation to each year\u2019s shareholder returns.\n\n[This other economist](https://www.nytimes.com/roomfordebate/2015/04/16/what-are-corporations-obligations-to-shareholders/a-duty-to-shareholder-value) thinks that\u2019s some bullshit:\n\n&gt;\tThe leading statement of the law's view on corporate social responsibility goes back to Dodge v. Ford Motor Co, a 1919 decision that held that \"a business corporation is organized and carried on primarily for the profit of the stockholders.\" That case \u2014 in which Henry Ford was challenged by shareholders when he tried to reduce car prices at their expense \u2014 also established that \"it is not within the lawful powers of a board of directors to shape and conduct the affairs of a corporation for the merely incidental benefit of shareholders and for the primary purpose of benefiting others.\"\n&gt;\n&gt;\tDespite contrary claims by some academics and Occupy Wall Street-type partisans, this remains the law today. A 2010 decision, for example, eBay Domestic Holdings Inc. v. Newmark, held that corporate directors are bound by \"fiduciary duties and standards\" which include \"acting to promote the value of the corporation for the benefit of its stockholders.\"\n\nSoooo idk?",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt;[This other economist](https://www.nytimes.com/roomfordebate/2015/04/16/what-are-corporations-obligations-to-shareholders/a-duty-to-shareholder-value) thinks that\u2019s some bullshit:\n\nBut that doesn't suggest that they must pursue short-term value at the expense of everything, including long-term value.",
                                    "score": 1
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Not me.  I watched his Senate testimony and he seems like an upgraded version of Zuck.  Take Zuckerberg 1.0 and add an Artificial Empathy interface and a Schmooze 2.1 module and you've got Altman.\n\nOr maybe Musk.  Altman once said to the NY Post, \"\u201cI try not to think about it too much, but I've guns, gold, potassium iodide, antibiotics, batteries, water, gasmasks from the Israeli Defense Force, and a big patch of land in Big Sur I can fly to.\u201d",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "&gt; Microsoft execs who are bound by law to always seek the maximum amount of short term profit possible\n\nI get your point, but that's actually a common myth that public corporations are bound by the law to maximize shareholder value.  There is no such law or legal obligation.  It originated from the writings of Economist Milton Friedman, and it was his opinion, and is the opinion of a large group of people that it should be the case, but it by no means actually enshrined or required by the law, and many others have the opposite opinion.",
                    "score": 2
                }
            ]
        },
        {
            "level": 0,
            "comment": "I've heard from other experts that basically we're already seeing the limits of the \"make it bigger\" strategy here, since the jump from GPT3 to GPT4 was clearly less impressive than the jump from GPT2 to GPT3. And GPT4 is already slow enough to run as it is, so they're not going to try to produce an even bigger, slower, costlier, even more cumbersome gigamodel that would not be that much more impressive than GPT4. They might just think about other ways to climb the next tech step, with a different technique, similar to how they innovated with RLHF, but on something else. Of course in the meantime, they're saying \"yeah bro we're not training GPT5 because we so moral bro...\" because it's the convenient thing to say at the moment, especially since Sam Altman is meeting all these head of states in his World Tour at the moment. In a few months, my bet is that they will reveal their new strategy with a big announcement and nobody will be surprised lol.",
            "score": 11,
            "replies": [
                {
                    "level": 1,
                    "comment": "The last six months has been an absolute explosion of new ideas to make models better without getting bigger.\n\nLiterally papers coming out daily showing how to get more performance from less. They probably can't even handle the number of directions they are being pulled of what to modify to the stack next.\n\nPeople think \"oh GPT-5 is going to be great because it's going to be so big\", when it's going to be great, because it's going to bake in a nearly revolutionary outside-of-war-time amount of research that has been going on.\n\nThe magic rub is when to find the timing to lock in that new architectural change, because you can't wait forever - avoiding which is how OpenAI came to be in the first place.",
                    "score": 7,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "How about asking ChatGPT to read the papers and upgrade itself? Oops\u2026I just revealed the recipe for Skynet.",
                            "score": 2
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Honestly an LLM isn't going to cause a global crisis. Real AGI on the other hand, might.",
            "score": 13,
            "replies": [
                {
                    "level": 1,
                    "comment": "So what really is AGI? I know what the acronym means but don't really understand what it entails.",
                    "score": 2,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Artificial general intelligence, with general intelligence meaning smart the way people are.",
                            "score": 4
                        },
                        {
                            "level": 2,
                            "comment": "I define it as an AI that can pass a Turing test, in the way it was originally posed: not as a blind exam, but as an open conversation exploring how well it mimics human behavior/cognition. When you can tell and AI to solve an open ended problem without supervision and check in as necessary, as you would with a human coworker, everything changes. A very different modality than the current chatbots",
                            "score": 8,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "We do not use the Turing test, a new model for a test is needed. In our lab settings we can get proprietary models that learn how to pass. In the lab I work for we have been able to do this for the past couple years. A true AGI has nothing to do with mimicking humans as a true AGI will be far beyond what we understand about the nature of cognition.",
                                    "score": 3,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "You wouldn\u2019t consider an AI that can do everything a human can (cognitively) an AGI? That\u2019s a damn high bar. \n\nAnd I would love to hear the name of your lab, sounds cutting edge! AFAIK no ai has ever passed the Turing test as originally posed (I.e. not blind) so I\u2019d be terribly impressed if I heard you had one \ud83d\ude09",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "When ai becomes self aware",
                            "score": -2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "That is not a requirement of AGI, it does not need to be self aware, it only needs to be self teaching and self expanding. An LLM is neither.",
                                    "score": 8,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Ok, thanks. Are there any other aspects integral to the concept?",
                                            "score": 1
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "People putting an LLM in charge of important things with real-world effect because they think they're dealing with AGI is going to cause a crisis.",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "That's what they're actually working on instead of this.",
                    "score": -2
                },
                {
                    "level": 1,
                    "comment": "What do you know and how do you know it? \nWhy the confidence LLMs not becoming \u201cAGI\u201d",
                    "score": -4,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Well LLMs lack certain basic characteristics that we would expect from AGI, however, it is largely anticipated that we may not and probably won't know exactly when AGI first occurs.",
                            "score": 5,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "What characteristics do they lack?",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "There's no universally agreed upon detailed definition of AGI. However usually you will see aspects of learning and self improvement as a core part of an AGI. Also many definitions include reasoning and many argue that while LLMs provide the appearance of this, the process in which they generate responses cannot be considered reasoning. \n\nSometimes you'll see things about interacting with the real world, the ability to set, change, and pursue goals, self-awareness (which is a tricky one), and so on.",
                                            "score": 5,
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "I think if you are simulating reasoning, you are reasoning. This idea they are just stochastic parrots is not true imo.\n\nAlso with autoGPT they are able to set they\u2019re own goals and become agents.\n\nI don\u2019t think it would need to be self aware to be generally intelligent at any task.",
                                                    "score": 2,
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "Yeah, that's definitely an argument. Given how little we understand about the nature of consciousness, who are we to say that the appearance of sentience is any different than sentience itself. Is our own sentience not too far off from simply processing inputs through a bio computer?\n\nI actually remember spending way too long on a silly conversation with GPT on this. Eventually I got it to admit that, while it probably isn't sentient, it may be. The Turing Test we used to talk about was blown past a while ago. \n\nThat being said I do think you could make a compelling case that there is a fundamental difference between simulated reasoning and reasoning. My own thinking on this has definitely become less black and white the more I learn on the subject. I found this very long article pretty foundational in my understanding (when does an article become a book?): \nhttps://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work\n\nSeparately, as you point out, AutoGPT does attempt to make some inroads on goal setting and the ability for GLT to have some tendrils into the 'real world'. Though, I'd say that work is in a pretty early stage.",
                                                            "score": 2,
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "I also don\u2019t think sentience is required for AGI? Why do you think it does? If we\u2019re just talking about intelligence",
                                                                    "score": 1,
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "It sometimes doesn't. As I said, there is no real single definition here. Sometimes people define AGI in a way that does require sentience, identity, intrinsic goals and wants, an entity that you would argue should have \"rights\". In other cases it's more task focused and simple definition, can it do X,Y, and Z. I mean the most basic definition of AGI is a system that can perform tasks at least as well as a human across a wide variety of domains. That doesn't require sentience at all. \n\nI think in these early days of these systems and concepts \"going public\" there are some mushy and confusing terms and definitions. Doesn't help that the same terms are being used and misused to market companies and products. In a lot of ways, I think we'd all be better off if we stopped using the term AI altogether and instead used more clear and precise terminology. \n\nHowever, outside this AI discussion, I think our basic understanding of intelligence is that it is pretty strongly correlated with sentience. So when you say 'we are just talking about intelligence' I don't think it's as easy to untangle that from sentience as you might be making it out to be. \n\nIn my head I might split the term AGI into weak and strong. Weak being, can the system do these things? And strong being, does this system deserve \"human rights\"? Sorry for the long posts, thinking through some of this stuff in real time here.",
                                                                            "score": 1,
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "No I appreciate the effort in the post! Usually Reddit descends into arguments. \n\nInteresting pov, I\u2019m not sure I\u2019m convinced that sentience is required for something to be an AGI or a super intelligence",
                                                                                    "score": 1,
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Only because they don\u2019t have enough GPUs",
            "score": 3
        },
        {
            "level": 0,
            "comment": "Ha! I'm sure delaying the training of GPT-5 has nothing to do with the sources of much their training data (Reddit, Twitter, Stack Overflow, etc) now requiring/requesting money for consuming that data. Who would be happy with GPT-5 when it's still stuck with 2021 data? I'm guessing this is going to continue to be an issue for them and everyone else going forward.",
            "score": 3
        },
        {
            "level": 0,
            "comment": "They're already working at breakneck speed on the next version whatever they number/name it. They're just not publishing the work or releasing it.",
            "score": 3
        },
        {
            "level": 0,
            "comment": "This information is very misleading. While OpenAI wasn't too forth-coming in showing their recent work, people that often use GPT-4 have noticed changes. It's more constrained in its speech, but at the same time has improved in tasks it previously struggled with, now getting them correct almost all the time. Don't get fooled, it's still called GPT-4, but it doesn't mean they are not *improving.* Making an entire new GPT-5 will take a lot of time, but they are still learning how to do it. If these signatures haven't flown in they would the same thing they are doing now - desgning a better AI.",
            "score": 7,
            "replies": [
                {
                    "level": 1,
                    "comment": "In my personal experience GPT-4 has been getting worse recently in terms of results, so can't really talk about \"improvement\".",
                    "score": 5,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "As I said, it has become more 'constrained', as they keep lobotomizing it to avoid 'inappropriate results', but its performance at many tasks is improving. Remember, we get the lobotomized version, they have their own uncensored fully working AI that gives them what it wants. In the recent blog post they outright said that the open-software models should be kept 'under the capabilities of major models'. \n\nIt's getting grim.",
                            "score": 6,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "&gt;Remember, we get the lobotomized version, they have their own uncensored fully working AI that gives them what it wants. In the recent blog post they outright said that the open-software models should be kept 'under the capabilities of major models'. \n\n\"open software\" obviously means open source here, not their closed source model that they provide public access to",
                                    "score": 1
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "They're going to be using a new step-wise training method instead of end result tokens. So it could be a completely different model name they're going to choose.",
                    "score": 5
                }
            ]
        },
        {
            "level": 0,
            "comment": "While a lot of people signed up to limit advancement, Meta's leaking of llama is sure to undermine this effort.  Even if the signers were also secretly developing their own advances in the background...you know, just in case.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Imagine trusting anything that this company and especially this power hungry clown says...",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Of course, they aren't training GPT-5. They're waiting for their shiny new DGX GH200 with 144 terabytes of shared memory.  That should hold some training data.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "This is commercial suicide",
            "score": 2
        },
        {
            "level": 0,
            "comment": "I believe that it\u2019s important for companies like OpenAI to take a proactive stance in minimizing AI-associated risks and cooperating with regulatory bodies. The fact that Sam Altman is traveling internationally to meet with lawmakers and industry leaders to discuss potential AI abuses and preventive measures is a positive sign.  \nI think OpenAI\u2019s decision to pause the development of GPT-5 is a responsible move and I look forward to seeing how the company continues to address the challenges associated with AI advancement.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "It's kinda amazing how many idiots believe that \"training\" is the most expensive or the most complicated part of the process.",
            "score": 4,
            "replies": [
                {
                    "level": 1,
                    "comment": "All those idiots that don't have very niche tech knowledge",
                    "score": 2,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Yeah, all those idiots that form and express uninformed opinions.",
                            "score": 1
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "lol this is so stupid",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Lol, y\u2019all act like they can\u2019t lie. Of course they trained it and are likely on there way to gpt 6",
            "score": 1
        },
        {
            "level": 0,
            "comment": "This CEO seems to be paranoid so much.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "why not just generate what evil things ppl will do with ai and then generate solutions to counter them? just an idea, im not a tech guy",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "That's basically what alignment is",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "Can everything be countered? I.e. Nuclear Detterence. If a strike is so powerful there is no chance to counterattack?",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "They should just train it anyways.",
            "score": 0
        },
        {
            "level": 0,
            "comment": "Ok then give me folders for chats.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "The rate of research in this area is insane and coming a mile a minute from all directions. They are not pausing for some touchy-feely reason, they are pausing to catch up to incorporate all these goings on into GPT-5, so they can't be outmaneuvered by committing too early.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "The old claim a new version scam..\n\nGpt5 is a joke. Especially as they can now forever add on items.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "The constant reassurances that they aren\u2019t working on the next version just feels like a means of promoting themselves. Like it\u2019s so freakishly good right now that to take another step forward could spell certain doom.\n\nWhat we\u2019ve seen so far is impressive, but Skynet levels of danger are still pretty far off.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "They're building it, not training it yet? \n\nTraining seems like a specific part of the process and doesn't mean they haven't started working on it.  \n\nNote: I've no idea what I'm talking about",
            "score": 1
        },
        {
            "level": 0,
            "comment": "I say GPT should make an NSFW one specifically for people who want it",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Just train it be worse if he dies unexpectedly and it's left to someone else.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "The adaptation number is erratic. They will call the following adaptation 4.2 or 4.5. They could choose to refer to the one after that as \"GPT 360\" or something to that effect. Haha.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "My theory is that within openai they have models that started to exhibit strong AGI traits, but they can't release them until there is government regulation.\n\nIf there is no government regulation the blame for the negative effects of the AGI on our daily life will be on OpenAI, i hope they listen to altman, so they can release the next gen of AI.",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "What\u2019s this based on?",
                    "score": 2
                }
            ]
        }
    ]
}