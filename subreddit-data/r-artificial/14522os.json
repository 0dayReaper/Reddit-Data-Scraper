{
    "id": "14522os",
    "score": 25,
    "title": "What are the most thoughtful people to listen to about AI, the future of it, social and economical implications, etc?",
    "author": "Signal_Hedgehog_343",
    "date": 1686308216.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "Dharmesh Shah is great. I'm not confident he consistently touched ons social/economic impact, but he is incredibly knowledgeable and down to earth (surprising for a billionaire). \n\n&amp;#x200B;\n\n* [https://www.linkedin.com/in/dharmesh](https://www.linkedin.com/in/dharmesh)\n* [https://twitter.com/dharmesh](https://twitter.com/dharmesh)",
            "score": 7,
            "author": "erikudahl"
        },
        {
            "level": 0,
            "comment": "Future of life podcasts. Mo Gawat; not quite as bleak as Eliezer but he brings up a lot of good points on potential hazards we will be dealing with.",
            "score": 5,
            "author": "domcobb8"
        },
        {
            "level": 0,
            "comment": "Rob Miles YouTube channel is great. He does a great job of simplifying and explaining things. \n\nMaybe watch the Lex Friedman with Ben Goertzel if you like Lex in general. \n\nIt depends how technical you want to get but AIXI by Marcus Hutter is one of the coolest ideas out there. \n\nI also think the culture series by Iain Banks is the closest to a super long term forecast which is attractive.\n\nAnd if course Paths Strategies Dangers by Bostrom is a classic.",
            "score": 17,
            "author": "parkway_parkway",
            "replies": [
                {
                    "level": 1,
                    "comment": "Wow, that's a lot! Thank you!",
                    "score": 1,
                    "author": "Signal_Hedgehog_343",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Rob Miles has videos about AI safety on his own channel, but he has several on the Computerphile YouTube channel also. If you want to understand why we have not solved yet how to avoid being killed by AI, those are a great watch. And you don't need to be a computer science expert to understand them at all.",
                            "score": 2,
                            "author": "REOreddit"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "This is a good podcast with Mo Gawdat, ex Google Officer on @TheDiaryOfACEO posted about a week ago.  It already has 3M views.\n\nhttps://m.youtube.com/watch?v=bk-nQ7HF6k4\n\nAlso, there is a new small channel I ran across a couple of days ago that has some really slick videos on AI.  @EraOfAI_\n\nhttps://www.youtube.com/@EraOfAI_/videos",
            "score": 4,
            "author": "Psychological-Ice370",
            "replies": [
                {
                    "level": 1,
                    "comment": "Mo is interesting. The points on near term problems should not be ignored.  Also feels more grounded than some of the other doom scenarios being presented. \n\nDefinitely also feel his point the convergence of destructive issues we are facing.  Have a feeling a lot of us do whether or not we are conscious of it. I also like that he points out there is a path and AI could be deciding factor but it is very narrow, not obvious we will see it through and if we do, that we will retain human dignity. We can\u2019t rest on a hope but we need to keep it alive to make it though.  Keep compassion alive.",
                    "score": 1,
                    "author": "domcobb8",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "What is quite interesting to me is how some of the people I know who use AI in very technical and important work (airline safety for example) view the future. Most of them operate within the parameters of private data sets which are not in the public domain. They have control over what goes into the data base and feel confident that whatever answers are produced by their AI application are the product of quality,ie,true, information. This is the exact opposite of the data which composes the LLMs used by public AI chatboxes. There is too much garbage and the results ,often called \"hallucinations\" are the result",
                            "score": 1,
                            "author": "Calm-Cartographer719",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I would be more inclined to trust specialized and controlled applications. Regardless of application though, I think concern is justified over use cases where we cannot or are not validating and/or quality of methods are used to validate are questionable. \n\nThe more embedded it becomes and the more dependency we shift, it would seem there would be a problem in maintaining and discerning for quality; black box logic that we cannot credibly interpret but rely on feels dangerous. Already Open AI is using [AI to explain itself.](https://openai.com/research/language-models-can-explain-neurons-in-language-models) This seems incredibly problematic. From what I gather in forums, most enthusiasts will dismiss concerns as sensationalized or greedy but also seeing inverse sentiment among high level experts being increasingly vocal on hazards.  \n\nEither way, momentum is built in and feel pretty strongly we are on for radical changes in relatively near term future. Setting aside AGI and alignment issues for a later time, there are enormous potential benefits to be had but there are harder questions of for whom and what are the unintended consequences; particularly where we are outsourcing knowledge work, reasoning, and critical thinking. Already, there are grey lines on how, what, and veracity of information is being disseminated at scale. At what point are we making a choice on content and at what point are we the product of the content. How much would that be affected when models 100x smarter than us are used to deploy the information we consume?\n\nIn some ways, the speed of AI development is timely. The intensity of climate change is also on exponential rise and i do not we can react with enough speed to offset the severity without some pretty dramatic breakthroughs so despite misgivings, it may be a Faustian agreement we cannot escape.",
                                    "score": 1,
                                    "author": "domcobb8"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Look up Yuval Noah Harari on youtube, author of Sapiens. He does a good job on analyzing AI in the context of humanity as a whole. He's also written some pieces but I find listening to him a better experience.",
            "score": 8,
            "author": "ChinCoin",
            "replies": [
                {
                    "level": 1,
                    "comment": "his bhutan interview, along with the recent video (formal statement) on consciousness, are must-watches",
                    "score": 2,
                    "author": "hoodiemonster"
                }
            ]
        },
        {
            "level": 0,
            "comment": "ive been enjoying david shapiros channel for interesting, thoughtful speculation. https://youtube.com/@DavidShapiroAutomator\n\nfound this vid, and all vids, with daniel schmachtenberger to be riveting. more about the \u201cmetacrisis\u201d in general but related. https://youtu.be/_P8PLHvZygo\n\ni like yannic kilcher for the really technical stuff\n\nseconding yuval noah harari. this video is important: https://youtu.be/1rtS2OEV6bM",
            "score": 3,
            "author": "hoodiemonster"
        },
        {
            "level": 0,
            "comment": "Haven't finished it yet, but really enjoying The Alignment Problem by Brian Christian. Much more balanced than many AI takes I've seen which tend to fall into the AI proselytizers or the AI doomsayers. He discusses in detail the benefits and challenges of implementing AI in effective and beneficial ways.\n\nMelanie Mitchell's book on AI was okay, but it didn't really resonate with me in the same way.",
            "score": 3,
            "author": "justgetoffmylawn",
            "replies": [
                {
                    "level": 1,
                    "comment": "That sounds perfect. Those balanced takes seems to be a rarity.",
                    "score": 2,
                    "author": "Signal_Hedgehog_343"
                },
                {
                    "level": 1,
                    "comment": "It was mentioned in yesterday's NYT book review section and I just ordered it.",
                    "score": 1,
                    "author": "Calm-Cartographer719"
                }
            ]
        },
        {
            "level": 0,
            "comment": "This presentation by the minds behind the doc The Social Dilemma is absolutely quintessential: [https://vimeo.com/809258916/92b420d98a](https://vimeo.com/809258916/92b420d98a). I will warn you not to watch it before bed.",
            "score": 5,
            "author": "farmpasta",
            "replies": [
                {
                    "level": 1,
                    "comment": "I second this. Fascinating and urgent.",
                    "score": 1,
                    "author": "I_Amuse_Me_123"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Perry Metzger, Robin Hanson, Marc Andreessen, Patrick Blumenthal, Michael Shellenberger, Matt Parlmer, Foresight Institute, most of OpenAI and Meta, most of the e/acc accounts on Twitter...\n\nReally anyone outside of the LessWrong/EA orbit. So I'm necessarily disagreeing with everyone recommending Rob Miles. He's cute and all, but carrying water for totalitarianism.",
            "score": 2,
            "author": "Saerain"
        },
        {
            "level": 0,
            "comment": "[https://www.youtube.com/watch?v=nvyZd9h7GJ0](https://www.youtube.com/watch?v=nvyZd9h7GJ0) These people are pretty deep and profound.",
            "score": 2,
            "author": "Plenty-Strawberry-30"
        },
        {
            "level": 0,
            "comment": "Honestly just browse Lex Fridman's videos. Select those where they discuss AI. Lex's podcasts are almost always gold.",
            "score": 9,
            "author": "Lolleka",
            "replies": [
                {
                    "level": 1,
                    "comment": "The biggest downside of Lex' videos is you'll have to listen to Lex. I can't stand his voice anymore and his MIT professor larp and his same ambiguous questions about unrelated subjects to his interviewee expertise.",
                    "score": 9,
                    "author": "wonderingStarDusts",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Also his obvious right wing bias, and simping for Musk and Jordan Peterson can be quite off putting.",
                            "score": -1,
                            "author": "3j141592653589793238"
                        },
                        {
                            "level": 2,
                            "comment": "he's a repulsive creep with negative charisma, can't blame you",
                            "score": 0,
                            "author": "Schmilsson1",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "What the fuck.",
                                    "score": 0,
                                    "author": "Saerain"
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "lex, a bit of kurzweil, gets you there",
                    "score": 2,
                    "author": "indoortreehouse"
                },
                {
                    "level": 1,
                    "comment": "Long time listener here, love the podcast! I'm looking for more text-based options where the author spent time formulating his thoughts and opinions as well as he could about the particular subject matter of his or hers article.",
                    "score": 1,
                    "author": "Signal_Hedgehog_343"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Stuart Russell has some sensible things to say about why the current path of \u201cstatistical AI\u201d may be the wrong one.",
            "score": 2,
            "author": "Smallpaul",
            "replies": [
                {
                    "level": 1,
                    "comment": "Thank you!",
                    "score": 1,
                    "author": "Signal_Hedgehog_343"
                },
                {
                    "level": 1,
                    "comment": "What is the basis of his claim? Can you give a general idea?",
                    "score": 1,
                    "author": "Careful-Temporary388",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "1. Unreliability: such as hallucination, forgetting the task, getting confused.\n2. Inscrutability: nobody knows how they \"actually work\" so how do you fix a bug you discover?\n3. Dead end: he think that the combination of 1 and 2 means there is an upper bound of how intelligent and useful they can get.\n\nThere is also a strong upper-bound of how much CONFIDENCE we can have in a black-box system that no human understands. We are going to hand over more and more of our economy to systems that we do not understand at all.",
                            "score": 2,
                            "author": "Smallpaul",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Every word that pops into our head is just fancy autocomplete.   \n\n\nNo one understands how the brain works in general, or how their own brain works, or why we also constantly hallucinate. Yet, no one says we shouldn't rely on the brain because it is a complete black box.",
                                    "score": -1,
                                    "author": "HeyHershel",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "&gt;No one understands how the brain works in general, or how their own brain works, or why we also constantly hallucinate. Yet, no one says we shouldn't rely on the brain because it is a complete black box.\n\nOf course they do. That's what transhumanists say. And many computer programmers also work to make systems that are dramatically more reliable than the human brain. People use calculators instead of the human brain. And there are proof checkers and programming type checkers to correct mistakes made by the brain.\n\nWhen we have an option of using something more reliable than the human brain, we do. Airplane auto-pilot is another good example.\n\nAnd then look at the ENTIRE edifice of legal restrictions. All of those laws are intended to try to restrain the flaws in the human brain. And the entire police force and court system.\n\nAnd then there's the whole peer review system where scientists point out the mistakes other scientists make. And sometimes miss the mistakes for decades.\n\nIt isn't a crazy idea to say: \"hey...let's not invent a tool that will behave so randomly that we might need to worry about whether it will engage in unethical, criminal, illogical or dangerous behaviour as humans would.\"\n\nBear in mind that the goal is to make minds that are 10 times smarter than a human. So now you've got a potential criminal that's much smarter than the people trying to enforce the laws. Doesn't seem very safe, does it?",
                                            "score": 3,
                                            "author": "Smallpaul"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Thank you.",
                                    "score": 1,
                                    "author": "Careful-Temporary388"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Yoshia Bengio is one of the most impactful thinkers in the field with multiple extremely influential papers\n\nhttps://yoshuabengio.org/",
            "score": 2,
            "author": "HolevoBound",
            "replies": [
                {
                    "level": 1,
                    "comment": "This is great, thank you!",
                    "score": 2,
                    "author": "Signal_Hedgehog_343"
                }
            ]
        },
        {
            "level": 0,
            "comment": "&gt;I feel like a lot of the articles I've been reading are from some Joe Schmo blogger and not the most authoritative people on the subject.\n\nThere aren't a lot of people talking about this as it is outside the lanes of most of the AI enthusiasts. They aren't sociologists, economists or philosophers. Authoritative sources can tend to be a community of closed group think.\n\nAt the risk of being labeled just another \"Joe Schmo\", I will leave this as a FYI if you care to take a look, but I've put more into the social and societal subjects than I've found elsewhere.\n\nhttps://dakara.substack.com/p/ai-and-the-end-to-all-things",
            "score": 2,
            "author": "Liberty2012"
        },
        {
            "level": 0,
            "comment": "Eliezer Yudkowsky",
            "score": 2,
            "author": "dietcheese",
            "replies": [
                {
                    "level": 1,
                    "comment": "You forgot the /s",
                    "score": 3,
                    "author": "Spskrk",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "What's wrong with EY? You have someone you would recommend instead?",
                            "score": 1,
                            "author": "EnsignElessar",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "If you follow him on Twitter and you don\u2019t see what is wrong with him then nothing I say here will convince you there is something wrong with him. \nI would recommend any actual AI researcher over him but I personally agree with the views of Francois Chollet, Yan LeCun and Andrew NG.",
                                    "score": 2,
                                    "author": "Spskrk",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Fedora? Is it the fedora?\n\n&gt;  personally agree with the views of Francois Chollet, Yan LeCun and Andrew NG.\n\nWhy though?",
                                            "score": 1,
                                            "author": "EnsignElessar"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "The \"Godfather of AI,\" Geoffrey Hinton, has interesting thoughts since he was in on the origins of what we have now.  In an interview, he said that long ago while exploring Neural Networks, he was interested in how the brain works.\n\nHe left Google.\n\nToday he focuses on dramatically reducing the cost of LLM models and their power requirements. He noted how the brain uses an incredibly small amount of energy to \"think\" compared to AI which could consume vast amounts of power where multiple computers containing many GPUs exchange information.\n\nIn one interview, he imagined what if in the future someone could talk to their AI toaster which had a tiny chip that cost less than $20.\n\nGeoffrey  talked about how back in the 80s he explored getting a computer to recognize an image, such as a cat. He explaind in simple terms the concept  Back Propagation to show how a computer could be trained to \"see\" a cat in an image. Back in the 80s, computers were much slower and couldn't process much data compared to today so there were limitations to what they could do.\n\nHere's a [snippet](https://youtu.be/qpoRO378qRY?t=211) where he talks about his primary interest being how the brain works in relation to things such as neural networks and LLM models. He thinks today's LLM models aren't quote doing it the right way. And as seen in the news, he left Google because he's concerned about AI.",
            "score": 1,
            "author": "president_josh",
            "replies": [
                {
                    "level": 1,
                    "comment": "Nice, this certainly sounds like a heavy hitter who has been thinking deeply about this for many years. Thanks.",
                    "score": 1,
                    "author": "Signal_Hedgehog_343"
                }
            ]
        },
        {
            "level": 0,
            "comment": "The easiest would be just to get the list of people who signed the \u201clet\u2019s stop AI for 6 months\u201d and \u201cAI is existential threat\u201d letters and avoid them. \n\nJokes aside, I mostly agree with the views of Francois Chollet, Yann LeCun and Andrew Ng.",
            "score": 1,
            "author": "Spskrk",
            "replies": [
                {
                    "level": 1,
                    "comment": "Why?",
                    "score": 1,
                    "author": "EnsignElessar"
                }
            ]
        },
        {
            "level": 0,
            "comment": "The decisions remain the same. \n\nWhat input.\nIs output as desired.\nIf Yes --&gt; Celebrate\nIf No --&gt; Repeat first step\n\nAll AI is doing is removing the obstacle of translation method. \"Technique Gatekeeping\" is suddenly a far less lrevelant thing. More and more who does what will be a function not of who has had time consuming, expensive training and experience \nAnd more and more the only thing that matters for decisions will from AI.\nThe interest.\nThe WILL.\n\nThat's still all us, and with AI/AGI mixed in, demand's going up, supply going down.\nNot a real bad place to be. Kind of exciting. New Internet? Wild West all over? \nRIDE WAVE THIS TIME. GROW WITH. DISCOVER AS.",
            "score": 1,
            "author": "HotaruZoku",
            "replies": [
                {
                    "level": 1,
                    "comment": "Cool. What are you methods of making sure you ride the wave instead of getting swallowed or surpassed by it?",
                    "score": 0,
                    "author": "Signal_Hedgehog_343"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Me.\n\nObviously everyone is going to tell you the one who agrees most with their own views. I'm simply being more direct.\n\nBut yes, I also vote for Robert Miles.",
            "score": 1,
            "author": "2Punx2Furious"
        },
        {
            "level": 0,
            "comment": "I\u2019ll give you a simple breakdown of my favorite AI accounts to follow:\n\nYouTube: [AI advantage](https://youtube.com/@aiadvantage) : He is super fast with AI news and tutorials in a video format which isn\u2019t easy to do.\n\nNewsletter: [The Edge](https://www.theedge.so) : The Edge post M-F with AI news and tools and the AI tools are tested and tried so I know they are good quality\n\nNews Station: [TechCrunch AI](https://techcrunch.com/category/artificial-intelligence/) : \nAs far as an official AI outlet they are the best they post almost 10 quality AI articles daily \n\nAnd follow _akhaliq on Twitter he post multiple Machine learning articles which are full length papers you can check out. \n\nHope this helps!",
            "score": 1,
            "author": "Evening_Temporary36",
            "replies": [
                {
                    "level": 1,
                    "comment": "Now this is a good list",
                    "score": 1,
                    "author": "Ok-Feeling-1743"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Stephen Wolfram",
            "score": 1,
            "author": "utf80"
        },
        {
            "level": 0,
            "comment": "Most of the AI grifters are truly horrible people and it's disturbing to see their profiles rise in this current \"moment\"",
            "score": 1,
            "author": "Schmilsson1"
        },
        {
            "level": 0,
            "comment": "Hi there, I don't intend to hijack OP's thread but if anyone can give some links towards the AI and the visual arts I would really appreciate it.\n\nsigned, a worried photographer/videographer",
            "score": 1,
            "author": "spudnado88"
        },
        {
            "level": 0,
            "comment": "Ray Kurzweil, made a documentary in the 2000\u2019s on predictions based on his \u201claw of accelerating returns\u201d which is about how we use todays tools to create tomorrows tools which lead to exponential computational growth.",
            "score": 1,
            "author": "Tough-Lab2184"
        },
        {
            "level": 0,
            "comment": "Chris McCormick did an excellent post about how stable diffusion actually works https://mccormickml.com/2022/12/21/how-stable-diffusion-works/\n\nOther than that - a16z has a pretty solid post about AI canon featuring leaders in the field etc.  https://a16z.com/2023/05/25/ai-canon/",
            "score": 1,
            "author": "tanyaelectricdreamer"
        },
        {
            "level": 0,
            "comment": "Kurzweil, Chalmers",
            "score": 1,
            "author": "sproutsatoshi"
        },
        {
            "level": 0,
            "comment": "This post has generated (by humans) a LOT of very good responses. Good work !",
            "score": 1,
            "author": "Calm-Cartographer719"
        },
        {
            "level": 0,
            "comment": "listen to sam harris and lex fridman and you're pretty much set.",
            "score": 1,
            "author": "ZenithAmness"
        },
        {
            "level": 0,
            "comment": "Since you said you're interested in different approaches...I wrote a book about the social implications of AI. Where we are and where we're going. Free right now, can be read here:\nhttps://javiermarti.co.uk/JM_website_2016/other/BOOK_Beautiful%20tsunami_AI_Javier_Marti.pdf",
            "score": 0,
            "author": "ronin_khan"
        },
        {
            "level": 0,
            "comment": "I've been listening to Lastweekin.ai for the past couple of years. It was started by Stanford University PhDs studying under Andrew Ng. They cover news articles each week from the perspectives of PhDs with additional insights on ethics and safety discussions which helps clear through some of the doomerism in academic AI discussions. \n\nhttps://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch?si=RUfV55LnTJaOKta45y7e9Q\n\nAnd 'Hold on to your papers!' because I've been listening to TwoMinutePapers almost as long. He covers scientific papers and uses visuals where appropriate. He does a lot of side by side comparisons with similar methods to demonstrate the quality of advancements. \n\nhttps://youtube.com/@TwoMinutePapers\n\nFor meme laden more general tech news, Fireship frequently covers what's happening from a more open source perspective like regarding regulator capture. He's not. A PhD in the field, but he shows how to use these tools in practice\n\nhttps://youtube.com/@Fireship",
            "score": 0,
            "author": "2good4hisowngood"
        },
        {
            "level": 0,
            "comment": "I personally love the lex Fridman podcast, he always brings in the top people in the field",
            "score": 0,
            "author": "amy_katt"
        }
    ]
}