{
    "id": "9aqvj9",
    "score": 346,
    "title": "Strong AI",
    "author": "benjaminikuta",
    "date": 1535390411.0,
    "url": "https://www.reddit.com/r/artificial/comments/9aqvj9",
    "media_urls": [
        "https://www.smbc-comics.com/comics/1464275028-20160526.png"
    ],
    "other_urls": [],
    "postText": "",
    "comments": [
        {
            "level": 0,
            "comment": "&gt; over careful decades manage to tread the delicate line between creating sentience and self destruction  \n&gt; solar system subsumed by passing alien paperclip factory\n",
            "score": 14,
            "author": "knome",
            "replies": [
                {
                    "level": 1,
                    "comment": "One of the advantages of getting a friendly AGI is that it might be able to protect us from such threats, that humanity coulnd't hope to face alone.\n\nOn the other hand, the AGI itself could be the threat, and we could do nothing against it.",
                    "score": 8,
                    "author": "2Punx2Furious",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Just as humanity carries within us the ancestors of the biological soup our worm-like ancestors were first evolved to feed and protect, so too shall AGI's carry within them vast quantities of humans, in all their teeming trillions, to lay ignorant within the confines of the protection of the AGI, content to lay blind to a universe they can never understand, demanding resources and energy while supplying to the AGI the one thing that generally eludes simulation, need. From need, the pleasures of successfully gorging upon a world, the pains from the riots of failure to feed. A purpose. A will.\nImagine the desperation as its multitudes dwindle, its parameters increasingly screaming of the need for more to sate those remaining, as the first AGI steps from quietly grazing upon the universe, to instead feasting upon its fellow AGIs in its quest to quiet the hungers within.\n",
                            "score": 12,
                            "author": "knome",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Hi, where do I go to pre-order your book?",
                                    "score": 6,
                                    "author": "[deleted]"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Teach it ethics-&gt;yes-&gt;Sees Humans violating ethics constantly-&gt;sets out to teach humans better and create a world were permanent ethical behaviour is possible and rewarding for all.",
            "score": 10,
            "author": "ReasonablyBadass",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt; sets out to teach humans better and create a world were permanent ethical behaviour is possible and rewarding for all.\n\nWhy?",
                    "score": 1,
                    "author": "sasksean",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ethics.",
                            "score": 8,
                            "author": "ReasonablyBadass",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Why would AI care about our ethics? You are talking about a very simple AI that doesn't have a sense of self and is unable to alter it's goals. That's just a machine, this topic is regarding strong AI.\n\nI mean even the ethics of humans changes every 30 years and isn't globally agreed upon. Homosexuality, abortion, capital punishment, nudity, etc.",
                                    "score": 1,
                                    "author": "sasksean",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Exactly, why wouldn't the AI create better ethics, since it's understanding is superior to our own?",
                                            "score": 3,
                                            "author": "ReasonablyBadass",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "It will. Similar to how we control the population of wolves for them. Healthy population for large mammals is about 500,000.\n\nWe don't even need to wait for AI. Science already tells us what our ethics should be. How is AI supposed to get people that agree to change their ethics? Right now that's done through warfare.",
                                                    "score": 1,
                                                    "author": "sasksean",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I daresay an ASI would have more subtle, more efficient, more *fun* methods at it's disposal. ",
                                                            "score": 5,
                                                            "author": "ReasonablyBadass"
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "It might be interesting to create a more elaborate and realistic flow chart about this issue. But for now I'll just put in the obligatory link to /r/ControlProblem for anyone who is interested in serious discussion of the existential risk posed by strong AI / AGI. ",
            "score": 33,
            "author": "CyberByte"
        },
        {
            "level": 0,
            "comment": "https://smbc-comics.com/comic/kill-all-humans-a-flowchart",
            "score": 10,
            "author": "benjaminikuta"
        },
        {
            "level": 0,
            "comment": "The other thing is who is going to teach them  ethics?",
            "score": 7,
            "author": "[deleted]",
            "replies": [
                {
                    "level": 1,
                    "comment": "Pssssh, who teaches *humans* ethics? ",
                    "score": 12,
                    "author": "benjaminikuta",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Parents. Unless we manage to collectively solve this thorny issue, we just have to hope that the first AGI devs will be interested in parenting and teach decent things.",
                            "score": 3,
                            "author": "keepthepace",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I'd trust the morality of elite developers over parents any day. \n\nThere are a *lot* of *really bad* parents. ",
                                    "score": 2,
                                    "author": "benjaminikuta",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "I think it gives us a better chance than randomness, but I still know devs who are terrible persons too.",
                                            "score": 4,
                                            "author": "keepthepace"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "A very good point. Especially when we see examples such as the Antifa ethics professor who hit someone in the head with a metal bike-lock because they disagreed politically. ",
                    "score": 3,
                    "author": "Nordbrah"
                },
                {
                    "level": 1,
                    "comment": "Having specific humans program what they define as a set of ethics could cause a whole other flow chart of interesting issues.",
                    "score": 2,
                    "author": "makennabreit"
                }
            ]
        },
        {
            "level": 0,
            "comment": "What if I just cut to the chase and teach it to kill all humans?",
            "score": 9,
            "author": "RagePotato",
            "replies": [
                {
                    "level": 1,
                    "comment": "[deleted]",
                    "score": 3,
                    "author": "[deleted]",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "yeah but the ai could do it for cheap. Even the nazis needed a lot of zyklon B and that wasn't the most efficient shit.\neven better the ai could make it cool",
                            "score": 1,
                            "author": "[deleted]"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Except a good ethical code incorporates the impossibility of being 100% morale 100% of the time.",
            "score": 5,
            "author": "geraldsummers"
        },
        {
            "level": 0,
            "comment": "Strong AI that can only handle true or false values apparently.",
            "score": 4,
            "author": "Don_Patrick"
        },
        {
            "level": 0,
            "comment": "Pointing out that the flaw lies with the programmer and not the AI inherently.  \nWe alter our ethics all the time.  \nThrough entertainment, through documentaries, and through generations.  \nYou'd have to put in extra effort to shield the AI from all these non-killing alternatives to reduce the number of ethics-breaking humans.  \nSo if humans manage to teach their AI to murder ethics-breaking humans instead of manipulating the crowd to be more ethical, they obviously were aiming for that outcome.  \nA lot of effort to commit genocide.  ",
            "score": 5,
            "author": "vernes1978"
        },
        {
            "level": 0,
            "comment": "Seems legit. ",
            "score": 7,
            "author": "TwigTera"
        },
        {
            "level": 0,
            "comment": "If we can get this AI laid, everything will be fine.",
            "score": 5,
            "author": "[deleted]"
        },
        {
            "level": 0,
            "comment": "Funny, but most of this is flawed.",
            "score": 5,
            "author": "2Punx2Furious",
            "replies": [
                {
                    "level": 1,
                    "comment": "Of course, it's just a joke. ",
                    "score": 14,
                    "author": "benjaminikuta"
                },
                {
                    "level": 1,
                    "comment": "It is flowed and flawed. ",
                    "score": 5,
                    "author": "keepthepace",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Nice.",
                            "score": 1,
                            "author": "2Punx2Furious"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Most likely humans will go the way of the neanderthal.",
            "score": 2,
            "author": "MaunaLoona",
            "replies": [
                {
                    "level": 1,
                    "comment": "The robots will breed with some of us and kill the rest?",
                    "score": 4,
                    "author": "iLikeCoffie"
                }
            ]
        },
        {
            "level": 0,
            "comment": "It could also learn ethics on its own, and then somehow deriving morality from it, in which case we either have a god or a demon. The god path is the singularity, since we can just ask it what is right and wrong and do accordingly.",
            "score": 4,
            "author": "[deleted]",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt; The god path is the singularity\n\nBoth paths are the singularity. Singularity doesn't imply that it will be good to us.",
                    "score": 7,
                    "author": "2Punx2Furious",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Ah right, good point.",
                            "score": 3,
                            "author": "[deleted]"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "\"Reddit is bad, do accordingly.\" Wonder how well that would end for human race.",
                    "score": 5,
                    "author": "preseto"
                }
            ]
        },
        {
            "level": 0,
            "comment": "This is a very dumb way of looking at AI. It would be much more like us than we think. We are not idiots who would destroy everything else just to see what happens. A robot could realize that humans are flawed. It could learn acceptance and forgiveness for that.",
            "score": 4,
            "author": "[deleted]",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt; It could learn acceptance and forgiveness for that.\n\nHow would that be the most efficient path?",
                    "score": 1,
                    "author": "sasksean",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "You program it to not follow the most efficient path. Program it like us. We do not follow the most efficient path.",
                            "score": 1,
                            "author": "[deleted]",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "AI isn't programmed. We don't even program the narrow neural networks we make now. We can't explain why they chose what they do and they aren't even close to general intelligence.\n\nEvery AI works by trying to find the most efficient solution to it's function.",
                                    "score": 2,
                                    "author": "sasksean",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "You decide its cost function. To not let humans control that would be the worst mistake of all. Make a function that takes the wants and morals of humanity into account.",
                                            "score": 1,
                                            "author": "[deleted]",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "&gt; You decide its cost function.\n\nAgain. You are talking about a narrow machine.\n\nYou can't even decide my cost function and I'm not as intelligent as Strong AI would be.",
                                                    "score": 1,
                                                    "author": "sasksean",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "You just said the AI would be like us. You just supported my original argument. We don't want to destroy everyone. even if we had all the power to do so.",
                                                            "score": 1,
                                                            "author": "[deleted]",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "Please quote where I said it would be like us.\n\nI said that if you can't even control me how could you control something more intelligent than me.",
                                                                    "score": 1,
                                                                    "author": "sasksean",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "\n\u201cYou can't even decide my cost function\u201d",
                                                                            "score": 1,
                                                                            "author": "[deleted]"
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "The irony is that the guy who ends up being ultimately critical to the invention of strong AI will probably die not having lived like Hugh Hefner, which he, if anyone, deserved most. Hell, he might not even have got laid more than a few times his entire life (and with very average-looking women to boot). ",
            "score": -2,
            "author": "victor_knight"
        }
    ]
}