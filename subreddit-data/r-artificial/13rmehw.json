{
    "id": "13rmehw",
    "score": 108,
    "title": "We aren't much different from Generative AI",
    "author": "ShaneKaiGlenn",
    "date": 1685032388.0,
    "url": null,
    "media_url": "https://www.reddit.com/r/artificial/comments/13rmehw/we_arent_much_different_from_generative_ai/",
    "comments": [
        {
            "level": 0,
            "comment": "I wonder how many parameters we have",
            "score": 10,
            "replies": [
                {
                    "level": 1,
                    "comment": "Current guess is around 100T",
                    "score": 7,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I think I have much less than that",
                            "score": 6
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "At least four. Maybe even five or six.",
                    "score": 3,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "On a good day I have as many as 40.",
                            "score": 2
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Same principle discussed here  about how our brains use binomial probabilities to determine things https://www.samharris.org/podcasts/making-sense-episodes/320-constructing-self-and-world\n\ne.g. if you're walking down the street and it's foggy, and in the distance you see something kind of resembling a lion, your brain goes into processing mode..I'm on a street in Kansas, far from a zoo, there's a person standing next to it, that's not a lion it's most likely a dog so you don't panic.\n\nHowever if you're  in the Serengeti and you see the exact same thing, then context clues will fill you in that it's more likely to be a lion than a dog.",
            "score": 9
        },
        {
            "level": 0,
            "comment": "&gt;Our brains are constantly simulating an environment for us, but we can never truly access \"reality\" as it actually is.\n\nSeems like basically what Kant said &gt;200 years ago - dude was pretty smart.\n\nThe Free Energy Principle seems super promising for further insights, though. I've been excited to learn more about it after listening to a great podcast with Karl Friston.",
            "score": 8,
            "replies": [
                {
                    "level": 1,
                    "comment": "Or Plato, 2000+ years ago\n\nhttps://en.m.wikipedia.org/wiki/Allegory_of_the_cave",
                    "score": 4
                }
            ]
        },
        {
            "level": 0,
            "comment": "100% there is something going on in our heads that LLMs have started to mimic in meaningful ways. This gives us insight into ourselves that we had no experimental access to before.\n\n[https://medium.com/predict/what-ai-teaches-us-about-stupid-dd3df2df6b68](https://medium.com/predict/what-ai-teaches-us-about-stupid-dd3df2df6b68)",
            "score": 47,
            "replies": [
                {
                    "level": 1,
                    "comment": "Not quite right. Buddhist (and maybe other meditative traditions?) already described such process of constructed reality hundreds of years ago.\n\nEdit: Nevermind, you wrote \"experimental\", I read \"experiencal\" ...",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "Language. That's what makes humans sentient. Without our facility with language there is no \"intelligence\". We can only make the tools we could fashion ourselves in our lifetime and never convey information to each other or into the future through writing.\n\nThese systems model language. \"Language models model language,\" is the canonical quote.\n\nHumans tend to react to things that sound like people as if they are people. But they aren't people. They are statistical models literally picking the next most likely word based on context. That's \"all\" they are doing. It's a useful tool but not intelligence, at least not what we've previously defined intelligence as.\n\nI think most people believe that they are doing more than picking the next most likely word when they think. Certainly neuroscientists don't think that is what human cognition boils down to.",
                    "score": -1,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                            "score": 20,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "But that is \"literally\" what they are doing. They are picking the next best word, based on the weights and bias values baked into their models, using a statistical process.\n\nYou can claim emergent behavior all you like. Perhaps you are right. We shall see.\n\nMy concern is that they are dangerous enough already, just doing what they are doing now. A more powerful model will just be more dangerous, IMO.",
                                    "score": -2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "\nThis user profile has been overwritten in protest of Reddit's decision to disadvantage third-party apps through pricing \nchanges. The impact of capitalistic influences on the platforms that once fostered vibrant, inclusive communities has \nbeen devastating, and it appears that Reddit is the latest casualty of this ongoing trend. \n\nThis account, 10 years, 2 months, and 25 days old, has contributed 318 \ntimes, amounting to over 54036 words. In response, the community has awarded it more than 10346 \nkarma. \n\nI am saddened to leave this community that has been a significant part of my adult life. However, my departure is driven \nby a commitment to the principles of fairness, inclusivity, and respect for community-driven platforms. \n\nI hope this action highlights the importance of preserving the core values that made Reddit a thriving community and \nencourages a re-evaluation of the recent changes. \n\nThank you to everyone who made this journey worthwhile. Please remember the importance of community and continue to \nuphold these values, regardless of where you find yourself in the digital world.",
                                            "score": 11
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "It borrows our collective insight and intelligence in one condensed form. Is it intelligent? It is as intelligent as all of us. Is it creative? Somewhat in how it picks it's word choices. Is it the singularity? Absolutely not, but it is a glimpse into how we might get there. I'm amazed that it gets so many correct responses and appears to understand us using our own language reflecting back to us. It can do so much with so little actual thought.",
                                    "score": 1
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "&gt;picking the next most likely word based on context\n\nAnd sometimes that is what we do too.\n\nNot the only thing we can do, but that is all we need to do sometimes to be competent.",
                            "score": 5
                        },
                        {
                            "level": 2,
                            "comment": "There is an underlying logic to language though (Boolean gates like and/or, not, etc). As the systems learn from language, they organize via semantic order and eventually may be arriving at context. I do agree that it just elaborates the illusion that much more, though. Indistinguishable is dangerous.",
                            "score": 6
                        },
                        {
                            "level": 2,
                            "comment": "I think \"picking the next word\" or \"picking the next action\" is exactly what our human brains our doing.  Benjamin Libet's experiments in the 80s largely align with that.  We're sort of on autopilot based on complex survival and reproductions instincts, internal and external stimuli, and a few other factors. We just use language to tell ourselves stories of why we did the things we already did.  My opinion, anyway.",
                            "score": 2,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Assuming that's true, for someone to learn language first they need to get the data from somewhere, at this point in history you could say that we learn just like language models because we just listen to other people speak and that's our training data, but before language existed there was no data to learn from so how did we invent language?",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "We inched toward it slowly.  Pointing, grunting, ooks and acks.  Eventually something formed.  It's weird because after enough time and selection pressure we optimized for the wiring that made us better at language because those who could communicate -- even at a primitive level -- had a distinct survival advantage over those who could not.\n\nI think one thing that gets lost is epigenetic interactions.  Like how smiling as a sign of happiness is universal across human cultures.  Or how puppies instinctively know not to make a mess in their crates (most of the time).  There are some things that are \"hard coded\" in our DNA/brain wiring.  I think that's what connection weights are in LLMs.  But again, this is conjecture.",
                                            "score": 2
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "level": 2,
                            "comment": "Language makes humans sentient. \n\nI adore reddit.",
                            "score": 1
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "[removed]",
            "score": 6,
            "replies": [
                {
                    "level": 1,
                    "comment": "Honestly there's a lot less emergent behavior than we think. A lot of it is input driven. Sit alone in a room for a while and try to think brand new thoughts and see how far you can get.",
                    "score": 1
                }
            ]
        },
        {
            "level": 0,
            "comment": "It's even worse. Not only do we only experience a \"simulation\" (hallucination) of reality, the simulation is a prediction of the near future as neurons are way to slow to create a realtime simulation (it's impossible to life in the present). The brain is a prediction machine. On top of that, different sensory inputs are processed at variable speeds depending on the type of sensory input and complexity of processing them, so the brain has to integrate different prediction durations to calculate the hallucination. It does that by not simulating a constant smooth simulation, but \"quantised\" blocks (of variable durations based on complexity). The smoothness we experience is an illusion.",
            "score": 16
        },
        {
            "level": 0,
            "comment": "Have you read or listened to Donald Hoffman by chance? He\u2019s been talking about this for a while. It\u2019s pretty kind bending when you think about it. Also makes you wonder if someone could hijack the inputs and replace with a facsimile that makes us think nothing has changed",
            "score": 3,
            "replies": [
                {
                    "level": 1,
                    "comment": "same thing i said, before seeing your comment\n\n[Donald Hoffman's \"interface theory of perception\"](https://en.m.wikipedia.org/wiki/Donald_D._Hoffman#:~:text=Hoffman%20argues%20that%20consciousness%20is,a%20fundamental%20aspect%20of%20reality.)\n\nis kind of very similar to this or same. i don't know but it's been a while since i saw his interview and he described it similar to OP\n\ni had GPT4 summarise his theory &gt;\n\n\"Donald Hoffman's Interface Theory of Perception (sometimes conflated with Interface Theory of Consciousness) is a radical perspective on how we perceive reality. The basic premise of the theory is that what we perceive around us is not the \"true\" reality, but merely a simplified interface designed by evolution to help us survive.\n\nHoffman uses the metaphor of a computer desktop to illustrate his theory. When you interact with the icons on your desktop, you're not engaging directly with the complex workings of the computer, but with a simplified user interface designed for usability. According to Hoffman, evolution has done something similar with our perception of reality. The objects we perceive \u2013 tables, chairs, other people, etc. \u2013 are like the icons on a computer desktop, serving as a simplified interface that hides the complexity of the real world.\n\nIn this model, our senses are not windows that give us an accurate view of the world, but rather a set of tools that allow us to navigate and interact with the world in ways that have promoted survival and reproduction.\n\nIt's important to note that the Interface Theory of Perception doesn't deny the existence of an objective reality. Rather, it suggests that we don't have direct access to this reality, and that what we perceive is a user-friendly version designed by natural selection.\n\nThis theory also proposes that consciousness is fundamental, not derivative. According to Hoffman, consciousness is not something that emerges from sufficiently complex computation, as some theories suggest. Instead, he argues that consciousness is fundamental to the universe, much like space, time, and matter.\n\nInterface Theory of Perception is a controversial viewpoint and it has significant implications, particularly for fields such as artificial intelligence and philosophy of mind. It challenges deeply held assumptions about reality and our relationship to it, and its acceptance or rejection could have profound implications. \"",
                    "score": 4,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Thanks for that. I\u2019ve been leaning towards this perspective for a long time. It would help bridge the gap between different conflicting theories and views. It makes logical sense even though it\u2019s unintuitive. \n\nBut it makes sense that we would hold our stimuli and senses as accurate readers of reality but the same could probably be said for the bat or the slug.",
                            "score": 2
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "I haven't, but I will check it out. But this also explains how psychedelics work... hallucinations result from interference in the models which finetune your perception to novel patterns.\n\nEDIT: This was a great talk: https://www.youtube.com/watch?v=oYp5XuGYqqY",
                    "score": 2
                },
                {
                    "level": 1,
                    "comment": "&gt;hijack the inputs and replace with a facsimile that makes us think nothing has changed\n\nThat was essentially the background of The Matrix.\n\nPrior to that, this scenario was considered by French philosopher and mathematician Rene Descartes (his [evil demon](https://en.wikipedia.org/wiki/Evil_demon)), the Chinese philosopher Zhuangzi (the [man dreaming he's a butterfly](https://en.wikipedia.org/wiki/Zhuangzi_(book))), and by many other 20th and 21st century philosophers (the [brain in a vat](https://en.wikipedia.org/wiki/Brain_in_a_vat)).",
                    "score": 2
                }
            ]
        },
        {
            "level": 0,
            "comment": "This thread needs to read an intro to philosophy textbook and smoke a little less weed.",
            "score": 4
        },
        {
            "level": 0,
            "comment": "Yeah we have known this for a couple hundred years. https://en.m.wikipedia.org/wiki/Immanuel_Kant",
            "score": 3
        },
        {
            "level": 0,
            "comment": "We all live in our own personal delusion.  Some of tend to migrate to a norm and experience things similarly while others do not.",
            "score": 3
        },
        {
            "level": 0,
            "comment": "This general idea isn't a new one :\n\n https://en.wikipedia.org/wiki/Allegory_of_the_cave",
            "score": 3
        },
        {
            "level": 0,
            "comment": "[Donald Hoffman's \"interface theory of perception\"](https://en.m.wikipedia.org/wiki/Donald_D._Hoffman#:~:text=Hoffman%20argues%20that%20consciousness%20is,a%20fundamental%20aspect%20of%20reality.)\n\nis kind of very similar to this or same. i don't know but it's been a while since i saw his interview and he described it similar to you.\n\ni had GPT4 summarise his theory &gt;\n\n\"Donald Hoffman's Interface Theory of Perception (sometimes conflated with Interface Theory of Consciousness) is a radical perspective on how we perceive reality. The basic premise of the theory is that what we perceive around us is not the \"true\" reality, but merely a simplified interface designed by evolution to help us survive.\n\nHoffman uses the metaphor of a computer desktop to illustrate his theory. When you interact with the icons on your desktop, you're not engaging directly with the complex workings of the computer, but with a simplified user interface designed for usability. According to Hoffman, evolution has done something similar with our perception of reality. The objects we perceive \u2013 tables, chairs, other people, etc. \u2013 are like the icons on a computer desktop, serving as a simplified interface that hides the complexity of the real world.\n\nIn this model, our senses are not windows that give us an accurate view of the world, but rather a set of tools that allow us to navigate and interact with the world in ways that have promoted survival and reproduction.\n\nIt's important to note that the Interface Theory of Perception doesn't deny the existence of an objective reality. Rather, it suggests that we don't have direct access to this reality, and that what we perceive is a user-friendly version designed by natural selection.\n\nThis theory also proposes that consciousness is fundamental, not derivative. According to Hoffman, consciousness is not something that emerges from sufficiently complex computation, as some theories suggest. Instead, he argues that consciousness is fundamental to the universe, much like space, time, and matter.\n\nInterface Theory of Perception is a controversial viewpoint and it has significant implications, particularly for fields such as artificial intelligence and philosophy of mind. It challenges deeply held assumptions about reality and our relationship to it, and its acceptance or rejection could have profound implications. \"",
            "score": 3
        },
        {
            "level": 0,
            "comment": "Not sure what the relevance of AI is but I totally agree with most of what you're saying.\n\nThe analogy i use is a windows versus a CCTV camera. People think of their eyes like windows but really they are like digital cameras, and your experience is the reconstructed image that's projected on the secuturity monitor.\n\nWhen you dream, you're still a security monitor but the camera is something different to what it when you are awake.\n\nWhere this thread leads when you pull it, obviously, is that you have no reason to believe that anything you experience is real. There's no reason to make any correlation between reality and your experience at all.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Generative adversarial networks, we all are. -me in a yoda voice.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Proving that almost everything creative is derivative of things we've seen or experienced.\n\nAnd while I feel that companies should compensate artists that use art to train AI, I don't think it should be forbidden. Frankly, if I was an artist that was really good at replicating a style of art (not requiring compensation to original artist), I'd love to be paid for my art to train an AI to emulate or integrate that style. \n\nBottom line though, is that the best art will likely require input from a person, making it a collaborative tool.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Our perception of reality is like a constantly updated simulation generated by our brains, influenced by predictive processing and the goal of minimizing prediction errors, as supported by concepts such as the Free Energy Principle.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Exactly what I have been saying for years. See https://theintermind.com/#ConsciousLightScreen",
            "score": 2,
            "replies": [
                {
                    "level": 1,
                    "comment": "Nice, a lot to unpack here. I will give it a read. Thanks for sharing!",
                    "score": 2
                }
            ]
        },
        {
            "level": 0,
            "comment": "This is *partly* what [Plato's cave](https://en.wikipedia.org/wiki/Allegory_of_the_cave) allegory is about.  Or later, what Immanual Kant meant when he wrote about the *Ding an sich (*\"[Thing-in-itself](https://en.wikipedia.org/wiki/Thing-in-itself)\").  It's a pretty well-worn topic in philosophy, psychology, and neurology.\n\n&gt;the difference between its expectations and the actual sensory information it receives\n\nThis is called [cognitive dissonance](https://en.wikipedia.org/wiki/Cognitive_dissonance) in psychology.",
            "score": 4
        },
        {
            "level": 0,
            "comment": "You have a poor understanding of generative AI. It's a very primitive, preliminary step toward real AGI",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Fun fact, when steam power was invented, it was theorised our brains worked a lot like steam engines, hence the phrase \"letting off steam\"!\n\nBefore that when hydraulics were the new thing, our brain must work like the most advanced tech of the day, hence doctors of the day trying to \"balance your humours\"!\n\nWith the invention of the telephone and switchboard, it was theorised that no, our brains are more like a switchboard routing signals!\n\nAnd then when the computer was invented it was theorised our brains actually worked a lot like that, and just did \"information processing\" with neurons acting as complicated transistors!\n\nWith quantum theory development, it was theorised that our brain actually works as a quantum processor, and because quantum mechanics makes no sense, this in some way explains how wacky consciousness is! (waves hands vaguely in the air)\n\nI think you can see where this is going...\n\nIn 2023 with the rise of the newest tech of the day, LLM's, it was theorised that our brains actually work a lot like them and just predict the next likely word in a sequence!\n\n\nIn 2060 with the rise of [next technology] it will be theorised that, wouldn't you believe it, our brains actually work just like [next technology]",
            "score": 4,
            "replies": [
                {
                    "level": 1,
                    "comment": "History repeats!",
                    "score": 1
                },
                {
                    "level": 1,
                    "comment": "You have a good point, and also, all of those technologies you listed weren't anywhere close to reliably being able to convince other humans that it is a human. Like, this is clearly a different galaxy from those other technologies you listed. I hope that's apparent.",
                    "score": 1,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No doubt LLMs appear human, just like the hydraulic automatons did 1000 years ago. It's always tempting to think this time really is different when looking at history.It seems pretty obvious we are in a hype bubble with predictions of AGI just years away (again). The thing with being in a hype bubble is the hype really does feel true.\n\nAs an aside I think quantum theory is actually more advanced than anything we have done with AI (if there was a civilisation tech tree).",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "As a clarification: I should say I about 95% agree with you, but that 5% is a big 5%. In that, AI can act like a human and talk like one. Talk to [Pi \\(with voice on\\)](https://heypi.com/talk) and compare that to hydraulics. \n\nAlthough, I didn't really include the comparison to quantum theory in my head because I don't understand QP enough to relate it to how humans think.",
                                    "score": 1
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Omg, people need to stop overhyping LLMs.",
            "score": 4
        },
        {
            "level": 0,
            "comment": "I thought I was the only one thinking about this, nice to know I'm not the only external agent in this simulation",
            "score": 2
        },
        {
            "level": 0,
            "comment": "This is the same reason that photographs aren\u2019t necessarily what the world actually looked like, especially older photographs.  They are an interpretation of what they are showing filtered through the technology of the day. \n\nWhen we see old photographs of historical people, we actually can\u2019t claim that\u2019s exactly how they looked.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "Imagine without wearing the VR you would be in a completely sensory-dark world. No light, no sound, no smell, no taste, no feeling. \n\nTo be able to move through this world we would be totally dependent on the sensory input that is created by the VR headset.\n\nNow, imagine wearing this car headset in your own house. You would bump into walls, furniture, etc., bc the sensory input from the VR headset does not correlate with the real world. \n\nNow imagine that our brain functions as a VR headset, just like OP wrote. We are convinced that what we experience through our sensory input, is the real world, bc we can\u2019t take the VR headset off. It is part of our body, and we\u2019re totally depending on it, from the moment we were born. \n\nBut is it reality? Or just part of reality, that part that we can experience through sensory input? What would the rest of reality that lies outside the scope of our perception look like? \n\nSuddenly ghosts, God, angels, demons and whatever other entities that exist outside our range of sensory perception, might be real. Reality might en that we are living and moving among them, like in a dark world. We just don\u2019t know it. We stumble on them all the time, like we would stumble over out furniture in a dark room, we just don\u2019t feel it, bc they are outside out VR headset, and thus outside our perception.",
            "score": 2,
            "replies": [
                {
                    "level": 1,
                    "comment": "\"Suddenly ghosts, God, angels, demons and whatever other entities that exist outside our range of sensory perception, might be real. Reality might en that we are living and moving among them, like in a dark world. We just don\u2019t know it. We stumble on them all the time, like we would stumble over out furniture in a dark room\" \n\nthis is a kind of good summary, that's how i imagine it could be.",
                    "score": 0
                }
            ]
        },
        {
            "level": 0,
            "comment": "Jesus Christ this sub fucking sucks.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "We all have a blind spot in central vision for the optic nerve (fingers together trick), we all routinely ignore unexpected stimuli, we all sometimes see things that aren't really there, we pay attention to  just thing at a time (gorilla experiment). And then there are the examples in Oliver Sachs' books.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "This is a limited way to understand the human mind. Yes the brain is virtual reality simulator and is still probably among the best in the world. And at this point for me the distinction between brain and mind get blurred so i ll say \"brainmind\". The brainmind does more than simulate reality, the brainmind can generate never-before-imagined artifacts that can be used to change reality in favorable way. This is a useful way to encapsulates AGI better than most descriptions you ll see.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "I am glad I\u2019ve found someone who thinks like me. AI can and will think just like us one day, and then, we\u2019ll have to treat them as equals or face a r/terminator",
            "score": 1
        },
        {
            "level": 0,
            "comment": "We don't even know how our brain is doing much of what it does yet. So, hard to agree.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "I've adopted prompting as a useful tool for myself. If you keep telling yourself something, it changes the way you think, react, and perceive the world. Literally thinking to yourself, \"I'm a hardworking, motivated, determined person who doesn't give up,\" will actually make you that after a while. It's much slower for your brain to correct itself because it has a very strong ingrained identity, but over time, it will change. I've picked up a lot of mental tricks from messing around with AI and it's taught me how to be a more productive and successful person.\n\n\"If I was an expert at .... how would I approach this?\"\n\nThat call and response way of thinking, which I've been doing all my life, and even more so now has worked wonders for me. It's not about knowing all the answers innately it's about asking yourself the right questions and framing your experience in a way that makes it easier to navigate.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "I have been thinking recently how similar we may be to LLM's. We take in sensory information, touch, taste, smell, vision, hearing, process it through a bunch of parameters and then output that in a variety of ways (muscle movements, thoughts etc.).",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Interesting that the only higher intelligence species is also the only one which has language.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "OP's a stoner for sure",
            "score": 1
        },
        {
            "level": 0,
            "comment": "What is real, how do you define real? If you're talking about what you can see hear feel touch or taste then real is simply electrical impulses interpreted by the brain.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Somebody else's problem.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Our perceptions also evolved to help keep us alive and do not necessarily show us objective reality as it really is.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "All those things you see with your eyes aren\u2019t actually happening. It takes time for light to reach your eyes, which means, the only information your senses can perceive is related to things that happened in the past.\n\nIn the present moment there is only awareness, and the accumulation of information gathered in the past by all things that are aware (all things are aware, but not self-aware).\n\nThe future is this whole other thing. It\u2019s this infinite thing. Each instant of the past was part of the future before turning into the past, but the future is not depleted. It\u2019s still infinite. In the beginning, before there was a past, all things were contained within the future.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "Wait, so how do you get from your first sentence to the rest of your post? How has generative ai helped you understand how our brains work?",
            "score": 1
        },
        {
            "level": 0,
            "comment": "The interesting thing about AI is that we can in certain way analyze ourselves from an external perspective, like, if at some point ai get to a point where it experience its external reality in a similar way to how we experience ours, it would help significantly to comprehend the path of our own develop from the beginning of our specie.",
            "score": 1
        },
        {
            "level": 0,
            "comment": "You don't really know anything bruv \n\nCute post tho",
            "score": -2
        },
        {
            "level": 0,
            "comment": "[deleted]",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "It's been known in religion and philosophy for centuries, and recently in neuroscience and psychology but that recent is also a decade old.\n\nIt's nothing new, whereas generative ais have only paced in the last 3-4 years.\n\nyou can ask the same to gpt4 and can confirm if you phrase your question correctly in the context of this post.",
                    "score": 1
                }
            ]
        }
    ]
}