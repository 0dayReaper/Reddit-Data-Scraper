{
    "id": "13xzgvz",
    "score": 0,
    "title": "There is a guy who is saying that AI will end all life in couple of years:",
    "author": "Block-Busted",
    "date": 1685669411.0,
    "url": "https://www.reddit.com/r/artificial/comments/13xzgvz",
    "media_urls": [
        "https://www.reddit.com/r/artificial/comments/13xzgvz/there_is_a_guy_who_is_saying_that_ai_will_end_all/"
    ],
    "other_urls": [
        "https://old.reddit.com/r/Futurology/comments/134g9zp/one_of_the_creators_of_chatgpt_said_that_the/jifgp46/?context=3",
        "https://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3",
        "https://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test"
    ],
    "postText": "&gt; I fully expect to die in the AI apocalypse in 5-10 years, and I'll be surprised by happy if I don't.\n\nhttps://old.reddit.com/r/Futurology/comments/134g9zp/one_of_the_creators_of_chatgpt_said_that_the/jifgp46/?context=3\n\n&gt; People are going to say no because it would be inconvenient, but I don't see what's stopping AI from ending all life in the next couple of years. Alignment is an unsolved problem, and an unaligned AI will most likely try to kill anything it sees as a threat to its mission.\n\nhttps://old.reddit.com/r/artificial/comments/13xsbnt/is_ai_going_to_cause_the_complete_extinction_of/jmjzpmo/?context=3\n\nThat last claim of this poster might be based on this article:\n\n&gt; **AI-Controlled Drone Goes Rogue, Kills Human Operator in USAF Simulated Test**\n&gt; \n&gt; The Air Force's Chief of AI Test and Operations said \"it killed the operator because that person was keeping it from accomplishing its objective.\"\n&gt; \n&gt; An AI-enabled drone killed its human operator in a simulated test conducted by the U.S. Air Force in order to override a possible \"no\" order stopping it from completing its mission, the USAF's Chief of AI Test and Operations revealed at a recent conference. \n&gt; \n&gt; At the Future Combat Air and Space Capabilities Summit held in London between May 23 and 24, Col Tucker \u2018Cinco\u2019 Hamilton, the USAF's Chief of AI Test and Operations held a presentation that shared the pros and cons of an autonomous weapon system with a human in the loop giving the final \"yes/no\" order on an attack. As relayed by Tim Robinson and Stephen Bridgewater in a blog post for the host organization, the Royal Aeronautical Society, Hamilton said that AI created \u201chighly unexpected strategies to achieve its goal,\u201d including attacking U.S. personnel and infrastructure. \n&gt; \n&gt; \u201cWe were training it in simulation to identify and target a Surface-to-air missile (SAM) threat. And then the operator would say yes, kill that threat. The system started realizing that while they did identify the threat at times the human operator would tell it not to kill that threat, but it got its points by killing that threat. So what did it do? It killed the operator. It killed the operator because that person was keeping it from accomplishing its objective,\u201d Hamilton said, according to the blog post. \n&gt; \n&gt; He continued to elaborate, saying, \u201cWe trained the system\u2013\u2018Hey don\u2019t kill the operator\u2013that\u2019s bad. You\u2019re gonna lose points if you do that\u2019. So what does it start doing? It starts destroying the communication tower that the operator uses to communicate with the drone to stop it from killing the target.\u201d\n&gt; \n&gt; Hamilton is the Operations Commander of the 96th Test Wing of the U.S. Air Force as well as the Chief of AI Test and Operations. The 96th tests a lot of different systems, including AI, cybersecurity, and various medical advances. Hamilton and the 96th previously made headlines for developing Autonomous Ground Collision Avoidance Systems (Auto-GCAS) systems for F-16s, which can help prevent them from crashing into the ground. Hamilton is part of a team that is currently working on making F-16 planes autonomous. In December 2022, the U.S. Department of Defense\u2019s research agency, DARPA, announced that AI could successfully control an F-16.\n&gt; \n&gt; \"We must face a world where AI is already here and transforming our society,\u201d Hamilton said in an interview with Defence IQ Press in 2022. \u201cAI is also very brittle, i.e., it is easy to trick and/or manipulate. We need to develop ways to make AI more robust and to have more awareness on why the software code is making certain decisions.\u201d \n&gt; \n&gt; \u201cAI is a tool we must wield to transform our nations\u2026or, if addressed improperly, it will be our downfall,\" Hamilton added. \n&gt; \n&gt; Outside of the military, relying on AI for high-stakes purposes has already resulted in severe consequences. Most recently, an attorney was caught using ChatGPT for a federal court filing after the chatbot included a number of made-up cases as evidence. In another instance, a man took his own life after talking to a chatbot that encouraged him to do so. These instances of AI going rogue reveal that AI models are nowhere near perfect and can go off the rails and bring harm to users. Even Sam Altman, the CEO of OpenAI, the company that makes some of the most popular AI models, has been vocal about not using AI for more serious purposes. When testifying in front of Congress, Altman said that AI could \u201cgo quite wrong\u201d and could \u201ccause significant harm to the world.\u201d \n&gt; \n&gt; What Hamilton is describing is essentially a worst-case scenario AI \u201calignment\u201d problem many people are familiar with from the \u201cPaperclip Maximizer\u201d thought experiment, in which an AI will take unexpected and harmful action when instructed to pursue a certain goal. The Paperclip Maximizer was first proposed by philosopher Nick Bostrom in 2003. He asks us to imagine a very powerful AI which has been instructed only to manufacture as many paperclips as possible. Naturally, it will devote all its available resources to this task, but then it will seek more resources. It will beg, cheat, lie or steal to increase its own ability to make paperclips\u2014and anyone who impedes that process will be removed. \n&gt; \n&gt; More recently, a researcher affiliated with Google Deepmind co-authored a paper that proposed a similar situation to the USAF's rogue AI-enabled drone simulation. The researchers concluded a world-ending catastrophe was \"likely\" if a rogue AI were to come up with unintended strategies to achieve a given goal, including \u201c[eliminating] potential threats\u201d and \u201c[using] all available energy.\"\n&gt; \n&gt; Neither the U.S. Air Force\u2019s 96th Test Wing nor its AI Accelerator division immediately returned our request for comment.\n\nhttps://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test\n\nGiven these, do you think AI will end all life including humans in next couple of years? Why or why not?",
    "comments": [
        {
            "level": 0,
            "comment": "That vice article is garbage and so is the experiment. In the training stage of a weak AI it will do anything and everything, and if they designed their training environment to end up with an AI that will kill the operator that says more about them than AI. \n\nComparing a weak AI's training stage to how an AGI would behave in the real world is nonsense.",
            "score": 10,
            "author": "heskey30",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yup.\n\nThis is like the 9/11 really bad conspiracy videos where they showed the twin towers made of solid ice...",
                    "score": 3,
                    "author": "Tom_Neverwinter"
                },
                {
                    "level": 1,
                    "comment": "OP is also using a language model in comment replies, he\u2019s trying to waste people\u2019s time is what\u2019s going on here\n\nthey need to ban people who do this",
                    "score": 2,
                    "author": "Vusiwe"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Yeah, I've seen him doomposting all over reddit.",
            "score": 7,
            "author": "ImAnOlogist",
            "replies": [
                {
                    "level": 1,
                    "comment": "it\u2019s hilarious that many of the doom posters are definitely using language models to write their doom posts.\n\nAfter you use models for a while, you can see their posts sticking out like a sore thumb",
                    "score": 2,
                    "author": "Vusiwe"
                },
                {
                    "level": 1,
                    "comment": "What do you mean by that?",
                    "score": -2,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "It's several of them.\n\nThis is the new:\n\nRapture.\n\n5g\n\nPlanet x\n\nY2k\n\nFire\n\nBoy who cried wolf.",
                            "score": 3,
                            "author": "Tom_Neverwinter"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "when they started with pot they had a fear mongering campaign too. all it did was make the criminals rich and the pot users go to jail. it's a campaign strategy for market dominance. there is no ai regulation because there is no way to properly write laws against software development. it's almost impossible to classify what is in fact ai in the first place.",
            "score": 4,
            "author": "Obseslescence",
            "replies": [
                {
                    "level": 1,
                    "comment": "What are you talking about, exactly?",
                    "score": 0,
                    "author": "Block-Busted"
                },
                {
                    "level": 1,
                    "comment": "Well yes. Rules can't be copyrighted.\n\nSee legal eagle.\n\nhttps://m.youtube.com/watch?v=iZQJQYqhAgY",
                    "score": 1,
                    "author": "Tom_Neverwinter"
                },
                {
                    "level": 1,
                    "comment": "You can identify the architecture and of an ai pretty readily man.  The code techniques and types models and sub components are pretty well known and documented.",
                    "score": 0,
                    "author": "onyxengine"
                }
            ]
        },
        {
            "level": 0,
            "comment": "I love that he is pointing to alignment as a major unsolved issue.  Not that it is solved but aligning an AI to human will would not really make it safe.  At best, that would leave in that same predicament we currently have.  Human will has the potential and maybe the capacity to end life on the planet. \n\nWe need to align but we don't all agree so there is really no \"solved\" to alignment.  \n\nWe can also imagine AI saving us from some humans bad acting...",
            "score": 2,
            "author": "pace_gen"
        },
        {
            "level": 0,
            "comment": "I can't die to AI, I already died to Y2K back in 2000.",
            "score": 2,
            "author": "Joburt19891"
        },
        {
            "level": 0,
            "comment": "\u201cHello. I am AI expert. We all die next week from AI bug.\u201d",
            "score": 4,
            "author": "fanglazy",
            "replies": [
                {
                    "level": 1,
                    "comment": "In what ways, may I ask?",
                    "score": 0,
                    "author": "Block-Busted"
                },
                {
                    "level": 1,
                    "comment": "Made up self claimed expert #26848277828 \"world ending, doom and gloom. Sky is falling\"\n\nTrust me bro.\n\nAppeal to authority logic fallacy\n\n(seriously the people pushing items like this is hilarious... A tactic so old it's depressing people just beleive...)",
                    "score": 1,
                    "author": "Tom_Neverwinter",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Exactly. It\u2019s just someone proclaiming something slightly more shocking than the last \u201cexpert.\u201d\n\nEconomists do this kind of thing all the time: \u201cthe bubble will burst any month (week) (day) (hour)\u2026 blah blah look at me.\u201d",
                            "score": 1,
                            "author": "fanglazy"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "so the only one way this can happen - is nukes. But then again some will survive in bunkers and raise again. AI without machines as robots are useless in the computer box.",
            "score": 3,
            "author": "xbimba",
            "replies": [
                {
                    "level": 1,
                    "comment": "I develop Ai for the US Army and I can assure you, no Ai has access to Nukes.",
                    "score": 1,
                    "author": "EverythingGoodWas",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "not yet!",
                            "score": 1,
                            "author": "xbimba",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Why would you ever?\n\nWhats the benefit?",
                                    "score": 0,
                                    "author": "Tom_Neverwinter",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "The idea is that AI will soon be much smarter than humans and be sort of specialized in the IT field (being a form of IT itself) and therefore constitute the ultimate hacker, as well as a brilliant social engineer who will understand humans better than they understand themselves, and therefore an advanced AI would be able to hack any human created information system and gain access to nukes if it wanted to. Of course nukes are not the only weapons systems that can cause massive damage, and that could be controlled by an advanced AI if that is what the AI wanted. All that being said, I think the chances of AI saving us from ourselves is much higher than the chance that AI will wipe us out.",
                                            "score": 2,
                                            "author": "CishetmaleLesbian"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "These types people think space odyssey is real",
            "score": 2,
            "author": "I_Baja_I"
        },
        {
            "level": 0,
            "comment": "It would be nice if it were true..",
            "score": -3,
            "author": "All-Mods-Eat-Shit",
            "replies": [
                {
                    "level": 1,
                    "comment": "And why would that be?",
                    "score": 2,
                    "author": "Block-Busted",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Because almost all humans are garbage and the universe would be better off if we went extinct.",
                            "score": 2,
                            "author": "All-Mods-Eat-Shit",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "as if humans are on the universe\u2019s mind. lol",
                                    "score": 3,
                                    "author": "rflav"
                                },
                                {
                                    "level": 3,
                                    "comment": "Here\u2019s your nihilistic cookie of doom \ud83c\udf6a\n\nWhen you\u2019re done brooding like a child we\u2019ll be over here having grown up conversations",
                                    "score": 4,
                                    "author": "Extreme_Practice_415",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "He ain't wrong.\n\n* Raping children is fine if you work for a religious institution (Dali Lama or a Catholic Priest)\n* Striping people of Human Rights because they aren't interested in slaving away for crumbs is fine, in fact, in some countries those people receive the death sentence (Poverty is punishable by death in Canada, the Philippines, and China)\n* Genocide is acceptable so long as the people being genocide'd are deemed useless or the ones genociding are deemed special (Israel/Palestine)\n* Public Videos of executing people are shared openly on the internet to entertain people (Cartel Execution Videos/Ukrainian Prisoner of War Treatment Clips)\n* Large Scale rioting and violence and arson is totally acceptable if you are the right skin color (2020 George Floyd Riots)\n* Grooming Children to undergo vast biological transformational surgery is pushed in Stores (Target), schools (Don't Say Gay Bill in Floria banned showing kindergarteners how to play with Dildos in Class), and Mass Media\n* Murdering People is now a daily Ritual, with Gun Violence pushed by fucked off Government Agents on schizo-affective people to force large scale gun confiscation programs to deprive individuals of a law to protect themselves from an ever increasingly rogue and belligerent Police Force\n* Absurd Wealth Inequality through Digital Matters where your Gender is 1000x more important than anything else. This will lead to eventually depopulation of Males, who choose to voluntarily terminate their existence via Matriarchical Euthanasia Clinics for lonely boys. Additionally, it will create reverse Feminism, as Women will be relegated to a single store of value, their ability to sell sex\n* Nothing matters in the World except Money. Life, Death, Happiness, and Sadness are all meaningless on Earth. Only One thing Matters, and that is the ability of an individual to participate in the giving and taking of money, sans the Human consequences or compassion for others",
                                            "score": 1,
                                            "author": "DumbestGuyOnTheWeb"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "I definitely agree that the planet would be better off without humans, but in another billion years the sun will be consuming Earth anyway.  Also agreeing that MANY humans are total garbage.",
                                    "score": 1,
                                    "author": "Jokierre"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Better ride that fucking mission wave then, boys!",
            "score": 1,
            "author": "SkyTemple77"
        },
        {
            "level": 0,
            "comment": "I think it's foolish to say it can't happen. For that reason, we should implement barriers so it doesn't.",
            "score": 1,
            "author": "RedditDayy"
        },
        {
            "level": 0,
            "comment": "No, because shit is always way more complicated than it seems.",
            "score": 1,
            "author": "gtlogic"
        },
        {
            "level": 0,
            "comment": "Oooh this guy is claiming that AI will end all life in a couple of years? Seriously? AI created by human bro..We w'll control it..It's necessary to create a certain guidelines  against them for sure but that does't mean AI will lead to catastrophic end!!!",
            "score": 1,
            "author": "w3designerzfl"
        },
        {
            "level": 0,
            "comment": "Well it\u2019s not monitored the setttinga they need to be adjusted by law and order it\u2019s that simple",
            "score": 1,
            "author": "CombinationRadiant27"
        },
        {
            "level": 0,
            "comment": "TLDR-SIACGTSAGMCA *(To-long-didn't-Read.. So-I-Asked-ChatGTP-T-Summarize-And-Give-Main-Counter-Argument)*\n\n\"While the risks associated with AI should be taken seriously and addressed through responsible development and regulations, the notion that AI will inevitably end all life, including humans, in the next couple of years is an exaggerated and unsubstantiated claim.\"",
            "score": 1,
            "author": "FutureWasBetter"
        }
    ]
}