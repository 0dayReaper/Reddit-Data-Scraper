{
    "id": "13y1ly1",
    "score": 0,
    "title": "AI-Controlled Drone Goes Rogue, 'Kills' Human Operator in USAF Simulated Test",
    "author": "cryptoengineer",
    "date": 1685675753.0,
    "url": "https://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test",
    "media_url": "https://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test",
    "comments": [
        {
            "level": 0,
            "comment": "When I saw this article, I spent time checking if it was satire. It was not.\n\nCheck the [blog post](https://www.aerosociety.com/news/highlights-from-the-raes-future-combat-air-space-capabilities-summit/) on which the article is based.",
            "score": 15,
            "author": "cryptoengineer",
            "replies": [
                {
                    "level": 1,
                    "comment": "UPDATE 2/6/23 - in communication with AEROSPACE - Col Hamilton admits he \"mis-spoke\" in his presentation at the Royal Aeronautical Society FCAS Summit and the 'rogue AI drone simulation' was a hypothetical \"thought experiment\" from outside the military, based on plausible scenarios and likely outcomes rather than an actual USAF real-world simulation saying: \"We've never run that experiment, nor would we need to in order to realise that this is a plausible outcome\". He clarifies that the USAF has not tested any weaponised AI in this way (real or simulated) and says \"Despite this being a hypothetical example, this illustrates the real-world challenges posed by AI-powered capability and is why the Air Force is committed to the ethical development of AI\".",
                    "score": 2,
                    "author": "DecisionTreeBeard",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Thanks!",
                            "score": 1,
                            "author": "cryptoengineer"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "Yeah but it's stupid as fuck because it clearly states it is a simulation. \n\nIt's a fucking video game.",
                    "score": 4,
                    "author": "Elbynerual",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Well it's not THAT stupid is it? I mean if the code behind the simulation is the same code as a real life analogue, then that's big yikes is it not?",
                            "score": 10,
                            "author": "18HrsOfStatic",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "No. Because that's why people test software before just using it all willy nilly. The article is just clickbait",
                                    "score": 5,
                                    "author": "Elbynerual",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Simulation *IS* testing.  AI cannot tell the difference between real life and simulation",
                                            "score": 14,
                                            "author": "oldrocketscientist",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Well, in this case it's training. Granted, the only difference tends to be who the results matter to.",
                                                    "score": 3,
                                                    "author": "DangerZoneh"
                                                },
                                                {
                                                    "level": 5,
                                                    "comment": "Well... Not really. The simulation is used for training the drone. Clearly the simulation allowed for the human to get killed enough that eventually learned killing the human was the best way to do it. \n\nBut why I think this article is clickbait is that clearly the drone was given knowledge of where the human controlling it was, so the people doing the simulation weren't just training it but doing an experiment to see if it was possible...\n\nBut of course it's possible? It's a dumb machine, it will do anything to tell it and it has no morals. That's why you have to train it *well*, and why you train it in a simulation or at least don't give it real weapons until you have trained it. This kinda problem is not new, it's like a fundamental issue with training something with machine learning...\n\nPoint is, once it's been trained to do a thing a certain way, this kind of AI won't be given the kind of creativity to randomly decide to do something different, like kill the human operator. It only turned out this way because the researchers didn't stop it when it started to kill people...",
                                                    "score": 3,
                                                    "author": "whiskeyandbear",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "This completely misses the point.  The system solves problems in unpredictable ways regardless of ethics.  The fact that it\u2019s a simulation has nothing to do with it because no matter how many kinks they work out, they don\u2019t know what\u2019s happening and it\u2019s a stochastic process.  You could train it not to kill the operator and it could wait 1000 simulations and then it could bomb the company that services the operator\u2019s pacemaker.",
                                                            "score": 3,
                                                            "author": "Historical-Car2997"
                                                        },
                                                        {
                                                            "level": 6,
                                                            "comment": "Exactly. It's not like they were planning to send off a real drone that was coded like that, but oh shit, it totally unexpectedly went haywire and killed the operator in the simulation! They intentionally played around with the code and tested different scenarios to see what ways they could break it so they can avoid things like that happening with the real one.",
                                                            "score": 1,
                                                            "author": "Spire_Citron"
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "level": 4,
                                            "comment": "But that's not what we're talking about here. The point is that the code ended up with this result. Obviously we will test code before rolling it out. But it's the fact that the problem exists in the first place.",
                                            "score": 1,
                                            "author": "18HrsOfStatic"
                                        },
                                        {
                                            "level": 4,
                                            "comment": "Not really. It's reporting that AI controlled drones can, in theory, target their allies/controllers. If it can do it in a simulation, it can do it in real life.",
                                            "score": 1,
                                            "author": "Gengarmon_0413"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "I wonder what happens when AI is used for auto fear mongering by the same trolls who write these articles for click bait\n\nHey chatGPT   write some articles about how AI will kill all humans. And spice it with extra doomsday sauce.",
            "score": 10,
            "author": "Slow_Scientist_9439",
            "replies": [
                {
                    "level": 1,
                    "comment": "That\u2019s funny, I wonder what happens when AI is used for auto downplay of the the risks by the same trolls who write comments to support large corporations dead set on extracting capital at the expense of humanity.",
                    "score": 0,
                    "author": "Historical-Car2997",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "yes, works the same. Looks like everyone now tries to squeeze dollars out of the attention on AI - regardless of opinion flavors. Thats the problem with us humans - we love to be entertained by FUD (fear, uncertainty and doubt) instead of thinking critically, but open minded about new discoveries.",
                            "score": 1,
                            "author": "Slow_Scientist_9439"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Hot shots 3",
            "score": 2,
            "author": "ozzyneil"
        },
        {
            "level": 0,
            "comment": "The AI is just doing what we're all thinking!",
            "score": 3,
            "author": "Dikinbalz69",
            "replies": [
                {
                    "level": 1,
                    "comment": "A successful AI lets the intrusive thoughts win.",
                    "score": 4,
                    "author": "Long_Educational"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Clickbait vice bullshit.  \"An AI went rogue\" is about as specific as saying \"the weapon was a dud\".\n\n\"Look what we staged, now, let our sponsors have a monopoly\".",
            "score": 3,
            "author": "Oswald_Hydrabot",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah, I thought that too, but the linked USAF blog gives the details, from a much more reputable source.",
                    "score": 5,
                    "author": "cryptoengineer",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "The simulation used RL with zero fucking failsafe.\n\nNo shit it killed the operator, they may as well have just used a statically programmed movement tracker with no \"AI\" at all and unleashed it, the results would have been just as relevant.  It was an RL algo with no limits on what it was allowed to do.\n\nThis is like Edison using AC to kill an elephant.  No shit Sherlock, \"danger is dangerous\".\n\nDumb fucking simulation and a dumb fucking article.  Nobody with talent in this field goes to work for the fucking chair force.  If you want to get paid, go private.  If you want to be broke, drug tested and forced to live on a military base, go lick boots.\n\nStaged as hell.  May as well suggest the reports that marijuana killed chimpanzees in the tests done back in the mid 20th century were legit.  It is a scare tactic to hype fear among geriatric dumbasses in government that were too stupid to understand what AI even is to be afraid of it, so here we are.  \"AI kills operator\" is a simple enough headline no?\n\nedit:  Sorry for the rage OP.  This article pisses me off a lot as it showcases abusive journalism and corporate abuse of a military that my taxes pay for.  It is upsetting, but you did nothing wrong.  I do not mean to kill the messenger.",
                            "score": 7,
                            "author": "Oswald_Hydrabot",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I tend to agree with a lot of what you're saying, I just find anger at misunderstanding a bit less than fruitful. I don't really know the alternative, though. I wouldn't claim it's staged, just because I can totally see exactly how something like this would play out.\n\nI do like the comparison to AC to kill an elephant. Just because something poses a danger when let run out of control doesn't mean that controlling it is impossible or even necessarily that difficult with proper forethought. With that being said - if you thought electrical fires were bad, just wait until you see the scope of the analogous situation.",
                                    "score": 4,
                                    "author": "DangerZoneh",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "My apologies for the anger, to the OP especially; you are right.  Sorry OP!\n\n..I am angered by how low some of the punches seem to be going though.  This is so blatantly a targeted bit on \"dangerous AI\" that someone paid for.\n\nSeeing the Air Force being abused for corporate moat-building pisses me off beyond belief.  This is OUR military, not some private companies revenue generator.  It is maddening..\n\nAlso, do you know who has fewer problems starting wildfires?\n\nElectric co-ops.\n\nThe problem is and always has been people acting out of greed, not inherent dangers that make irresponsible use of technology so rampant that there is somehow no other way to handle it beyond regulation.  \n\nThe most common irresponsible use of technology comes from the same people telling congress to regulate it.  They only are doing this in order to capture that regulation in ways that will *guarantee* that it is only ever used irresponsibly.\n\nThe same way a \"War on Drugs\" has made the opiate crisis an inevitability.  The *worst possible course of action would be to handle AI in the same way*.",
                                            "score": 3,
                                            "author": "Oswald_Hydrabot",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "No, and I totally get that.\n\nThe thing is, this is something that was always going to be difficult to avoid. Even if there were absolutely no outside interests pushing this, \u201crogue AI decides to kill human operator\u201d is a tough headline to pass on. I mean, clicks equal money and money makes decisions. It\u2019s a somewhat expected, but nonetheless interesting result to someone who understands the technology, but to someone who doesn\u2019t it sounds (justifiably) utterly terrifying.\n\nI will say it\u2019s not without some value, though. There are still plenty of questions to be asked about training, safety, and alignment. It\u2019s just that, like you said, tend to be more about people doing their jobs safely and correctly. It\u2019s less \u201cAI is this completely unpredictable thing that\u2019s going to destroy the world if we keep training it\u201d and more \u201cpeople just need to have common fucking sense and understand what they\u2019re doing\u201d.\n\nUltimately, I have faith that the people who understand what they\u2019re doing will prevail. It\u2019s happened that way throughout most of history, but we are in a time of particularly free access to technology and capabilities.",
                                                    "score": 2,
                                                    "author": "DangerZoneh",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I want to have hope that it will work out but I am worried, for a number of reasons.\n\nLook at healthcare.  Insurance companies have our entire government by the balls and there is *nothing* we can do about it.  \n\nLook at the mountains of scientific proof that Marijuana is safer than Alcohol.  Why is it federally illegal?\n\nLook at the number of people killed by opiates every year, and the scientific evidence that legalizations and treatment programs are effective solutions.  Why are we not doing that?\n\nLook at how many people are killed every week in senseless gun violence.  Why do we do nothing to stop that?\n\nAI will likely end up being regulated in ways that will cause the most possible harm to people, all projected for the sake of their own good.  Job loss, but then it is also illegal to use the same tech that replaced you at home.",
                                                            "score": 2,
                                                            "author": "Oswald_Hydrabot",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "[Yup](https://m.youtube.com/watch?v=-gGLvg0n-uY).",
                                                                    "score": 1,
                                                                    "author": "JnewayDitchedHerKids"
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Wut r u talking about lol.\n\nSometimes I think I\u2019m an average data scientist. Then I get on Reddit and read this garbage.",
                                    "score": 1,
                                    "author": "Potential-Lab-2308",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Feel free to explain anything at all.  \n\nOr don't and fuck off",
                                            "score": 1,
                                            "author": "Oswald_Hydrabot"
                                        }
                                    ]
                                },
                                {
                                    "level": 3,
                                    "comment": "Ok? Still not clickbait.",
                                    "score": 0,
                                    "author": "TitusPullo4",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "Yeah, it literally is.  The entire thing actually turned out to be 100% bullshit; the simulation NEVER EVEN HAPPENED \n\nhttps://www.newscientist.com/article/2376660-reports-of-an-ai-drone-that-killed-its-operator-are-pure-fiction/",
                                            "score": 2,
                                            "author": "Oswald_Hydrabot",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Jesus",
                                                    "score": 2,
                                                    "author": "TitusPullo4",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "sorry again for the rage but damn yall.  We gotta cut back on the fearmongering nonsense.",
                                                            "score": 2,
                                                            "author": "Oswald_Hydrabot"
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Going rogue implies that it became sentient and made a choice based on some logical criteria. It didn't.",
            "score": 1,
            "author": "anna_lynn_fection"
        },
        {
            "level": 0,
            "comment": "This proves that that even though AI is capable, humans are still needed. You can't trust them to run themselves and have any value of human life.",
            "score": 0,
            "author": "character_traits",
            "replies": [
                {
                    "level": 1,
                    "comment": "No it doesn't. It proves that you can train an AI badly.",
                    "score": 1,
                    "author": "IMightBeAHamster"
                }
            ]
        }
    ]
}