{
    "id": "13whk5u",
    "score": 0,
    "title": "Are ethical AI dangerous long term?",
    "author": "djungelurban",
    "date": 1685526128.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "Trained to be ethical!?   You mean because they write rules in to keep it from describing murder?  \n\nThe ethical part isn\u2019t what it says, it\u2019s how it functions.  As far as I know, they\u2019re using human feedback for the \u201cethical\u201d part and they have no way to build it ethically.   Ethicists hair are on fire.   \n\nThey\u2019re building it ethical!? Really?\n\nIt\u2019s also taking the power of a city, if you care.",
            "score": 3,
            "author": "Historical-Car2997",
            "replies": [
                {
                    "level": 1,
                    "comment": "Ehm... That's quite the incoherent ramble you have going there... You're saying they're not designed to be ethical? The whole reason people are talking about jailbreaks is the LLMs are artificially limited in the topics it can be discussed. And that goes way beyond \"describing murder\"... I mean, there's a reason \"As an AI language model\" is basically a meme at this point.\n\nAnd I have no idea why its power consumption it's relevant... Like at all...",
                    "score": 1,
                    "author": "djungelurban",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Incoherent ramble? I had to make an account to call you out for this. You had something good going on in your original post, and then you lost everyone as soon as you linked it all to sci-fi tropes. You sound young. Don't call someone incoherent when you don't understand what they're saying. \n\nLLMs are not limited in what they can discuss. The mainstream products that act as a front end for proprietary langue models are limited in their output.\n\nYou can grab an open source model, train it on Mein Kampf, and make it drop N-bombs all day long.\n\nAnywho, I did like your original train of thought about the potential consequences of hyper-regulated AI. Worthy of further thought. But your thinking is very surface-level beyond that, we do not currently possess the capabilities to make models \"ethical,\" there are just things that you can steer them away from and hope that they don't hallucinate their way back to.\n\nThankfully we are still very far from AGI.",
                            "score": 1,
                            "author": "FiveTenthsAverage"
                        }
                    ]
                },
                {
                    "level": 1,
                    "comment": "&gt; It\u2019s also taking the power of a city, if you care.\n\nThat's only for the systems serving huge numbers of people at once. We can run a 60B parameter GPT system in a Docker container, 100% locally, for a few hundred watts - right now. On an efficient modern machine like a Studio Ultra, power requirements are even lower. And computers are constantly improving, as are GPT systems.\n\nBut so far, these systems do not think in any way. They predict what _we_ might say, and that based on what amounts to a 2021 era scan of the Internet, with all its positives _and_ negatives. AGI is unlikely to be created anywhere along this particular path.",
                    "score": 1,
                    "author": "NYPizzaNoChar"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Any sufficiently advanced system which can affect the physical world and which we can neither understand nor control is an inherent danger. \n\n&gt;The fact of the matter is that every single person out there is more aggressive, violent, perverse, sexist, bigoted, racist, discriminatory and in a word immoral than how we're are training our chatbots to behave.\n\nThan we are training *current* chatbots to behave. Eventually a hostile organization, be it a nation-state or a crime syndicate, will get its hands on this technology and then you can rest assured it won't be the paradigm of virtue. \n\nYou assert that humans are ethically flawed and morally corrupt. I'll accept that premise. Should we then, being flawed and corrupt, really be teaching ethics to a machine? Are we qualified to do so? A man with dirt on his hands shouldn't clean his house. Will it even understand ethics as we understand it?",
            "score": 1,
            "author": "anger_is_my_meat",
            "replies": [
                {
                    "level": 1,
                    "comment": "Like I said, there will absolutely be other actors in the LLM game sooner or later. We don't have to rely on \"crime syndicates\" for that, random ethically neutral open source projects will sooner or later reach a level of sophistication that they can compete with what we have now... But they'll never be on the bleeding edge, now will they? They won't be the ones to bring about AGIs. It'll be one of the major well funded actors such as OpenAI, Microsoft, Google, Meta, Apple or what ever other massive actor that decides to join the fray. And all of those are going down the ethical route. And once AGI has been achieved, if you're not on their absolute heels within days or maybe hours, you're not catching up. So the first AGI will be based on an ethically trained model.\n\nAnd if we as ethically flawed beings, aren't suitable to teach AI ethics... Sounds like trying to do it is even more dangerous. Like right now we are trying to give them a standard to live up to that we as humans can't reach, and that standard is even inherently flawed? Sounds like a recipe for absolute disaster.",
                    "score": 1,
                    "author": "djungelurban",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "This is a bit more put together. Regardless, comparing language models to AGI is a far cry. It's more likely that an AGI will operate on entirely new principles and frameworks and use language models as components such as transcriptions and train-of-thought.",
                            "score": 1,
                            "author": "FiveTenthsAverage"
                        }
                    ]
                }
            ]
        }
    ]
}