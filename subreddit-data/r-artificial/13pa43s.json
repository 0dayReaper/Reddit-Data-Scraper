{
    "id": "13pa43s",
    "score": 8,
    "title": "The next paradigm: The convoluted maze of abundant model choice, loop systems and the hopeful final solution",
    "author": "flexaplext",
    "date": 1684805659.0,
    "url": "https://www.reddit.com/r/artificial/comments/13pa43s",
    "media_urls": [
        "https://www.reddit.com/r/artificial/comments/13pa43s/the_next_paradigm_the_convoluted_maze_of_abundant/"
    ],
    "other_urls": [
        "https://youtu.be/BrjAt-wvEXI",
        "https://youtu.be/wVzuvf9D9BU"
    ],
    "postText": "**The next paradigm: The convoluted maze of abundant model choice, loop systems and the hopeful final solution.**\n\nI\u2019m going to be talking of things like these:  \n  \nhttps://youtu.be/BrjAt-wvEXI  \n(Tree of Thoughts - GPT-4 Reasoning is Improved 900% - Wes Roth)  \nhttps://youtu.be/wVzuvf9D9BU  \n(GPT 4 is Smarter than You Think: Introducing SmartGPT -  AI Explained)  \n\nGPT-4 is not the most accurate model, as some people still think. GPT-4 with this kind of pre-prompting and self-reflection is. I predicted this a while ago. I don\u2019t believe there\u2019s a name for these things yet, but I just call them \u201cloop systems\u201d. These loop systems are the most accurate models that we can possibly use right now. I can only foresee the meta staying this way as well. For people saying that OpenAI should change their base model to do this sort of thing if it gives more accurate results, that\u2019s not going to happen for reasons I will come on to.\n\nIt\u2019s alluded to in the SmartGPT video that there is so much more that could potentially be added to such a loop system. You could make more response calls, different prompts, more reflection. On top of this, you could also make API calls to other systems (like Wolfram alpha, calculators etc). You can also mess around with the different parameters in the model (like temperature etc). And on top of all this, you could also swap out calls to different models. So you could make some calls to gpt3.5 turbo or PaLM-2 rather than it all just being GPT-4 calls. What\u2019s failed to mention in that video is that there is a huge cost to these loop systems as they are magnitudes slower than just single calls to a base model. This is why it will make sense to offset some of the load onto different, more efficient models.\n\nIt\u2019s also why OpenAI and such companies won\u2019t put these systems in their base model, because they\u2019re simply way more expensive and it would be limiting. It makes more sense to leave the base models as they are and then allow these loop systems on top of them. As that leaves many more options available to the community. What people may have not realized yet is that these loop systems are the complete next paradigm shift. I'm predicting there will soon be a floof to the market for these different loop systems, everyone will be making them. Which is a good thing. But at the same time, there could be hundreds, even thousands, of them knocking around. With various sources advertising their own loop system and speaking of its particular benefits. Companies themselves, like OpenAi, will release and host their own loop systems too.\n\nAs I mentioned, there are so many different possible configurations of these loop systems. Each with their own benefit for accuracy, cost, speed, creativity and output type. Especially when you consider making API calls to different systems on top. Some of the loop systems will be the most accurate AI we possibly have available but they will be hugely costly and slow. For some tasks, accuracy is king above all else, so these will get used despite their high cost. Some systems will be more of a middle-ground between accuracy and cost. And some will focus most on lowering cost whilst trying to maintain as much accuracy as possible; these ones will probably not even be that much more costly than calls directly to the base models and will likely include utilizing your own hardware as much as possible (like your phone or PC or whatever).\n\nThe lower cost systems are what will make using the base models directly a redundant practice; apart from if you\u2019re making your own specialized loop system utilizing the base model.\n\nThere is, though, a price to pay for all this and this next paradigm shift. The accumulative cost itself. As said, some of these loop systems make way more calls to the base models, so when everyone starts using them it will cause significantly higher loads on company servers (like OpenAI). In effect, there is a resulting leap up in demand for model calls, and as we know from economics class, with increased demand will come increased cost. This will create significantly higher profits for companies like OpenAI, if they can monetize these models well.\n\nNvidia certainly is not going to be doing badly from all this either. There is going to be a huge call for more efficient GPUs and higher volumes of GPUs in order to keep up with society's demand for AI, more than what the industry probably realizes and is predicting. Further and rapid development in processor technology will be paramount for allowing the progression in AI to keep going at the rate it naturally wants to. There may potentially be a bottleneck happening here on the near horizon. If it happens, it will inevitably drive regular people out of the market for access to the very most advanced and accurate AI models. Companies utilize higher returns and will be willing to pay more for access to these models; regular people would not get a look in. Let\u2019s hope this doesn\u2019t happen, but regular folk will still have access to lower or mid-end models and locally run models even if it does happen.\n\nThere is also another cost that will arise from this: a societal one from the upcoming abundance of choice.\n\nPeople are already concerning themselves with which base model they should use, even though there's only a few decent ones to potentially choose from. But people could soon realize that they shouldn\u2019t be using these base models at all, but these loop systems instead. And given the potential flood of them coming, working out which one is best to use could be almost an impossible task.\n\nAs an individual or company, what system should I choose to use for a particular query or task? This will be incredibly difficult / annoying for an individual to work out, but for particular companies it could be more than that; it could mean the difference between remaining viable or not. If another company is able to utilize these loop systems more efficiently and cheaper than them, then that could be all the difference between staying in business or not in some potential future landscapes.\n\nThere is a potential solution to all this that I expect to see: just using AI itself to help find the best desired system. I expect to see an AI front-end created that has access to all upcoming loop systems. As a company, you then tell this AI what task you have and it works out the optimal loop system(s) to offload your task to. This is the sort of AI that could improve massively over time with more data and training. It would gather feedback from its users of how well it chose particular loop systems for them and then learn from this.\n\nWhat would the use-case of such an AI look like? Well, I imagine you would give it 3 main parameters: A detail of the overarching task you want to complete, your budget and the maximum time you want to allow for the task to be completed.\n\nFrom this the AI would then try to predict the necessary accuracy required for your task (if it has not been specified), the optimal form of output that would be best for you to receive (if it has not been specified) and then look at the loop systems available and work out which would be best to use that would satisfy this but also come in under the budget and time constraints that you allocated.\n\nIf you want to get a jump on the market, I would advise anyone with the expertise to try and start working on this sort of thing now. I predict that it will have an extremely high value for anyone that manages to get it right. I can foresee this being the near-future of how companies interact with AI models for task driven queries.",
    "comments": [
        {
            "level": 0,
            "comment": "Can we not with the final solution?",
            "score": 2,
            "author": "Historical-Car2997"
        },
        {
            "level": 0,
            "comment": "The Next Paradigm: Navigating Abundant Model Choices, Loop Systems, and the Hopeful Final Solution\n\nIn the evolving landscape of AI models, there exists a new approach referred to as \"loop systems.\" These loop systems, which involve pre-prompting and self-reflection, have proven to be more accurate than the base models like GPT-4. They represent the current state-of-the-art and are likely to shape the future of AI.\n\nThe video presentations on GPT-4 and SmartGPT highlight the potential for further enhancing loop systems. By incorporating additional response calls, prompts, reflections, and external API calls, such as Wolfram Alpha or calculators, these systems can become even more powerful. Furthermore, experimenting with different parameters like temperature and incorporating calls to other models like GPT3.5 Turbo or PaLM-2 opens up a wide range of possibilities.\n\nIt is important to note, however, that these loop systems come with a significant trade-off in terms of speed and cost compared to single calls to a base model. Consequently, it is unlikely that companies like OpenAI would incorporate these systems directly into their base models. Instead, they are more likely to be offered as additional options on top of existing models. This approach allows for greater flexibility and experimentation within the AI community.\n\nAs the concept of loop systems gains traction, it is anticipated that numerous variations will emerge. Companies, including OpenAI, may release their own loop systems, and the market will likely see a surge of different options with various advertised benefits. Each loop system configuration will offer different trade-offs in terms of accuracy, cost, speed, creativity, and output type. Some systems will prioritize accuracy at a higher cost and slower speed, while others will strike a balance or focus on cost reduction while maintaining reasonable accuracy.\n\nThe availability of lower-cost loop systems will render the direct use of base models obsolete, except for those who create specialized loop systems utilizing the base models. This paradigm shift will be accompanied by increased demand for model calls, placing a heavier load on company servers. Consequently, the cost of accessing these models may rise due to increased demand.\n\nThe rise of loop systems will also have implications for hardware providers like Nvidia. The demand for more efficient GPUs and higher volumes of GPUs will surge, driven by society's increasing reliance on AI. Processor technology advancements will be critical in supporting the rapid progression of AI. However, there may be concerns about a potential bottleneck in the near future, which could result in restricted access to the most advanced and accurate AI models for regular individuals. Nonetheless, lower and mid-range models, as well as locally run models, will continue to be accessible to the general public.\n\nAnother consequence of the proliferation of loop systems is the abundance of choice, posing challenges for individuals and companies alike. While the current focus is on selecting the best base model, the shift towards loop systems may render base model usage irrelevant. With numerous loop systems available, determining the most suitable one for a particular query or task could become a daunting task. This decision can be crucial for companies, as choosing the wrong system could impact their competitiveness.\n\nA potential solution to address the challenge of selecting loop systems is to utilize AI itself. Creating an AI front-end that has access to all loop systems and can analyze tasks to determine the optimal system(s) could alleviate this burden. Such an AI would consider parameters like the task details, budget, and time constraints to predict the necessary accuracy, output format, and select the appropriate loop system(s) within the allocated resources. Over time, this AI could improve through user feedback and training.\n\nFor those looking to stay ahead of the market, developing an AI system that assists in selecting loop systems would be a valuable endeavor. This technology is likely to play a pivotal role in how companies interact with AI models for task-driven queries in the near future.",
            "score": 2,
            "author": "nicdunz"
        },
        {
            "level": 0,
            "comment": "The emergence of loop systems in AI represents a paradigm shift, offering a multitude of options with varying trade-offs, and an AI-based solution for selecting the optimal system may be crucial for navigating this abundance of choices.",
            "score": 2,
            "author": "nicdunz"
        },
        {
            "level": 0,
            "comment": "This is definitely the way. I just released my own loop system in fact. It incorporates fractal note taking methods into gpt\u2019s response format.\n\nhttps://github.com/satellitecomponent/Neurite",
            "score": 1,
            "author": "Intrepid-Air6525"
        }
    ]
}