{
    "id": "145hqk5",
    "score": 3,
    "title": "How close are we to a true, full AI?",
    "author": "Victoryia",
    "date": 1686346950.0,
    "url": null,
    "media_url": null,
    "comments": [
        {
            "level": 0,
            "comment": "To put it plainly, no one knows. Not even those working on the most state of the art models. We are greatly improving upon our current technology but a lot of experts agree we probably need a whole new technology to reach AGI. It's like how we had algebra for centuries (and other types of math) and then one day Isaac Newton invented calculus because he was bored on a farm during a plague. Who could have possibly predicted a timeline for something nobody ever thought of before?",
            "score": 7,
            "replies": [
                {
                    "level": 1,
                    "comment": "This is the most important thing for anyone wondering. Ray Kurzweil doesn't know, Sam Altman doesn't know, the pessimists don't know and the optimists don't know. Will LLMs be it? Nobody knows. Will it be X new architecture? Nobody knows. It's a guessing game so your guess is as good as anyone elses.",
                    "score": 2
                }
            ]
        },
        {
            "level": 0,
            "comment": "GPT4 is actually kinda dumb.   It's designed to give answers that SOUND right; but are not necessarily right.  And humans' tendency to anthropomorphize fills in the rest.  \n\nI've been using GPT 3.5 and 4 for several months now and it's fun to have it report on a sports event in the voice of Hemingway or Shakespeare.   But whenever I try to have it help me with a real-world problem that requires general knowledge and logical thinking it fails with rookie mistakes.    Because it's really just a large language model; it can't think conceptually or logically and it doesn't really \"know\" anything.\n\nBut being a LLM it's very good at finding patterns in huge datasets.    That's why it's good at finding sorting algorithms or new, useful proteins.  That's what will also make it great at designing custom poisons and bio-weapons like targeted viruses.    \n\nHumans ALWAYS weaponize new technology if they can.    That's what makes AI dangerous.",
            "score": 8,
            "replies": [
                {
                    "level": 1,
                    "comment": "Alphafold doesn\u2019t design new proteins, it predicts protein structure.\n\nI\u2019m a data scientist/dev and gpt-4 has made me 3x productive. It\u2019s not dumb. There are emergent properties. It may just be a language model, but it has learned reason from language patterns.",
                    "score": 4
                },
                {
                    "level": 1,
                    "comment": "Always keep the ability to turn it off.",
                    "score": 0,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "&gt;Always keep the ability to turn it off.\n\nPointless advice.    You and I have no way to turn off AI's in other countries who are geopolitical rivals of the countries we live in.\n\nAs I said above, humans will **always** try to weaponize any new technologies they get their hands on.   AI's potentially have many, many ways to help us kill or hurt our rivals better.  And thanks to open source they will soon be in the hands of everyone.",
                            "score": 1,
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "you're full of shit",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "*you're full of shit.*\n\nBrilliant retort.  We sit in awe at your debating skill.  You must have used GPT4 to generate that because you could never have thought of it yourself.\n\nAnyway, have humans ever **not** tried to weaponise a new technology?  Fire?  The wheel? Bronze?  Iron?  Blue-ocean navigation?  The compass?  The telescope. The printing press?  Gunpowder?  Electricity?\n\nThere is no question that every country that can is currently studying how AI can give it an edge at killing people or dominating people.  It's just what we do as *Homo Sapiens*.  Whether it's helping to design new bioweapons or conventional weapons, or control autonomous weapons, or create or control computer malware, or wreck economies or climates, or create better propaganda or ???, AI is too potentially useful to not try to use.",
                                            "score": 2
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Sounds like you are talking about A**G**I \n\nhttps://en.wikipedia.org/wiki/Artificial_general_intelligence",
            "score": 3,
            "replies": [
                {
                    "level": 1,
                    "comment": "Yeah, and even on that term, we can expect people to widely disagree when the first will claim it'll be reached. There's simply no clear-cut consensus on an accepted scientific test, not even the Turing Test.\n\nOne scenario is that things simply change in viscerally-formed perception once the first household robots start having late-night conversations with people. With a body, a face, a voice and a seeming character, there's no way some people won't form friendships...",
                    "score": 2
                }
            ]
        },
        {
            "level": 0,
            "comment": "GPT-6 will replace God.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "We've witnessed impressive strides in AI development over the past decade, surpassing what many thought possible. Yet, we remain a significant distance away from achieving true, human-like consciousness.  While I don't envision a doomsday resembling Terminator, potential challenges could emerge. For instance, if AI systems were to gain unchecked power or develop unintended biases, it could impact our society negatively. The danger lies not in the AI itself, but in how we deploy and regulate it. It's crucial to ensure ethical frameworks are in place to prevent misuse or unintentional harm.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "The field of AI is rapidly advancing, and it\u2019s hard to predict exactly where we\u2019ll be in 10 years. However, many experts believe that we are still quite far from achieving true, full AI. While there are concerns about the potential dangers of advanced AI, it\u2019s important to remember that AI is a tool created by humans. It\u2019s up to us to ensure that it\u2019s used responsibly and ethically.",
            "score": 2
        },
        {
            "level": 0,
            "comment": "probably like 10-15 years. that'll be another 3-5 to train existing models on multi modal like video and images, give them more precise and effective parameters, and teach them how to search the internet without lying to us all the time. Then 5 more years to perfect that and make it quick, personalized, etc. then it may exist, or need a few more years to really be apply to apply its knowledge to new areas",
            "score": 2
        },
        {
            "level": 0,
            "comment": "6 months max. We just need to make an AI just baaaarely good enough to improve itself, then... whelp, game over",
            "score": 1
        },
        {
            "level": 0,
            "comment": "If you are refering to AGI i think GPT5 will be very close to AGI and it may see the day by the end of the year. Of course we won't get access to it for a while, i expect OpenAI to spend a lot of time \"aligning\" it.",
            "score": 0,
            "replies": [
                {
                    "level": 1,
                    "comment": "They aren\u2019t even developing gpt5. They haven\u2019t started training.\n\nI think AGI will require better permanent memory systems. Right now gpt-4 has no memory, it\u2019s just fed your previous conversation along with your current question. No way for it to learn from its interactions like that. More technical improvements needed.",
                    "score": 1,
                    "replies": [
                        {
                            "level": 2,
                            "comment": "They said they haven't started but Sam looks pretty damn hyped about it...\n\n\n\nthere is the role of strategic ambiguity. By declaring that GPT-5 training has not commenced, Altman might be carefully managing expectations, thereby giving his team more freedom to innovate and explore novel approaches to AI model training. This approach could be a strategic move that allows room for taking risks in the development process, potentially leading to surprising leaps in AI capabilities.\n\n\n\nAlso, training time may take like what, 6 months? they still have time to start it and have their own version in their lab by the end of the year.\n\n\n\nA for memory, Altman seems confident he will being way bigger context soon (like 100K). Once you have that, its not that difficult to ask the AI to use 20% of it for a long term memory.",
                            "score": 2
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "At least 30 years, probably 200-300 years. And only if the climate disaster is stopped otherwise it is first 1000 years of the Dark Ages before true AI rises.",
            "score": -5
        },
        {
            "level": 0,
            "comment": "I mean being in the Singularity doesn\u2019t make knowing any easier.",
            "score": 1
        }
    ]
}