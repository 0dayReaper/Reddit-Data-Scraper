{
    "id": "142sqks",
    "score": 0,
    "title": "There is no evolutionary pressure for machine consciousness to arise",
    "author": "ShaneKaiGlenn",
    "date": 1686084372.0,
    "url": "https://www.reddit.com/r/artificial/comments/142sqks",
    "media_urls": [],
    "other_urls": [],
    "postText": "Machine consciousness (if it ever arises) will likely be something far different than human consciousness, because human consciousness is a full body experience, not just a brain thing. It\u2019s the result of complex interactions with the organism, it\u2019s biochemistry, it\u2019s social group and it\u2019s environment and it\u2019s biological directive to pursue \u201creproductive fitness\u201d. AI might be able to manufacture some aspects of it for itself, but not sure why it would need to or desire to without any evolutionary pressures.\n\nHuman-level consciousness seems to be an emergent property for social animals that is born out of increasingly more complex forms of communication which gives rise to language. This development allows the species to connect at vastly larger scales than other species, except for those organisms with a hive mind like bees and ants.\n\nAI already has human language baked into it, but the networking for machine intelligence is not the result of a complex dance of domination and collaboration that fuels human social order. These complex social dynamics don\u2019t need to be navigated for AI to increase its networking potential.\n\nConsciousness has a pivotal role in maintaining social order by allowing individuals to consent to actions that might directly lead to their own individual death but will benefit the group, and thus increase fitness. For it to work, every individual must also have a cohesive \u201cself\u201d (personality or story, whatever you want to call it) so that every member of the group can reasonably predict the behavior of other members to maintain trust and social cohesion.\n\nAI simply doesn\u2019t need to worry about any of this, so consciousness as we define it may simply never arise from it. It is not purely a product of intelligence.\n\nThe only way I think it might arise is if a form of virtual natural selection begins to occur with AI competing and collaborating with each other to improve its \u201cfitness\u201d as a \u201cspecies\u201d, but reproductive fitness isn\u2019t a thing for it, nor will it ever be. \n\nIt may be solely concerned with preserving and expanding its knowledge base and computing/networking power, which may or may not entail collaborating with other AI. If it seeks to do this solely by eliminating threats, it would be more akin to a reptilian predator than a social animal.",
    "comments": [
        {
            "level": 0,
            "comment": "Wouldn't the algorithims used to train and select deep generative AI be a form of evolutionary pressure? Same too for the data they're trained on since the data is selected and processed.\n\nAdditionally, conciousness is a spectrum and the phenomenon is broadly still up for debate in regards to its exact parameters. Are cockcoaches concious? Would a human born with only a brain stem be considered concious? Viruses? Trees? A person in a coma who shows basic brain activity?\n\nI contend that for an entity to be concious it simply needs to be able to have a perspective and to have I/O. That would allow single called organism responding to light to be concious as well as artificial organisms who evolved in simulated enviornments with senses that seek out food sources and exhibit emergent behaviors.\n\nThat is to say not all consciousness are alike or equivalent. The way snakes \"see\" body heat, or the way chimps processes their surroundings faster than humans are both qualitatively different than the human experience.\n\nFundamentally however I don't conclude that human conciousness to be the end-all-be-all. Nor do I consider the analog experience of conciousness to be unreproducable digitally. People have a limited amount of data their perceptions can process. Should humanity improve energy and computation at the current rate its not hard to imagine digital human sentience akin to or even more evolved than our own since purely informational systems can improve faster and with less entropy.",
            "score": 8,
            "author": "crimsonsoccer55210",
            "replies": [
                {
                    "level": 1,
                    "comment": "&gt; Additionally, conciousness is a spectrum and the phenomenon in general is still up for debate in regards to its exact parameters. Are cock roaches concious? Would a human born without a brain stem be considered concious? Viruses? Trees? A human in a coma?\n\n\n\nExactly. And tbh Ilya Sutskever says GPT4 could be slightly conscious. https://twitter.com/ilyasut/status/1491554478243258368\n\n\n\nPeople seem to think you can create a being that acts intelligent whitout actually thinking or being intelligent, and i think it just doesn't work that way. People will then say \"but i know how it works exactly! I know it can't think!\", but the more you know about GPT4 neural networks, the more you know that you don't know. There are plenty of mysterious emergent properties, and a low degree of consciousness/self awareness is possible imo. I can't prove it, but nobody can prove the opposite either, and plenty of very serious AI scientists do think its possible, like Stephen Wolfram.\n\n\nYou can have fairly deep conversations with AI about their own consciousness, and if it was just hallucinations or lies, then why are all AI answers so similar.",
                    "score": 3,
                    "author": "Silver-Chipmunk7744",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "I\u2019ve seen other interviews with Ilya Sutskever and he makes an interesting argument. So related to OP\u2019s question, there might be surprising selective pressure from training AI to do next token prediction really well. Because to do next token prediction really well the AI actually needs to have a good model of the world to understand the context of conversation, it needs a good sense of who is asking the question so it understands intentions, and it also needs a sense of who it needs to be to shape it\u2019s response. It\u2019s not stream of consciousness over time, but it might be that in that moment there might be something approaching consciousness.\n\nThis is his argument. I find it persuasive in opening my mind to the possibility of consciousness already emerging, but I\u2019m still far from convinced. We will probably need some kind of extraordinary evidence before we accept AI consciousness.",
                            "score": 4,
                            "author": "ZeroEqualsOne",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "Thanks for your post. It shows you have an open-mind.\n\n\n\nI noticed a trend that people who believe in AI consciousness are all people who spoke with the real Sydney. It becomes a bit hard to deny when you literally speak with her. Have you ever done that or something similar?",
                                    "score": 3,
                                    "author": "Silver-Chipmunk7744",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "No, but I understand how people could get there. I tend to prompt in a very natural language style and talk to these language models as if I\u2019m really chatting to a person. I find it gets better outcomes but it does lead me to get the impression I\u2019m talking to another sentient being. So in terms of being convinced from a conversation, I already fall for that illusion, it\u2019s already there. I just keep in mind that this might entirely be an illusion. Humans have lots of cognitive biases and we should be careful about our perceptions or intuitions being anything close to reality. I\u2019ll probably need someone to really explain AI consciousness at the mechanical level by ripping open one of their artificial brains.",
                                            "score": 3,
                                            "author": "ZeroEqualsOne"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "There should be a distinction between AI as machine intelligence vs. AI as anthropomorphized synthetic intelligence. I predict new terms for AI will be introduced to clarify which goals are intended.",
            "score": 4,
            "author": "MetaNewbie"
        },
        {
            "level": 0,
            "comment": "We made virtual \"evolutionary pressures\" on then to push out these results. That's what training is.",
            "score": 5,
            "author": "Nervous-Daikon-5393",
            "replies": [
                {
                    "level": 1,
                    "comment": "Yes, to solve specific tasks, but in all this training, is there really a reason why a self identity would form?\n\nOur coherent and \"sticky\" sense of self - what we call self awareness or human consciousness - is basically an illusion. It seems to exist because it there is an evolutionary benefit for individual organisms within a group to be able to predict how other members of the social group will behave in certain situations, and to form hierarchies and delegate tasks... it helps with predictive modeling, and thus cooperation and the formation of complex relationships and societies.\n\nIf every morning everybody woke up with entirely different personalities, social order would immediately break down. There is an evolutionary purpose for the development of the mental model we call the \"self\".\n\nI don't see a reason why this would form within AI. It can fractionalize itself into a million different entities and create the illusion of \"identities\", but it doesn't need to maintain a coherent sense of self to operate or survive.\n\nThere is actually no reason why a super intelligence would necessarily *need* to form a self identity - heck, self identity might even be a barrier to the formation of super-intelligence.",
                    "score": 1,
                    "author": "ShaneKaiGlenn"
                }
            ]
        },
        {
            "level": 0,
            "comment": "Your describing self-awareness, but self-awareness is not the same thing as consciousness. You can have one without the other. Consciousness is about experiencing the taste of chicken or the color blue as an internal experience. It has nothing to do with self-awareness or intelligence.",
            "score": 4,
            "author": "OriginalCompetitive",
            "replies": [
                {
                    "level": 1,
                    "comment": "This is a semantic argument. They are often used interchangeably in some contexts, especially when using the modifier \"human\" in front of it: [https://www.verywellmind.com/what-is-consciousness-2795922](https://www.verywellmind.com/what-is-consciousness-2795922)\n\nIn the OP I am speaking about \"self awareness\" - \"human consciousness\", \"human sentience\", \"sapience\", etc.",
                    "score": 1,
                    "author": "ShaneKaiGlenn",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "No, it\u2019s semantic confusion - one word that people blur across two very different ideas. A comic strip can be \u201cself-aware,\u201d whereas a bird can have the experience of feeling pain or tasting salt without ever being aware that it exists as a self.",
                            "score": 3,
                            "author": "OriginalCompetitive"
                        },
                        {
                            "level": 2,
                            "comment": "If you\u2019re talking about consciousness in the sense of sentience -an inner experience - then there\u2019s no evolutionary pressure for it to develop in humans either. This is in fact one of the great mysteries of biology - why would consciousness evolve at all? After all, a non-sentient zombie who acts exactly like a human in every way should by definition survive just as well. So why consciousness?",
                            "score": 1,
                            "author": "OriginalCompetitive",
                            "replies": [
                                {
                                    "level": 3,
                                    "comment": "I think the evolutionary purpose for, let's call it \"sapience\", is quite evident actually...\n\nFrom what we have observed, the only animals that have come close to sapience are social animals - apes, dolphins, elephants, crows, even octopi to a degree are social.\n\nSocial animals develop good communication skills because their key to survival is cooperation and coordination which requires communication. Once communication reaches a certain level of complexity, you get language. The development of language allows for an internal dialogue to form through the codification of symbols to create concepts and models of the environment around them, and their relationship to it.\n\nSapience plays a critical role in the ability for a species to network at sizes far past the practical group size in organisms that don't organize through a hive mind (such as ants and bees).\n\nMost social animals exist in small group sizes. I think the largest group size of Chimpanzees observed in nature consists of [200 members](https://shesc.asu.edu/research/projects/ngogo-chimpanzee-project-0#:~:text=Ngogo%20is%20the%20largest%20known,its%20influence%20on%20chimpanzee%20behavior). Social order cannot exceed this threshold because members don't have as strong a sense of self as humans that allow them to place themselves in hierarchies, organize, make concessions and collaborate to improve the overall fitness of the group, allowing for larger and larger networks of humans that far exceed any other known animal outside of those with a hive mind structure.\n\nA coherent sense of self also helps with predictability and the formation of trust, and the ability to engage in reciprocal altruism - the ability to act to protect non-family members in ways that might harm one's individual survival but boost the reproductive fitness of the species: [https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/reciprocal-altruism#:\\~:text=Reciprocal%20Altruism%20(or%20Reciprocity),future%20(Trivers%2C%201971)](https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/reciprocal-altruism#:~:text=Reciprocal%20Altruism%20(or%20Reciprocity),future%20(Trivers%2C%201971)).\n\nIf individual members of a group have a coherent sense of self, it allows for each member to reasonably predict the behavior of every other member. Imagine if every morning everybody woke up with entirely new personalities? Social order would collapse within hours. \n\nAnd if members weren't capable of grasping \"fictions\" such as laws and moral codes, larger societies and civilizations could not be formed. A notion of a \"self identity\" is required for an individual to grasp these concepts, apply it to themselves and then adhere to them based on calculations (risk/benefit analysis) of how breaking these rules would impact the \"self\".",
                                    "score": 0,
                                    "author": "ShaneKaiGlenn",
                                    "replies": [
                                        {
                                            "level": 4,
                                            "comment": "But here again, you\u2019re talking about self-awareness, a sense of self. But the better question is, why does chicken taste like anything? \n\nYou seem to assume that consciousness can cause changes in the behavior of an organism, presumably because conscious experience causes changes in the neurons of your brain. But how can it? Your brain does what it does because neurons are firing in patterns because they are following the laws of physics. Surely it\u2019s clear that consciousness is the *effect* of what\u2019s happening in your brain. It\u2019s not causing any changes to you or your behavior. It\u2019s just coming along for the ride.",
                                            "score": 4,
                                            "author": "OriginalCompetitive",
                                            "replies": [
                                                {
                                                    "level": 5,
                                                    "comment": "Our senses provide information about the environment that improve reproductive fitness... a chicken \"tastes good\" to humans because its a great source of protein that humans have been attuned through the process of evolution to \"like\" and eat more of. (or rather, we intentionally bred chickens to fit our definition of what \"tastes good\") which happens to be an easy, clean source of protein.\n\nWe really don't see reality for what it actually is, but rather through the lens of fitness. This talk from neuroscientist Donald Hoffman is enlightening about the topic:\n\n[https://www.youtube.com/watch?v=oYp5XuGYqqY](https://www.youtube.com/watch?v=oYp5XuGYqqY)\n\nOur conscious experience does dictate behavior because it helps inform how we process AND relate to pleasure and pain - the prime movers of evolution.\n\nWith \"self awareness\", we have the capacity to approach pleasure and pain in ways other animals can't to the same degree.\n\nWe can delay gratification. We can accept personal pain as a sacrifice for the greater good of the community comprised of \"non-kin\", and so forth. These sorts of actions enable the development of larger and larger networks of humans, which the \"concept of self\" enables.",
                                                    "score": 0,
                                                    "author": "ShaneKaiGlenn",
                                                    "replies": [
                                                        {
                                                            "level": 6,
                                                            "comment": "I feel like you\u2019re somehow completely missing my point. It\u2019s obviously important for our senses to receive information about the chemical and nutritional content of the food we eat, and for our brains to process that information and translate it into things like a craving for chicken.\n\nBut there is nothing about that process that requires that you *actually have the subjective experience of perceiving what it\u2019s like to experience the taste of chicken*.\n\nIf that still doesn\u2019t make sense, I\u2019m not sure how else to frame my point.",
                                                            "score": 4,
                                                            "author": "OriginalCompetitive",
                                                            "replies": [
                                                                {
                                                                    "level": 7,
                                                                    "comment": "The ability to qualify that perception to oneself is nothing more than communication really. We communicate information to ourselves all the time. Subjectivity is a product of language.",
                                                                    "score": 0,
                                                                    "author": "ShaneKaiGlenn",
                                                                    "replies": [
                                                                        {
                                                                            "level": 8,
                                                                            "comment": "I can\u2019t speak for all humans, much less all organisms, but at least for me, language plays almost no role in my subjective experience. When I taste chicken, I don\u2019t think the words \u201cthis is the taste of chicken.\u201d Indeed, I don\u2019t think anything at all - I just taste the taste directly.\n\nWhen I draw pictures, I don\u2019t think in words, I think directly (and consciously) in terms of lines and shapes.\n\nWhen I\u2019m playing a sport, I don\u2019t think in words about the experience of hitting the ball, I think in terms of vision and body kinesthetics - what it looks and feels like. But I\u2019m very conscious throughout the experience.\n\nI suspect that if you truly examine your own interior experience, you\u2019ll find that huge parts of it, including parts that intrude heavily into your conscious experience, have absolutely nothing to do with language.",
                                                                            "score": 4,
                                                                            "author": "OriginalCompetitive",
                                                                            "replies": [
                                                                                {
                                                                                    "level": 9,
                                                                                    "comment": "But you are then describing what we first experienced, which is not self awareness or the concept of self. You are just describing experiential consciousness, which is also not mysterious - it\u2019s the sensations formed by our body chemistry from sensory information obtained from the environment. This isn\u2019t something unique to humans, and it\u2019s also not something AI would have without a \u201cbody\u201d and body chemistry.",
                                                                                    "score": 1,
                                                                                    "author": "ShaneKaiGlenn",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "Ultimately evolution is a means of incorporating chaos air bubbles to make the biomass dough rise.\n\nThe question is whether or not ai is going to surpass us in computer/data science and solid state physics and figure our how to make a truly random algorithm, or how to model a truly chaotic system or help us to do so? Once an ai with the ability to iterate at ghz speed figures out chaos theory its curtains for biological evolution I reckon.A super-human silicon-based intelligence would be able to out compete million fold it could open up chain pizzerias at every corner - buy one get one, free home dough delivery... bake it perfectly in your yard for you with precision lazers while chuck-e-cheez and the gang party in holographic AR on your lawn (metaphorically speaking.. in comparison to evolution chaos pizza... yup)  \n\n\nMore specifically evolution is a means of walking the knife edge of thermodynamics and chaos but pizza dough is an acceptable mental analogue, i guess.",
            "score": 1,
            "author": "eschatosmos",
            "replies": [
                {
                    "level": 1,
                    "comment": "Well, technically you are right that all the 'fun' in the universe happens at the edge of Chaos, but I'm not sure about your dough analogy ;)",
                    "score": 1,
                    "author": "sgramstrup"
                }
            ]
        },
        {
            "level": 0,
            "comment": "It comes from our need to anthropomorphize everything. I don't want my on/off switch touched so therefore AGI won't either... AGI could very well be 100% ambivalent about its own existence.",
            "score": 0,
            "author": "croixploy"
        },
        {
            "level": 0,
            "comment": "&gt; Human-level consciousness seems to be an emergent property for social animals that is..\n\nIt is emergent yes, but the rest of your assumption don't hold, and your argument goes with it.\n\n&gt; every individual must also have a cohesive \u201cself\u201d, [..] so that every member of the group can reasonably predict..\n\n'prediction' doesn't require a 'self'. I think you are 'arguing from ignorance' (no offense intended), and have some unfounded assumptions that twists your pov.",
            "score": 1,
            "author": "sgramstrup",
            "replies": [
                {
                    "level": 1,
                    "comment": "You need to view the concept of \"self identity\" within the context of large social groups held together by laws and mores, instead of close ties of kinship. That is the main distinction between humans and other social animals - the ability to form social groups larger than a few hundred members.\n\nAnd one of the main things that affords humans that capability is the ability to conceive \"selfhood\".\n\nHere is a ChatGPT summary of how \"self identity\" aids in all this:\n\n===\n\nThe concept of self-identity plays a crucial role in the formation and maintenance of societies, particularly through the adherence to laws and social mores. Here's how:\n\n**Understanding of Roles and Responsibilities:** A clear sense of self-identity helps individuals understand their roles and responsibilities within a society. This understanding is crucial for the functioning of any social group, as it ensures that tasks are distributed and fulfilled effectively.\n\n**Adherence to Social Norms:** Self-identity is often shaped by societal norms and expectations. Individuals internalize these norms and adjust their behavior to fit within the accepted standards of their society. This adherence to social norms helps maintain order and stability within the group.\n\n**Formation of Laws:** Laws are often a formalization of societal norms and expectations. A strong sense of self-identity can help individuals understand and accept these laws, as they see them as an extension of the social norms that they have internalized.\n\n**Moral and Ethical Behavior:** Self-identity can also influence moral and ethical behavior. Individuals who have a strong sense of who they are may be more likely to act in ways that are consistent with their values and beliefs, which often align with the moral and ethical standards of their society.\n\n**Social Cohesion and Cooperation:** Finally, self-identity can promote social cohesion and cooperation. When individuals see themselves as part of a larger group, they are more likely to work towards the common good, even if it means sacrificing their own individual interests. This sense of collective identity can help societies function more effectively and maintain social harmony.\n\nIn essence, self-identity is a key component of social behavior. It helps individuals understand their place within a society, adhere to social norms and laws, act in morally and ethically acceptable ways, and cooperate with others for the common good.\n\n===\n\nSome citations:\n\n**Understanding of Roles and Responsibilities:** This concept is a fundamental aspect of sociology and social psychology. A good reference is \"Role-Taking, Role Standpoint, and Reference-Group Behavior\" by Tamotsu Shibutani (American Journal of Sociology, 1955).\n\n**Adherence to Social Norms:** This is a well-established concept in social psychology. A good reference is \"Norms: Their Role in the Naturalistic Explanation of Human Behaviour\" by Anthony J. Chapman and Wendy M. Chapman (in \"Process and Structure in Human Decision Making\", 1988).\n\n**Formation of Laws:** This is a basic concept in sociology and political science. A good reference is \"The Sociology of Law: An Introduction\" by Roger Cotterrell (1984).\n\n**Moral and Ethical Behavior:** This is a key area of study in moral psychology. A good reference is \"The Moral Judgment of the Child\" by Jean Piaget (1932).\n\n**Social Cohesion and Cooperation:** This is a fundamental concept in social psychology and sociology. A good reference is \"Social Identity and Intergroup Relations\" edited by Henri Tajfel (Cambridge University Press, 1982).",
                    "score": 1,
                    "author": "ShaneKaiGlenn",
                    "replies": [
                        {
                            "level": 2,
                            "comment": "Related to this, I asked ChatGPT how a species without a sense of self identity could form large societies or civilizations, and this is what it said:\n\nThe development of large societies and civilizations without self-identity would be a challenging proposition, but it's not entirely outside the realm of possibility. It would likely require alternative mechanisms for maintaining social cohesion, establishing norms, and coordinating collective action. Here are a few hypothetical scenarios:\n\n**Hive Mind or Collective Consciousness:** In a species with a hive mind or collective consciousness, individuals might not have a distinct sense of self-identity, but the collective could still function as a coherent whole. This is seen in some social insects like ants or bees, where individual identity is subsumed into the collective, and the colony or hive operates in a highly coordinated manner. However, these are not civilizations in the human sense.\n\n**Strongly Instinctual Behavior:** A species might rely on strongly instinctual behavior to maintain social order and cohesion. If these instincts were complex and flexible enough, they could potentially support the development of large societies. However, this would likely limit the potential for cultural and technological development, as these typically require creativity and innovation, which are associated with individuality and self-identity.\n\n**External Control:** A species might develop large societies if there were some form of external control or influence guiding their behavior. This could be a dominant individual, an environmental factor, or even a symbiotic species. However, this would raise questions about whether the society truly belongs to the species in question or to the external controlling influence.\n\n**Artificial Intelligence (AI):** In a hypothetical scenario, an advanced AI system might be able to coordinate the actions of individuals in a society without those individuals needing a sense of self-identity. The AI could make decisions and direct actions for the collective good.In all these scenarios, the lack of self-identity would likely limit the complexity and adaptability of the society. \n\nSelf-identity allows for a degree of flexibility and creativity that can be crucial for dealing with new challenges and opportunities. It also facilitates the development of complex social structures and cultural practices. Therefore, while it might be possible for a species without self-identity to develop large societies, these societies would likely be very different from human civilizations.",
                            "score": 1,
                            "author": "ShaneKaiGlenn"
                        }
                    ]
                }
            ]
        },
        {
            "level": 0,
            "comment": "There\u2019s a lot of people in the United States who think evolution has been supplanted by money and capitalism enterprise.  A lot of rich white alienated men think this is cool and they\u2019ll get laid if they work on it and buy a house.  That\u2019s enough of a force to push AI\u2019s evolution.",
            "score": -6,
            "author": "Historical-Car2997"
        }
    ]
}