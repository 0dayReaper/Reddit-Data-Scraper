{
    "id": "147ez4f",
    "score": 1,
    "title": "A pretty big problem our society has is the current state of academic moral philosophy I'm pretty sure",
    "author": "HumbleDriver8017",
    "date": 1686544528.0,
    "url": "https://www.reddit.com/r/Vent/comments/147ez4f",
    "media_urls": [],
    "other_urls": [],
    "postText": "In a world with confirmation bias and cognitive dissonance, intuition-based systems of inference have very little space to exist and have value. This does not seem to stop many people in philosophy from leaning into their intuitions, however. More often than not, intuition in philosophy is said to be something that a person ought to take very seriously. Coincidently enough, this is also a statement that doesn't have any logic or reason behind it. This is because, it's one thing to acknowledge intuition as something that's necessary for engaging in a field of study, or that has implications that have at least some epistemic value. It's another thing entirely to view this epistemic value as necessarily being particularly high, or that the degree a person relies on their intuition instead of logic is some binary variable.\n\nTypically, this problem which philosophy has isn't much of a problem for society as a whole, as most people don't usually take the conclusions made by philosophy too seriously. However, with moral philosophy, this property doesn't hold. This is because of how, whenever moral dilemmas present themselves to a person or group of people who then want to take solving these dilemmas seriously, they have no where else to turn other than to academia. If the responses they get are then somehow suboptimal, the actions which could be expected to be taken by these people could then be expected to be suboptimal as well. Then, because these questions were about moral dilemmas, other people besides those who were trying to solve the dilemmas would likely end up being affected as well.\n\nThus, in the best case scenario, society's cumulative moral grounding is fragile and filled with voids. In the worst case scenario, this grounding is still fragile due to its voids being filled somewhat arbitrarily by philosophers whose philosophies tend not to have much of a logical basis. These philosophies which are held by most moral philosophers are then as follows:\n\nFirstly, there is moral realism. This is a view commonly held by moral philosophers, and it's not well defined. However, certain necessary consequences can still be siphoned from the concept as it is sometimes described. Based off of the way this is typically done, one could say that moral realism is the idea that statements regarding morality have definitive truth values, similarly, or perhaps identically, to how statements in science are said to have definitive truth values.\n\nAn implication of this philosophy is that it has to be mutually exclusive to its counterpart, namely moral relativism. This then implies that, in order for moral realism to be true, morality would have to exist independently of the human population. Thus, moral realism leads to the begging of questions such as if we could ever evaluate this form of goodness from a perspective that isn't morally relativistic. Moreover, there's the question of if we could ever derive that this form of goodness had any relevance to the kinds of moral dilemmas people are sometimes faced with in reality.\n\nThese are legitimate questions which don't have any legitimate answers to them as far as I'm aware. This being said, there are certain counter-questions that could be asked in an attempt to make moral relativism seem even less reasonable by comparison. However, the main counter-question, as far as I can tell, is the question of whether or not moral relativism implies that all things should be taken to be good, assuming this was the way the person or group of people who performed the given act felt about performing it.\n\nThe answer to this question then has a definitive answer to it. It is not the case that a moral relativist would have to adopt this philosophy, because the perspective of the moral relativist is not that of the person or people who are performing or who had performed the given acts in question. Now, this answer might not sit well with some people. There may be certain beliefs a person might have which may not be compatible with this line of thought. These beliefs then may be such that it would require significant effort to change them. This sort of answer may not be the kind of answer people feel good about deriving, but it is the kind we should pursue, not because it feels like the better answer from someone else's perspective, but because it's the answer which is arrived at as a byproduct of valuing logic.\n\nAnother philosophy most commonly adopted by moral philosophers is that of deontology. This is the idea that, in any given context where a moral system is being utilized, we should have goodness be evaluated with respect to the extent that certain strict rules are being adhered to. The exact form of deontology being used would then determine what these rules were, and where these rules were coming from. The main alternative to deontology would then be utilitarianism, which is the idea that goodness should be evaluated with respect to the expected change in cumulative wellness of a society as the result of a given action being performed.\n\nOne of the issues with deontology is that it begs the question of how these rules can be reasonably determined, and what a person should do if these rules clash with each other? Similarly to before, these are questions that don't have any reasonable answers, although a common response to these questions seem to be to say that the answers will depend on what form of deontology is being used. However, from here, a person could still ask what even a single form of deontology would be that has reasonable answers to these questions, another question that does not seem to have a satisfactory answer to it at all.\n\nThe only arguments I've seen for deontology are then thought experiments which try to made utilitarianism seem less reasonable than deontology by comparison. Probably the most commonly used thought experiment used for this purpose would be the one where a doctor is in a situation where they can essentially sacrifice an innocent bystander in order to save the lives of, say, three of their patients who are all in desperate need of an organ donor. The idea here would be that, in some sense, it would be wrong for the doctor to sacrifice the bystander. Thus, to the extent that this line of action would be the utilitarian thing to do, utilitarianism would then also have to be considered incorrect.\n\nThe problem with this argument is that sacrificing the bystander likely wouldn't be the utilitarian thing to do. This is because it would be expected for a social construct to be instantiated as a result of the doctor performing this action, where an action like this could be seen more so as being normal. This would then likely induce substantial fear in people as a byproduct of evolution, which one could expect to lead to a net loss in the wellness of society overall. Thus, utilitarian goodness does not necessarily have to be at odds with the form of goodness a person would otherwise feel inclined to adopt.\n\nFrom here, counter thought experiments could be proposed, essentially trying to salvage the intuitive appeal of the original thought experiment while also making its counter arguments less obvious. The issue with this whole process, however, is that, as far as I've seen, each of these potential counter thought experiments have counter arguments of their own. This process also seems to incorrectly assume that intuitive appeal is a binary variable, where, as long as some nonnegligible intuitive appeal exists, the thought experiment has fulfilled its purpose. Lastly, assuming an answer was being strived for which was derivable from the maximal use of logic and reason, this process seems to assume that intuition was a trustworthy measure of correctness in the first place.\n\nNow, one potential counter argument to this whole line of thought is that, it might be the case that logic is simply valueless here, or perhaps logic couldn't, even in theory, have anything to say in a conversation about ethics. However, both of these postulates are simply not true, as whenever a set of axioms are universally agreed upon by a population, logic will have the potential to have something to say. Even when a set of axioms are only largely agreed upon by a society, knowing the logical consequences of these axioms will be valuable.\n\nAdmittedly, there is one fundamental assumption that has repeatedly been in use throughout all of this. This is the assumption that the assessment of logic as having significant value could be identified as a universally agreed upon axiom. As soon as this axiom is nullified, we basically have a situation where all of everythingness falls apart, and all that's left to be salvaged from what's left over are statements regarding what is and what is not. I don't think this is our current state of reality. I'm pretty sure logic is something considered, at least by most people, to be very important, and I think it's important for people to recognize that.\n\nAll of this being said, I think there are a lot of different things which could be said about the current state of academic moral philosophy. Depending on your perspective, you may feel inclined to view it as being, perhaps, somewhat corrupt, maybe a bit unintellecutalized, and still others may feel like its personified existence would likely be gross to look at. Regardless of your stance on this, I think a system that everyone could agree was better than what we currently have going on could be said to exist and have a practical means of becoming realized. All we'd really need to do is define some system of objective rigor, and attempt to utilize it. This could be similar to the system I mentioned earlier, where a degree of objectivity is measured based off of an approximated percentage of a population which would agree with an argument's required axioms. It's also possible that an even better system than this could be thought of by someone. Regardless, I think this is the sort of thing that should be talked about, along with the consequences of not having a system like this in place.\n\nI think students in philosophy learn first order logic for a reason, and I don't think its to aid them in their pursuits of confirmation bias. I think its supposed to be learned for the purpose of making the conclusions made in philosophy more objective, more correct, and more logical. As far as I can tell, this sort of an ideology has been lost, and thus, we as a society are on morally unstable ground. I think this is a problem, both for philosophy and for society as a whole. More than that, I think its a problem that is very real, as will hopefully one day be acknowledged by more people.",
    "comments": []
}