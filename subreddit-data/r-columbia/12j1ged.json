{
    "id": "12j1ged",
    "score": 3,
    "title": "Difference between Richard Zemel's Neural Networks Class and ML?",
    "author": "csmajorbutlikeslit",
    "date": 1681254871.0,
    "url": "https://www.reddit.com/r/columbia/comments/12j1ged",
    "media_urls": [],
    "other_urls": [],
    "postText": "Anyone know the difference between his class and Verma/Hsu's?",
    "comments": [
        {
            "level": 0,
            "comment": "I assume you're talking about Intro to ML (Verma's) and Neural Networks &amp; Deep Learning (Zemel's).\n\nIntro to ML focuses a lot more on the theoretical foundations of ML - why they work from a mathematical perspective. There's no actual coding, focus is more on things like linear algebra, probability, proofs, etc. Topics include stuff like MLE, Naive Bayes, SVMs, etc.\n\nNNDL has Intro to ML as an unofficial prereq (as in, you don't necessarily have to have taken Intro to ML but having that background is really helpful). This course is more about the actual things that are used in industry, including things like GANs, autoencoders, transformers, etc. The homework is actual coding using stuff like PyTorch, and there's an open-ended group project for the last month of the class.",
            "score": 2,
            "author": "SuperLuigi231",
            "replies": [
                {
                    "level": 1,
                    "comment": "This is mostly true, except ML does include some coding. About 30-40% of the homework is coding. However, the tests are all math.",
                    "score": 2,
                    "author": "IngenTro"
                }
            ]
        }
    ]
}